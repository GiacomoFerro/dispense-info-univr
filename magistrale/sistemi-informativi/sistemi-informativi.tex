\documentclass[a4paper, 10pt]{article}
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{float}
\usepackage{fixltx2e}
\usepackage{listings}
\usepackage{color}
\usepackage{latexsym}
\usepackage{lstautogobble}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage[margin=3cm]{geometry}
\usepackage{hyperref}
\usepackage{libertine}
\usepackage{tikz}
\usepackage{wrapfig}
\hypersetup{
	hidelinks, 
	colorlinks = true,
	linkcolor = black,
}

\usetikzlibrary{shapes, arrows}

\newtheorem{definit}{Definizione}[subsection]
\newcommand{\chainto}{$ \to $}

\begin{document}
	\clearpage
	\begin{titlepage}
		\centering
		\vspace*{\fill}
		{\scshape\LARGE Università degli Studi di Verona \par}
		\vspace{1.5cm}
		\line(1,0){280} \\
		{\huge\bfseries Sistemi informativi\par}
		\line(1,0){280} \\
		\vspace{0.5cm}
		{\scshape\Large Riassunto dei principali argomenti\par}
		\vspace{2cm}
		{\Large\itshape Davide Bianchi\par}
		\vspace{1cm}
		
		\vspace{5cm}
		\vspace*{\fill}
		% Bottom of the page
		{\large \today\par}
	\end{titlepage}
	\thispagestyle{empty}
	\newpage
	\tableofcontents
	\newpage
	
	
	\section{Teoria dell'organizzazione}
	\subsection{Introduzione}
	Iniziamo con alcune definizioni \textit{estremamente} tediose.
	\begin{definit}[Sistema informativo]
		Il Sistema Informativo (SI) è la componente (sottosistema) di una organizzazione che gestisce le informazioni di interesse.
	\end{definit}
	
	\begin{definit}[Organizzazione]
		Un’organizzazione è : \begin{itemize}
			\item il processo attraverso il quale tale insieme di persone viene strutturato secondo i principi di divisione del lavoro e coordinamento;
			\item il risultato del processo di divisione del lavoro e coordinamento.
		\end{itemize}
	\end{definit}
	
	\begin{definit}[Azienda]
		Un'azienda, nell'economia aziendale, è un'organizzazione di uomini e mezzi finalizzata alla soddisfazione di bisogni umani attraverso la produzione, la distribuzione o il consumo di beni economici.
	\end{definit}
	
	\begin{definit}[Organizzazione aziendale]
		Il processo attraverso il quale l'insieme di persone che partecipano direttamente allo svolgimento dell'attività dell'azienda viene strutturato secondo i principi di divisione del lavoro e coordinamento.
	\end{definit}
	L'organizzazione aziendale ha sempre almeno i macro processi operativo e gestionale, e dispone di risorse materiali, umane e informative.
	
	\begin{definit}[Tecnologie informatiche]
		Insieme di sistemi, strumenti e tecniche predisposti per automatizzare il trattamento delle informazioni.
	\end{definit}
	
	Un sistema informativo aziendale è una collezione di elementi interconnessi che gesticono la raccolta, l'elaborazione e la restituzione di informazioni. \\
	
	Un sistema produttivo aziendale è basato su \textit{obiettivi} (output atteso), \textit{input} ed \textit{output} effettivi. Definiamo inoltre i concetti di \textit{efficienza}, ovvero il costo di raggiungimento degli obiettivi, e di \textit{efficacia}, ovvero il grado di raggiungimento degli obiettivi. A grandi linee: \[ \text{\textit{Efficienza}} = \frac{Output}{Input} \qquad \text{\textit{Efficacia}} = \frac{Output}{Obiettivi}  \]
	
	Efficienza ed efficacia subiscono impatti differenti rispetto ad una innovazione delle risorse tecnologiche. Nel caso dell'efficienza: \begin{itemize}
		\item Riduzione dei costi unitari;
		\item Aumento di produzione a parità di risorse;
		\item Incentivo alla crescita delle dimensioni organizzative;
		\item Maggiore complessità strutturale;
		\item Cambiamenti della struttura organizzativa.
	\end{itemize}
	
	Nel caso dell'efficacia: \begin{itemize}
		\item Più efficiente uso dei fattori produttivi a parità di volumi di produzione (economie di scopo);
		\item Razionalizzazione dell'uso di risorse;
		\item Maggiore efficienza spesso legata a differenziazione dei prodotti e all’ampliamento della gamma.
	\end{itemize}
	
	L'organizzazione è un sistema aperto, influenzato da variabili ambientali, che vengono riassunte nell'\textit{incertezza ambientale}.
	L'incertezza ambientale determina i requisiti di capacità elaborativa della organizzazioni e l'adeguatezza del sistema informativo.
	
	\begin{definit}[Capacità elaborativa]
		Adeguatezza di un’organizzazione rispetto alle necessità di elaborare informazioni a essa imposte dai propri obiettivi e dal contesto in cui opera.
	\end{definit}
	
	L'ambiente è riassunto nel modello della piramide di Anthony, ovvero una piramide divisa in livelli gerarchici.
	Il layer più alto si occupa delle decisioni strategiche, quello centrale delle decisioni direzionali e quello basso di quelle operative.
	% FIGURA DELLA PIRAMIDE DI ANTHONY
	
	
	
	\subsection{Informazione come risorsa organizzativa}
	\paragraph{Caratteri principali.} L'informazione è la vera risorsa nelle attività organizzative, infatti viene scambiata ed elaborata; è immateriale, non è facilmente divisibile, può essere soggetta ad obsolescenza e si autorigenera.
	
	La capacità autorigenerativa dell'informazione permette di instaurare circoli virtuosi di generatori di conoscenza e di arricchimento delle informazioni disponibili, che si traducono in un incremento dei processi produttivi.
	
	\paragraph{Overload e underload informativo.} L'\textit{overload informativo} è un aumento incontrollato dell'informazione disponibile, che eccede la capacità di elaborazione individuale, con conseguente rallentamento nell'elaborazione. L'\textit{underload informativo} è invece una disponibilità di informazione al di sotto delle capacità individuali, con conseguente presa di decisioni in tempi brevi.
	
	\subsection{Sistemi informativi verticali e orizzontali}
	I sistemi informativi possono essere immaginati a due versi. 
	
	I sistemi informativi verticali sono stati i primi ad essere supportati dai sistemi informatici, tuttavia al crescere dell'incertezza i vertici sono sovraccaricati dai compiti decisionali. 
	
	I sistemi informativi orizzontali invece sono costruiti sulla delega delle decisioni e sui collegamenti sullo stesso layer che aumentano la capacità elaborativa (team di lavoro, task force).
	
	\section{Classificazione dei sistemi informativi}
	Vi sono varie possibili classificazioni dei sistemi informativi, ovvero: \begin{itemize}
		\item tipologie di SI disposti lungo la piramide aziendale (definizioni e funzioni attribuite a seconda del loro livello nella piramide);
		\item tipologie di SI diposti nelle varie aree gestionali dell'impresa.
	\end{itemize}

	\subsection{SI disposti lungo la piramide aziendale}
	I SI disposti lungo la piramide di Anthony sono i seguenti:
	\begin{enumerate}
		\item \textit{Transaction Processing Systems (TPS)}: gestione delle transazioni, quali ordini ecc. Sono alla base della piramide;
		
		\item \textit{Management Information Systems (MIS)}: sono al livello immediatamente sopra ai TPS e rappresentano periodicamente le informazioni raccolte dai TPS. Sono alla base del sistema di reportistica delle aziende;
		
		\item \textit{Decision Support Systems (DSS)}: affiancano il management delle decisioni di non routine e permettono di simulare ipotesi per verificare la validità di una gestione.
		
		\item \textit{Executive Information Systems (EIS)}: sono al vertice della gerarchia, aiutano i senior manager alla gestione.
	\end{enumerate}
	
	\subsection{Portafoglio applicativo}
	Il portafoglio applicativo è l'insieme delle applicazioni utili in azienda. È diviso in 3 segmenti principali: \begin{itemize}
		\item Portafoglio direzionale: insieme delle applicazioni informatiche a supporto dei cicli di pianificazione strategica;
		
		\item Portafoglio istituzionale: applicazioni informatiche per i processi di supporto all’amministrazione;
		
		\item Portafoglio operativo: applicazioni informatiche per i processi primari dell’azienda.
	\end{itemize}

	Il portafoglio istituzionale è un'area con elevate potenzialità di informatizzazione, a causa dei grandi volumi di dati che li coinvolgono e la forte proceduralità. Come conseguenza si hanno riduzioni nei tempi e nei costi di elaborazione, inoltre la pianificazione risulta più efficace.
	
	Il portafoglio operativo contiene le applicazioni informatiche necessarie ai procedimenti coinvolti nella catena del valore di Porter, ossia: \\
	
	Gestione materie prime \chainto Trasformazione \chainto Vendita \chainto Distribuzione \chainto Postvendita \\
	
	ovvero la catena di azioni finalizzate a produrre valore per il cliente. Il portafoglio applicativo ovviamente è specifico di ogni settore industriale, e comporta un aumento della complessità gestibile nei processi aziendali, permettendo inoltre la sincronizzazione dei dati in un'azienda (basi di dati condivise).
	
	Il portafoglio applicativo è andato informatizzandosi col passare degli anni, a cominciare dalle procedure per automatizzare attività singole, ai pacchetti MRP (Manufacturing Resource Planning), che contenevano i primi database e pacchetti integrati, ai CIM (Computer Integrated Manifacturing), che automatizzano interi segmenti produttivi, ai sistemi ERP (Enterprise Resource Planning) che consentono di gestire ogni fase produttiva e sfruttano architetture client-server e pacchetti integrati con un unico modello dati.
	
	Negli ultimi anni sono andati sviluppandosi i sistemi CRM (Customer Relationship Management), che forniscono interi cicli di assistenza al cliente, gestioni avanzate di distribuzione, vendita e postvendita. Negli anni 2000 si è sviluppato l'E-Procurement, ovvero l'informatizzazione del buy-side delle imprese, e utilizza pacchetti per l'intero ciclo di acquisto e architetture basate su tecnologie web.
	
	\section{Ingegneria Sociale}
	Definizione di Ingegneria Sociale a caldo:\begin{definit}[Ingegneria Sociale]
		Manipolazione della naturale tendenza alla fiducia dell’essere umano, architettata e realizzata dall’ingegnere sociale con l’obiettivo ottenere informazioni che permettano libero accesso e informazioni di valore del sistema.
	\end{definit}

	La figura dell'ingegnere sociale mira a stabilire confidenza con la vittima, sviluppando ogni possibile scenario di difficoltà e preparandosi ad evaderlo. Prima di tutto ciò viene la fase di \textit{footprinting}, ovvero di raccolta delle informazioni, l'analisi dell'azienda, dei suoi sistemi di comunicazione, della posta, ecc. I primi ingegneri sociali furono i \textit{phreaker}, che utilizzavano la rete telefonica sfruttando i sistemi e i dipendenti dell'azienda per arrivare a dati sensibili.
	
	La falla da sfruttare è quindi data da operatori umani, che spesso gestiscono le informazioni sensibili ma ignorano le procedure di sicurezza, magari non sono nemmeno consapevoli delle informazioni che stanno gestendo e che dovrebbero custodire. 
	Ovviamente le vittime perfette per un attacco di ingegneria soociale sono le persone che non hanno nulla da perdere nel fornire informazioni sensibili, che sottostimano il valore delle informazioni, sottostimano le procedure di sicurezza oppure che non valutano le conseguenze delle proprie azioni.
	
	\subsection{Attacco tipico di Ingegneria Sociale}
	\paragraph{Fasi di un attacco di SE.} Un generico attacco di SE si svolge nel seguente modo: \begin{itemize}
		\item una fase fisica di raccolta di informazioni attraverso persone, documenti e luoghi;
		\item una fase psicologica di impersonificazione e persuasione del personale adatto ad essere una tipica vittima
	\end{itemize}

	\paragraph{Fase fisica.} Gli strumenti essenziali alla fase fisica sono gli strumenti di comunicazione più disparati. L'obiettivo di questa fase sono password, server e router, e si possono raggiungere tramite una giusta combo di uso della tecnologia (phishing, lancio di malware, ...) e interazione col personale (truffe telefoniche, dumpster diving, rovistare negli hdd dismessi...).
	
	\paragraph{Fase psicologica.} È necessario fare leva sulla fiducia che una persona è per inclinazione disposta a concedere, facendo leva sui bisogni primari dell'uomo (fisiologici, di sicurezza, ecc.), secondo la gerarchia di Maslow. 
	
	Gli attacchi di social engeneering sfruttano quindi le debolezze della persona singola, ossia la disponibilità e la fede che una persona è disposta ad affidare ad un possibile attaccante.
	
	 \begin{definit}[Phishing]
		Tecnica di ingegneria sociale basata sul principio della supposta autorità che utilizza un messaggio di posta elettronica per acquisire informazioni personali riservate (password, dati finanziari, numero di carta di credito) con la finalità del furto di identità.
	\end{definit}

	Il phishing è basato sul concetto di \textit{mail spoofing}, ossia sull'inviare mail a nomi di terzi, per il semplice motivo che la persona che manda la mail non è autenticata dal server di posta elettronica.
	
	\section{Ingegneria dei processi gestionali}
	
	I processi rappresentano il modo di operare in un'azienda. Dal momento che le tecnologie informatiche modificano il modo di operare in un'azienda, è necessario il processo di \textbf{Business Process Reengineering} (BPR), che mette in correlazione l'innovazione dei processi e dell'organizzazione aziendale tramite l'uso di strumenti informatici.
	
	I processi possono essere materiali, informativi, oppure \textbf{Business Process}, ovvero un insieme di attività finalizzato alla realizzazione dell'interesse dell'azienda. In generale un processo aziendale è formato da attività, che, partendo da input definiti, producono l'output richiesto dal cliente.  I processi sono flussi di attività che concatenano marketing, produzione e approvigionamento. 
	
	Un business process è un processo costituito da 4 elementi: \begin{itemize}
		\item attività;
		\item input (materiali o risorse di partenza);
		\item output (oggetti, materiali, servizi in uscita);
		\item clienti.
	\end{itemize}

	Considerando come è definito un processo, un'azienda è facilmente costituibile come un processo (catena del valore di Porter). La catena del valore di Porter è suddivisibile in 3 macro-strategie: una \textit{buy-side} (acquisizione delle risorse), \textit{in-side} (trasformazione delle risorse) e \textit{sell-side} (vendita, distribuzione, postvendita).
	
	\paragraph{Strategia buy-side.} Include il rapporto con i fornitori, con una potenziale riduzione dei costi del materiale stesso. La strategia buy-side si appoggia ai sistemi di e-procurement, infrastrutture internet, mercati elettronici.
	
	\paragraph{Strategia in-side.} È mirata alla trasformazione dei processi interni dell'azienda. Questa strategia può arrivare  ridurre il costo 	di funzionamento dei processi e migliorare il rapporto con il cliente. È appoggiata principalmente ai sistemi ERP.
	
	\paragraph{Strategia sell-side.}È orientata ai processi di marketing, vendita e distribuzione dei prodotti. La trasformazione dei processi si appoggia ai sistemi CRM e comporta un maggiore valore del prodotto percepito dal cliente e un abbattimento dei costi di produzione. 
	
	\subsection{Classificazione dei processi}
	I processi sono classificabili nelle seguenti categorie: \begin{itemize}
		\item \textit{intersettoriali:} gestiscono le pratiche di molteplici settori;
		\item \textit{settoriali:} distinguono i vari settori;
		\item \textit{aziendali:} processi di una specifica azienda o di una sua parte;
		\item \textit{normativi e best-practice:} sono processi di riferimento e di giuda su come gli altri processi dovrebbero essere nelle aziende del settore.
	\end{itemize}

	Ogni processo è scomposto (dal macro al micro) nelle seguenti fasi: \begin{itemize}
		\item \textit{Macroprocesso}: constituisce il primo livello di segmentazione dell'azienda, la catena del valore di Porter ne è un'esempio;
		\item \textit{Processo}: illustrano il modo di operare dell'azienda;
		\item \textit{Fase}: illustrano il modo in cui il processo è implementato (una fase è una tappa del processo);
		\item \textit{Attività}: livello minimo di analisi normalmente adottato nello studio dei processi, sono operazioni fatte da singoli o pochi;
		\item \textit{Operazione}: passi elementari necessari per eseguire una data attività (mai usate).
	\end{itemize}

	\subsection{Griglia metodologica}
	
	La griglia metodologica è uno strumento di supporto alla progettazione dei processi. Questa metodologia comprende\begin{itemize}
		\item Descrizione delle variabili di analisi;
		\item Descrizione delle fasi di analisi;
		\item Identificazione degli strumenti di supporto alle analisi.
	\end{itemize}

	\subsubsection{Variabili organizzative}
	La trasformazione dei processi per avere successo deve ruotare intorno ai perni dell'innovazione tecnologiche e organizzative. Le variabili organizzative sono i punti su cui bisogna lavorare per ottenere un successo (almeno teoricamente). Le variabili sono le seguenti: \begin{itemize}
		\item Flusso delle attività: sequenza di attività attraverso le quali il processo è svolto;
		\item Organizzazione del processo: è la divisione operativa del processo e come i singoli compiti sono mappati sui ruoli ;
		\item Competenza delle risorse umane che operano nel processo.
	\end{itemize}
	
	\paragraph{Flussi di attività.} Il flusso delle attività determina la durata del processo, il livello di servizio e la qualità del prodotto. La modellazione dei flussi può essere ricondotta a diversi schemi: schemi di sequenza (che raccolgono solamente i caratteri delle attività da svolgere) oppure altri flussi più ricchi (che raccolgono altre variabili ma sono più complessi da realizzare).
	
	\paragraph{Organizzazione.} L'organizzazione è una variabile fondamentale nella fase di descrizione dei processi. Per descrivere un'organizzazione si possono utilizzare organigrammi, tabelle di proprietà e Linear Responsibility Charting (LRC). Le tabelle di proprietà sono delle tavole che elencano, per ogni organo aziendale, i compiti devoluti a tale organo, i processi svolti, gli organici ecc.
	
	I Linear Responsibility Charting offre una visione tabellare delle reponsabilità organizzative. Lo scopo è, per ogni processo, identificare il ruolo svolto da ogni struttura aziendale (ruolo che può essere decisionale, esecutivo, di supporto...). 
	
	\paragraph{Risorse umane.} Le risorse umane determinano la differenza tra il risultato effettivo di un processo e il massimo risultato teoricamente possibile in una data configurazione. Ovviamente l'innovazione tecnologica porta alla necessità di avere un insieme di figure altamente specializzate, acquisite dal mercato oppure anche riformando le figure già esistenti.
	
	\paragraph{Analisi delle prestazioni.} Ogni processo è valutato con un sistema di analisi delle prestazioni, comprendente: \begin{itemize}
		\item Pianificazione e controllo che fissa gli obiettivi di efficacia ed efficienza del metodo;
		\item Incentivazione e promozione che fissa gli obiettivi del processo e valuta il lavoro del singolo;
		\item Sistema dei valori che descrive gli obiettivi generali dell'azienda e decide i valori da incentivare nel lavoro (soddisfazione del cliente, produttività, ecc.).
	\end{itemize}

	\subsection{Analisi dei processi}
	La metodologia di analisi dei processi è divisa in molteplici fasi. Gli approcci sono 2:
	\begin{itemize}
		\item \textit{bottom-up}: ridisegno dei processi basato sul confronto con altre aziende;
		\item \textit{top-down}: dati dei criteri di ottimizzazione, si lavora al disegno del processo seguendo tali criteri.
	\end{itemize}

	Alla base di entrambi gli approcci è necessario analizzare la situazione esistente, attraversando una fase preliminare di analisi della situazione di partenza, attraverso i passaggi di:
	\begin{enumerate}
		\item Identificazione dei processi (input, output, tipo, clienti del processo);
		\item Dettagli del processo (diagrammi gerarchici, diagrammi di flusso, schede che descrivono le proprietà dei processi)
		\item Incrocio processi/Unità organizzative (rilevazione delle strutture e dei ruoli, mappatura delle attività del processo);
		\item Valutazione del processo (definizione dei parametri di funzionamento, giudizio sul valore dei prodotti, sia da parte del cliente che degli esecutori).
	\end{enumerate}

	La fase successiva dell'analisi di un processo è composta dalle seguenti fasi: \begin{itemize}
		\item Confronto quantitativo e parametrizzazione (confronto tra aziende concorrenti);
		\item Confronto qualitativo (analisi delle divesità rispetto ai valori di mercato).
	\end{itemize}

	La terza ed ultima fase dell'analisi di un processo è data dalla \textbf{ridefinizione} del processo, ossia della \textit{vision} che da una rappresentazione degli elementi fondamentali della soluzione proposta, solitamente basata su degli schemi best-practice.
	
	La trasformazione dei processi, dovuta in larga parte all'applicazione di tecnologie informatiche, ha come effetto primario l’integrazione inter-funzionale o inter-organizzativa dei processi, in quanto aumenta al disponibilità di informazioni e supporta l'esecuzione di compiti individuali di natura decisionale.
	
	\newpage
	\section{Data warehouse}
	\subsection{Introduzione}
	Iniziamo dando la definizione di \textit{business intelligence}.
	
	\begin{definit}[Business Intelligence]
		Disciplina che consente a chi deve decidere in azienda di capire, attraverso soluzioni software, i fattori chiave del business e conseguentemente di prendere le migliori decisioni in quel momento.
	\end{definit}

	Sostanzialmente il ruolo chiave della business intelligence è quello di trasformare i dati aziendali in informazioni fruibili in maniera semplice, con un livello di dettaglio variabile.
	
	Il passaggio da grandi moli di dati ad informazioni importanti e di un certo rilievo è operato dall'informatica, dal momento che negli ultimi anni le moli di dati sono diventate davvero enormi. A partire dagli anni 80 infatti iniziano a nascere i \textit{decision support systems} (DSS), ovvero un insieme di tecniche e strumenti che consentono di estrapolare informazioni a partire da dati grezzi.
	
	Qui nasce il data warehouse, ovvero un raccoglitore di informazioni che riorganizza i dati provenienti dalle sorgenti più disparate e li rende disponibili per analisi e valutazioni finalizzate alla pianificazione del processo decisionale.
	
	\begin{definit}[Data Warehouse]
		Una collezione di metodi, tecnologie e strumenti di ausilio al knowledge worker per condurre analisi dei dati finalizzate all’attuazione di processi decisionali e al miglioramento del patrimonio informativo.
	\end{definit}
	
	Le interrogazione al data warehouse sono di due tipologie:
	\begin{itemize}
		\item \textit{OLAP (OnLine Analitycal Processing)}: interrogazioni di tipo analitico, leggono grandi quantità di record e calcolano dati di sintesi;
		\item \textit{OLTP (OnLine Transactional Processing)}: interrogazioni di tipo transazionale, dove vengono letti e modificati piccoli gruppi di record.
	\end{itemize}

	Il processo di data warehousing presenta alcune caratteristiche fondamentali, quali: \begin{itemize}
		\item accessibilità ad utenti sprovvisti di particolari conoscenze informatiche;
		\item integrazione dei dati sulla base di un modello standard dell'impresa;
		\item flessibilità di interrogazione;
		\item sintesi per permettere analisi quanto più possibili efficaci;
		\item rappresentazione quanto più intuitiva possibile;
		\item completezza e correttezza dei dati manipolati.
	\end{itemize}

	\subsection{Architetture di supporto}
	Le architetture di supporto al DW devono soddisfare alcuni requisiti fondamentali: \begin{itemize}
		\item \textit{separazione}: tra elaborazione analitica e transazionale;
		\item \textit{scalabilità}: le dimensioni e le performance dell'architettura devono poter scalare bene con l'aumento della dimensione della mole di dati;
		\item \textit{estendibilità}: deve essere possibile estendere il sistema con nuove tecnologie senza doverlo riprogettare del tutto;
		\item \textit{sicurezza}: relativamente al controllo degli accessi;
		\item \textit{amministrabilità}: la complessità dell'attività di amministrazione non deve risultare eccessiva.
	\end{itemize}

	\paragraph{Architetture a un livello.} L'unico intermezzo tra gli strumenti di utility (reportistica, OLAP) è il middleware.

	\paragraph{Architetture a 2 livelli.} Le architetture a 2 livelli sono strutturate in maniera differente, in quanto ci sono anche i livelli di alimentazione e di warehouse. La particolarità di questa architettura è data dai \textit{data mart}, ovvero un sottoinsieme del data warehouse principale, relativi a sezioni particolari dell'azienda. I data mart sono utili come blocchi costruttivi del DW principale, inoltre, essendo di dimensioni minori, consentono migliori prestazioni.
	
	In alcuni casi si preferisce un'architettura con i data mart indipendenti dal DW primario, il che semplifica la progettazione ma rende lo schema più complesso a livello di accesso ai dati, e può determinare inconsistenze tra data mart.
	
	Le architetture a 2 livelli presentano sostanziali vantaggi, quali: \begin{itemize}
		\item a livello del DW sono sempre disponibili informazioni, anche se alle sorgenti non lo sono;
		\item l'interrogazione analitica sul DW non interferisce con quelle transazionali sul database operazionale;
		\item l'organizzazione logica del DW è multidimensionale, non relazionale o semistrutturata;
		\item a livello del DW sono ottimizzabili le interrogazioni ed in generale le prestazioni.
	\end{itemize}

	\paragraph{Architetture a 3 livelli.} Hanno in più i dati \textit{riconciliati}, che sono ottenuti dopo una serie di controlli di consistenza e pulizia. Il vantaggio dei dati riconciliati è che forniscono un modello unico, eliminando le problematiche per l'azienda di estrazione dei dati dalle sorgenti. D'altro canto, si introduce un elemento di ridondanza con i dati della sorgente.
	
	\subsection{ETL (Extraction, Transformation, Loading)}
	Il ruolo degli strumenti ETL è quello di alimentare una sorgente dati di buona qualità che possa a sua volta alimentare il DW (\textit{riconciliazione}). La riconciliazione avviene in due momenti distinti, ovvero quando il DW viene popolato per la prima volta e quando viene aggiornato periodicamente.
	
	Gli strumenti ETL operano attraverso 4 fasi: \begin{enumerate}
		\item \textbf{estrazione}: l'estrazione \textit{statica} viene fatta quando il DW viene popolato per la prima volta, quella \textit{incrementale} viene fatta dopo ogni aggiornamento, basandosi su cosa è cambiato nel frattempo;
		\item \textbf{pulitura}: si migliora la qualità dei dati da elaborare, rimuovendo dati mancanti, duplicati e incosistenze;
		\item \textbf{trasformazione}: conversione dei dati dal formato operazionale a quello del DW, i dati vengono normalizzati, convertiti nei formati supportati dal DW, e vengono sintetizzati;
		\item \textbf{caricamento}: i dati vengono importati nel DW con il \textit{refresh} (riscrittura totale dei dati) o con l' \textit{update}, quando si devono fare aggiornamenti controllati e di dimensioni ridotte.
	\end{enumerate}
	
	\subsection{Il modello multidimensionale}
	È il modello fondamentale per la rappresentazione e l'interrogazione ai dati. È strutturato su un cubo i cui lati sono una dimensione dei dati da analizzare, ogni cella contiene la misura numerica da analizzare.
	
	\subsection{Tecniche di analisi dei dati}
	Una volta che i dati sono stati trasformati e ripuliti, occorre scoprire come trarne il massimo vantaggio informativo. Esistono 3 differenti approcci: \begin{itemize}
		\item data mining;
		\item reportistica;
		\item OLAP.
	\end{itemize}

	\paragraph{OLAP.} È il principale metodo di analisi dei dati in un modello multidimensionale. È estremamente dettagliato grazie alla specifica di un percorso di navigazione, ossia un path di operatori che prendono in input il risultato dell'interrogazione precedente. Ogni risultato di interrogazione è ancora un modello multidimensionale. Gli operatori sono: \begin{itemize}
		\item roll up;
		\item drill down;
		\item slice and dice;
		\item pivoting;
		\item drill across.
	\end{itemize}

	\paragraph{Data Mining.} È un'attività orientata alla scoperta di dati nascosti, in particolare quando la mole di dati è molto grande. Il data mining raccoglie tecniche di machine learning e AI al fine di ricercare caratteri particolari a partire dalla mole di dati, quali:\begin{itemize}
		\item ricerche di mercato;
		\item efficacia del marketing;
		\item pianificazione aziendale e di investimenti;
		\item riconoscimento di attività fraudolente.
	\end{itemize}

	Un elemento fondamentale del data mining è dato dalle \textbf{regole associative}, ossia un insieme di regole che consentono di stabilire delle relazioni di implicazione all'interno della base di dati (gruppi di affinità). In tal modo è possibile costruire pubblicità mirate, ad esempio.
	Altri caratteri fondamentali del data mining sono:\begin{itemize}
		\item \textit{clustering:} raggruppamento di oggetti per carattere comune in un ridotto numero di insiemi;
		\item \textit{alberi decisionali:} alberi di decisione per la classificazione dei rapporti di causa effetto di un dato evento;
		\item \textit{serie temporali:} individuazione di pattern ricorrenti in sequenze di dati complesse (rilevazione di anomalie, analisi di percorsi web, ecc...).
	\end{itemize}

	\section{Ciclo di vita del Data Warehouse}
	
	\paragraph{Generazione del DW.} Nella generazione del DW si distinguono 2 approcci: \begin{itemize}
		\item \textit{top-down}: basato sull'analisi dei bisogni dell'azienda, per poi realizzare il DW nella sua interezza, ha costi onerosi e lunghi tempi di realizzazione, ma garantisce ottimi risultati;
		\item \textit{bottom-up}: la costruzione avviene in maniera incrementale, ha costi ridotti e tempi di realizzazione brevi, ma determina una visione parziale del dominio di interesse.
	\end{itemize}

	Qualunque sia l'approccio scelto, si segue sempre il path del tipo: \begin{enumerate}
		\item Pianificazione;
		\item Progettazione dell'infrastruttura;
		\item Progettazione e sviluppo del data mart.
	\end{enumerate}

	\paragraph{Analisi e riconciliazione delle sorgenti.} L'analisi e la riconciliazione delle sorgenti attraversa 2 fasi, la \textit{ricognizione} e la \textit{normalizzazione}.
	
	Vi è prima la fase di \textit{integrazione}, ovvero l'analisi delle sorgenti e il mapping, ovvero la correlazione di concetti delle sorgenti a schemi del nostro DW. La fase di integrazione è divisa in 4 step, ossia: \begin{enumerate}
		\item \textit{Preintegrazione: } definizione della strategia di integrazione;
		\item \textit{Comparazione degli schemi}: analisi degli schemi iniziali per identificare conflitti e correlazioni tra concetti;
		\item \textit{Allineamento degli schemi:} risoluzione dei conflitti rilevati precedentemente;
		\item \textit{Fusione degli schemi:} si fondono gli schemi ottenuti con lo scopo di formare un unico schema riconciliato.
	\end{enumerate}

	\paragraph{Analisi dei requisiti.} Lo scopo di tale analisi è quello di raccogliere le esigenze di utilizzo del data mart.
	L'analisi dei requisiti è un processo fondamentale in quanto influenze le decisioni riguardanti la progettazione del database, l'architettura del sistema, i piani di avviamento e manutenzione.
	
	\subsection{Progettazione concettuale}
	Al contrario dei database relazionali, per modellare il DW non è applicabile il modello ER standard, ma viene usato il DFM (\textit{Dimensional Fact Model}). La rappresentazione con il DFM prevede i seguenti costrutti di base: \begin{itemize}
		\item \textit{fatto}: è un concetto di interesse per il processo decisionale, modella un insieme di eventi che accadono nell'azienda (costituisce inoltre una relazione molti-a-molti tra le dimensioni);
		\item \textit{misura}: è un valore numerico relativo ad un fatto e ne esprime un aspetto quantitativo per l'analisi;
		\item \textit{dimensione:} è una proprietà con un dominio finito di un fatto; ne descrive una coordinata di analisi;
		\item \textit{attributi dimensionali:} si intendono le caratteristiche che descrivono una data dimensione;
		\item \textit{gerarchia:} è un albero orientato i cui nodi sono attributi dimensionali; modellano associazioni tra coppie di attributi.
	\end{itemize}

	Il DFM prevede inoltre una serie di attributi avanzati, relativamente poco usati, quali convergenze, additività, dimensioni/attributi opzionali, gerarchie condivise, ecc.
	
	La progettazione concettuale avviene partendo dalla documentazione relativa ai dati riconciliati, quali modelli ER, schemi XML, ecc. La progettazione avviene seguendo i seguenti passi: \begin{enumerate}
		\item Definizione dei fatti;
		\item Per ogni fatto: \begin{enumerate}
			\item Costruzione dell'albero degli attributi ed editing;
			\item Definizioni di dimensioni e misure;
			\item Creazione dello schema di fatto.
		\end{enumerate}
	\end{enumerate}
	
	L’albero degli attributi corrispondente a F può essere costruito in modo automatico applicando una procedura che naviga ricorsivamente le dipendenze funzionali espresse, nello schema sorgente, dagli identificatori e dalle associazioni a-uno.
	
	\paragraph{Editing dell'albero.} Dal momento che non tutti gli attributi sono di interesse per il data-mart, l'albero è manipolabile eliminando alcuni nodi secondo alcune regole di consistenza. La \textbf{potatura} di un ramo avviene eliminando il nodo radice e tutti i relativi figli, l'\textbf{innesto} avviene quando un nodo non è necessario ma serve mantenere i suoi nodi figlio.
	
	\paragraph{Definizione delle dimensioni.} Vanno scelte nell'albero degli attributi tra i vertici figli della radice. La loro scelta è rilevante in quanto definiscono la granularità degli eventi primari. Nota: il tempo dovrebbe sempre essere una dimensione.
	
	\subsubsection{Carico di lavoro e volume dati}
	Il carico di lavoro di un sistema OLAP è estemporaneo, e va identificato in fase di progettazione, sulla base della reportistica standard e dei colloqui con gli utenti.
	
	Una volta desunto il carico di lavoro del DW attraverso un qualche log di sistema, è possibile attuare una fase di \textit{tuning} del sistema, ossia una specie di ottimizzazione.
	
	\paragraph{Problema della sparsità.} Il problema della sparsità dei dati è un difetto del modello multidimensionale che consiste nell'avere coordinate su un evento che potrebbe anche non verificarsi. Tutto ciò comporta uno spreco di risorse, ovviamente. Le alternative per ovviare/attenuare il problema sono 2: \begin{itemize}
		\item ROLAP: tiene traccia solo degli eventi realmente accaduti;
		\item MOLAP: riduzione al minimo dello spazio necessario a tenere traccia degli eventi non accaduti.
	\end{itemize}

	\subsection{Progettazione logica}
	I modelli logici generali per la progettazione logica sono 2:\begin{itemize}
		\item MOLAP (Multidimensional Online Analytical Processing) utilizzano strutture multidimensionali (array multidimensionali), rappresentano soluzioni che non necessitano di istruzioni complesse in SQL, ma non hanno strutture dati standard. Gestisce la sparsità usando tecniche di compressione dei chunk in modo tale da non sprecare spazio per rappresentare dati sparsi;
		
		\item ROLAP (Relational Online Analytical Processing) usano semplicemente il modello relazionale. Il modello ROLAP usa uno schema a stella.
	\end{itemize}

	\paragraph{Schema a stella.} Uno schema a stella è uno schema caratterizzato da: \begin{itemize}
		\item Un insieme di relazioni $DT_1, DT_2, \dots, DT_n$ ognuna delle quali contiene una chiave primaria e il relativo insieme di attributi;
		
		\item Una \textit{fact table} $FT$, che importa le chiavi di tutte le dimension table.
	\end{itemize}

	Lo schema a stella è vantaggioso in quanto è necessario un solo join per recuperare le informazioni in tutte le dimensin table, inoltre non ha problemi di sparsità in quanto vengono memorizzate solo le tuple corrispondenti a punti dello spazio per il quale si sono verificati eventi.
	
	\paragraph{Schema snowflake.} Lo snowflake schema è una variante dello schema a stella in cui le DT hanno una chiave e un sottoinsieme di attributi che ne dipendono. Inoltre hanno 0 o più chiavi importate da altre DT necessarie alla ricostruzione del contenuto della DT iniziale. La FT contiene solo le chiavi di alcune DT (\textit{DT primarie}), mentre non contiene quelle delle DT secondarie.
	
	I principali vantaggi dello snowflake schema sono la semplificazione delle interrogazioni e la comodità in presenza di dati aggregati, tuttavia è necessario inserire le chiavi surrogate, e il tempo di interrogazione aumenta data la necessità di dover fare join multipli.
	
	\subsubsection{Viste}
	Le viste sono in sostanza le fact table contenenti dati aggregati di sintesi. Si distinguono in 2 categorie: \begin{itemize}
		\item \textit{primarie:} corrispondono al pattern di aggregazione primario (non aggregato);
		\item \textit{secondarie:} corrispondono a pattern di aggregazione secondari (aggregati).
	\end{itemize}

	La presenza di fact table multipli pone il problema di costruire la vista che risolve l'interrogazione da fare con il minor costo possibile. A tale scopo sono usati gli \textit{aggregate navigator}, ossia dei software specifici che si occupano di formulare interrogazioni OLAP sulla miglior vista a disposizione.
	
	Il passaggio dal progetto concettuale a quello logico funziona attraverso 4 fasi:\begin{enumerate}
		\item Scelta dello schema da utilizzare;
		\item Traduzione degli schemi concettuali;
		\item Scelta delle viste;
		\item Applicazione di altre forme di ottimizzazione (frammentazione).
	\end{enumerate}

	La traduzione da schema di fatto a schema a stella avviene semplicemente creando una FT contenente tutte le misure e gli attributi descrittivi collegati direttamente con il fatto e per ogni gerarchia creare una DT che ne contenga tutti gli attributi.
	
	\paragraph{Scelta delle viste.} La scelta delle viste è un task complesso, che deve tenere conto di numerosi fattori, quali:\begin{itemize}
		\item Minimizzazione delle funzioni di costo;
		\item Vincoli di sistema;
		\item Vincoli dell'utente.
	\end{itemize}

	In generale conviene materializzare una vista quando risolve un'interrogazione molto frequente, oppure riduce il costo di esecuzione di molte interrograzioni. Viceversa, non conviene quando il suo pattern di aggregazione è molto simile a quello di altre viste già materializzate, oppure non riduce di almeno un ordine di grandezza il costo dell'interrogazione.
	
	\subsection{Progettazione dell'alimentazione.} È la fase in cui vengono progettate le procedure necessarie al caricamento dei dati nel data mart. 
	
	\paragraph{Estrazione dei dati.} In particolare, l'estrazione dei dati può essere effettuata: \begin{itemize}
		\item In maniera assistita dall'applicazione;
		\item Tramite log;
		\item Tramite trigger;
		\item Tramite marche temporali.
	\end{itemize}
	
	In ogni caso, i dati estratti consistono di tutti i record che non sono stati estratti nell'ultima operazione di estrazione, e vengono messi nella staging area.
	
	\paragraph{Caricamento dei dati.} La modalità di caricamento dei dati nella staging area dipende dal tipo di estrazione e dalla storicizzazione del database. Se l'estrazione è completa, allora la riscrittura del data mart sarà totale; se l'estrazione è incrementale si salva anche il tipo di operazione che ha determinato la variazione del dato. In presenza di storicizzazione si salva anche una coppia di marche temporali indicanti l'intervallo di validità della tupla.
	
	\paragraph{Pulizia dei dati.} È l'insieme delle operazioni atto a fixare le incompatibilità tra i vari dati, quali errori di battitura, incompatibiltà di formati, inconsistenza di valori, ecc. Le tecniche utilizzate spaziano dai dizionari (tabelle di look-up) , join approssimati o regole di dominio specifiche.
	
	\paragraph{Alimentazione delle table.} L'alimentazione delle dimension table viene svolta semplicemente trasformando gli identificatori in chiavi surrogate. 
	
	

	
	
	
	
	
	
	
	
	
	
	
\end{document}