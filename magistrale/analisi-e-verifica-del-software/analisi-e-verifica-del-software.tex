\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[italian]{babel}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{listings}
\usepackage{booktabs}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{stmaryrd}
\usepackage[strict]{changepage}
\usepackage{galois}
\usepackage{multicol}
\usepackage{float}
\usepackage{textcomp}
\usepackage{makecell}
\usepackage{graphicx}

\hypersetup{hidelinks}

\graphicspath{{images}}

\newcommand{\code}[1]{\textup{\lstinline{#1}}}
\newcommand{\parts}[1]{\mathcal{P}(#1)}
\newcommand{\galoistuple}{\langle C, \alpha, \gamma , A \rangle}
\newcommand{\sem}[1]{\llbracket #1 \rrbracket (\rho, \mu)}

\newtheorem{definit}{Definizione}[subsection]
\newtheorem{thm}{Teorema}[subsection]

\begin{document}
    \clearpage

    \begin{titlepage}
        \centering
        \vspace*{\fill}
        {\scshape\LARGE Università degli Studi di Verona \par}
        \vspace{1.5cm}
        \line(1,0){340} \\
        {\huge\bfseries Fondamenti di Analisi e Verifica del Software \par}
        \line(1,0){340} \\
        \vspace{0.5cm}
        {\scshape\LARGE Dispensa del Corso \par}
        \vspace{2cm}
        {\Large\itshape Mattia Zorzan \par}
        {\Large\itshape Davide Bianchi \par}
        {\Large\itshape Marco Colognese \par}
        {\Large\itshape Mattia Rossini \par}
        \vspace{1cm}

        \vspace{5cm}
        \vspace*{\fill}
        {\large \today \par}
    \end{titlepage}
    \thispagestyle{empty}
    \newpage
    \tableofcontents
    \thispagestyle{empty}
    \newpage

    \section{Introduzione}
        Diamo la definizione di semantica:
        \paragraph{Semantica.} Una descrizione (tipicamente formale) del comportamento a \textit{tempo di esecuzione} di un programma.\\
        \\   
        Da questo definiamo \textbf{proprietà semantica} qualsiasi proprietà che riguardi il comportamento a tempo di esecuzione di un dato programma.\\
        L'idea alla base di tutto è quella di \textit{automatizzare} l'analisi di queste proprietà, per fare questo sarà necessario \textit{rilassare} l'analisi ammettendo la possibilità di ottenere risultati \textbf{inaccurati}. 

    \section{Linguaggio e semantica}
        Introduciamo in questa sezione il linguaggio che verrà usato nel resto della dispensa e la sua semantica.

        \begin{center}
            \begin{tabular}{cc}
                \hline
                \textbf{Statement} & \textbf{Codice} \\
                \hline
                \hline
                Variabili & \lstinline|x| \\
                Espressioni aritmetiche & \lstinline|e| \\
                Assegnamenti & $x \leftarrow e$ \\
                Condizionali & \lstinline|if (e) S|$_1$ \lstinline|else S|$_2$ \\
                \hline
            \end{tabular}
        \end{center}

        \subsection{Control Flow Graph (CFG)}
            E costituito da:
            \begin{itemize}
                \item \textbf{nodi}: corrispondono ai \textit{program points};
                \item \textbf{archi}: passi di computazione etichettati con la corrispondente azione; sono della forma $K=(u, lab, v)$, dove $u$ è il nodo sorgente, $v$ è il nodo di destinazione e $lab$ è l'etichetta.
            \end{itemize}	
            \begin{center}
                \begin{tabular}{cc}
                    \hline
                    \textbf{Statement} & \textbf{Label} \\
                    \hline
                    \hline
                    Test & $NonZero(e)$ or $Zero(e)$ \\
                    Assegnamenti & $x \leftarrow e$ \\
                    Input & $ input(x) $ \\
                    Statement vuoto & $;$ \\
                    \hline
                \end{tabular}
            \end{center}
            Ognuno di questi statement produce un \textit{effetto}:
            \begin{itemize}
                \item $ \llbracket ; \rrbracket (m) = m $
                \item $ \llbracket NonZero(e) \rrbracket (m) = m $ \textbf{if} $ \llbracket e \rrbracket (m) $ = \textbf{true}
                \item $ \llbracket Zero(e) \rrbracket (m) = m $ \textbf{if} $ \llbracket e \rrbracket (m) $ = \textbf{false}
                \item $ \llbracket x \gets e \rrbracket (m) = m[x \mapsto \llbracket e \rrbracket (m)] $
                \item $ \llbracket input(x) \rrbracket (m) = m[x \mapsto m(x)] $
            \end{itemize}
            \newtheorem*{definit1}{Basic Block}
            \begin{definit1}
                Sequenza massima di statements consecutivi con un singolo \textit{entry point}, un singolo \textit{exit point} e nessun \textit{branch} interno.
            \end{definit1}
            I \textit{basic block} si identificano facilmente poiché iniziano con un \textit{leader} che può essere dei seguenti tipi:
            \begin{itemize}
                \item l'\textit{entry point} del programma (il primo statement);
                \item ogni statement che è target di branch (condizionali o non condizionali) che contengono dei \textit{GoTo}
                \item ogni statement che segue un branch (condizionale o non condizionale) o un \textit{return}.
            \end{itemize}
            Dopo aver diviso il codice in \textit{basic block} (individuati tramite i \textit{leader} di ciascun blocco), essi verranno collegati dagli archi, in corrispondenza di:
            \begin{itemize}
                \item \textit{GoTo} non condizionali;
                \item branch condizionali / archi multipli;
                \item flusso di programma (il controllo passa ad un altro blocco se non ci sono branch alla fine).
            \end{itemize}
            Se non c'è un unico \textit{entry-node} $n_0$ ed un unico \textit{exit-node} $n_f$, si aggiungono \textit{dummy nodes} e gli archi necessari (nessun arco entrante in $n_0$ e nessun arco uscende da $n_f$).

    \section{Approssimare}
        Ma cos'è una \textit{proprietà}? Formalmente
        \paragraph{Proprietà.} L'insieme delle proprietà $\parts{\Sigma}$ di oggetti in $\Sigma$ è l'insieme di elementi che gode di quella proprietà. Questo insieme di proprietà costituisce un reticolo completo \[ \langle \parts{\Sigma}, \subseteq, \emptyset, \cup, \cap, \neg \rangle \] dove:
        \begin{itemize}
            \item $\subseteq$ è l'implicazione logica;
            \item $\Sigma$ è \verb|true|;
            \item $\cup$ è la disgiunzione (oggetti che godono di $P$ o di $Q$ appartengono a $P \cup Q$);
            \item $\cap$ è la congiunzione (oggetti che godono di $P$ e di $Q$ appartengono a $P \cap Q$);
            \item $\neg$ è la negazione (oggetti che non godono di $P$ stanno in $\Sigma \setminus P$).
        \end{itemize}
        Lo scopo è quello di trovare un'approssimazione di una semantica $\langle P \rangle$ di $\llbracket P \rrbracket$ tale per cui valgano:
        \begin{itemize}
            \item \textit{correttezza:} $\llbracket P \rrbracket \subseteq \langle P \rangle$;
            \item \textit{decidibilità:} $\langle P \rangle \subseteq Q$ è decidibile ($Q$ è un insieme di semantiche che soddisfa la proprietà di interesse).
        \end{itemize}
        Se entrambe le proprietà sono soddisfatte, allora vale che \[ (\langle P \rangle \subseteq Q) \Rightarrow (\llbracket P \rrbracket \subseteq Q) \]\\  
        La semantica è data da una coppia $\langle D, f \rangle$ dove $D$ è una coppia $\langle D, \leq_D \rangle$ rappresentante un dominio semantico e $f: D \to D$ è una funzione di trasferimento con una soluzione a punto fisso.\\
        Dato un oggetto concreto, definiamo:
        \begin{itemize}
            \item un \textbf{oggetto astratto} come una rappresentazione matematica sovrapprossimata del corrispondente concreto;
            \item un \textbf{dominio astratto} come un insieme di oggetti astratti con delle operazioni astratte, che approssimano quelle concrete;
            \item una funzione di \textbf{astrazione} $\alpha$ che mappa oggetti concreti in oggetti astratti;
            \item una funzione di \textbf{concretizzazione} $\gamma$ che mappa oggetti astratti in oggetti concreti.
        \end{itemize}   
        La caratteristica peculiare delle astrazioni è che solo alcune proprietà vengono osservate con esattezza, le altre vengono solo approssimate. In sostanza, dato un dominio astratto $A$, gli elementi di $A$ sono osservati con esattezza, gli altri sono approssimati o l'informazione è persa del tutto.
        \paragraph{Direzione dell'astrazione.} Quando si approssima una proprietà concreta $P \in \parts{\Sigma}$ usando una proprietà astratta $\overline{P}$, deve essere stabilito un criterio per definire quando $\overline{P}$ è un'approssimazione di $P$.
        
        Si distinguono quindi i seguenti casi:
        \begin{itemize}
            \item approssimazione \textit{da sopra}: $P \subseteq \overline{P}$;
            \item approssimazione \textit{da sotto}: $P \supseteq \overline{P}$.
        \end{itemize}   
        Dato un oggetto $o$, si vuole quindi sapere se $o \in P$:
        \begin{align*}
            P \supseteq \overline{P}: \begin{cases}
                \text{"Si"} &o \in \overline{P} \\
                \text{"Non lo so"} &o \notin  \overline{P}
            \end{cases} \qquad
            P \subseteq \overline{P}: \begin{cases}
            \text{"No"} &o \notin \overline{P} \\
            \text{"Non lo so"} &o \in \overline{P}\\
            \end{cases}
        \end{align*}      
        \paragraph{Migliore approssimazione.} Definiamo come \textit{migliore approssimazione} di una proprietà $P$ in $A$ il glb delle over-approximation di $P$ in $A$, ossia: 
        \[  
            \overline{P} = \bigcap \lbrace \overline{P^\prime} \in A\; |\; P \subseteq \overline{P^\prime} \rbrace \in A 
        \]

        \subsection{Collecting Semantics}
            \MakeUppercase{è} l'insieme dei comportamenti osservabili nella semantica operazionale. La \textit{Collecting Semantics} è il punto di partenza per ogni tipo di analisi (non ne esiste una universale).\\
            Definiamo un \textbf{sitema di transizioni} come una coppia $ \langle \Sigma, \tau \rangle $, dove:
            \begin{itemize}
                \item $ \Sigma $ è un insieme non vuoto di stati
                \item $ \tau \subseteq \Sigma \times \Sigma $ è la funzione di trasferimento tra gli stati in $ \Sigma $
            \end{itemize}
            La \textbf{\textit{trace semantics}} di un programma accumula informazioni temporali riguardo l'esecuzione: una traccia tiene conto dell'ordine in cui i \textit{program states} sono raggiunti durante l'esecuzione.
            \noindent
            Le tracce analizzate possono essere dei seguenti tipi:
            \begin{itemize}
                \item L'insieme di tutti i discendenti dello stato iniziale.
                \item L'insieme di tutti i discendenti dello stato iniziale che può raggiungere uno stato finale.
                \item Lo stato di tutte le tracce finite dallo stato iniziale.
                \item L'insieme di tutte le tracce infinite e finite dallo stato iniziale ecc.
            \end{itemize}
            Però non sempre siamo interessati alle informazioni temporali ma solamente agli invarianti presenti ad ogni \textit{program point}. Questi invarianti possono essere astratti dalle informazioni temporali attraverso la \textbf{\textit{collecting semantics}}.\\
            Più formalmente, un invariante del programma $P$ al punto di programma $l$ è una qualsiasi proprietà $I\in P$ (store) che è presente ogni talvolta che $l$ viene raggiunto.\\
            La \textit{collecting semantics} di $P$ è semplicemente l'associazione tra i vari \textit{program point} e le corrispondenti invarianti ben precise.\\
            Lo stato di input non è noto al momento della compilazione, quindi vengono collezionati tutti gli stati raggiungibili da tutti i possibili ingressi del programma.\\
            Si tratta di una collezione di stati che possono apparire su alcune tracce nei diversi program point. Trattandosi di un'astrazione, non è più possibile risalire alle tracce di esecuzione del programma conoscendo solamente i vari \textit{program states}.
            \begin{figure}[H]
                \centering
                \includegraphics[scale=0.32]{TraceCollect}
                \caption{Esiste la traccia rossa? \textit{Trace semantics}: NO; \textit{collecting semantics}: NON LO SO.}
            \end{figure}

    \newpage
    \section{Analisi Statica}
        \subsection{Introduzione}
            L'obiettivo dell'analisi statica è quello di dire, osservando le proprietà semantica di un programma, se una certa proprietà vale o meno. Esistono diverse tipologie di analisi statica: \begin{itemize}
                \item Control flow Analysis;
                \item Data flow Analysis (distributive e non-distributive);
            \end{itemize}

        \subsection{Analisi sul CFG}
            Viene generato un CFG per ogni procedura. Le analisi che vengono eseguite sono localizzate a 3 livelli: \begin{enumerate}
                \item \textbf{Locali al blocco}: sono eseguite all'interno di uno stesso \textit{basic block};
                \item \textbf{Intra-procedurali}: considerano il flusso di informazioni nel singolo CFG;
                \item \textbf{Inter-procedurali}: considerano il flusso di informazioni tra le procedure (con archi che rappresentano le chiamate di funzione).
            \end{enumerate}
            L'analisi di \textit{data-flow} dice come l'informazione viene manipolata in un blocco. L'informazione è caratterizzata dalla soluzione dell'equazione di punto fisso definita per ogni blocco.\\
            In alcuni casi questa equazione è ottenuta in 3 passaggi: \begin{itemize}
                \item definendo l'informazione entrante in un blocco, che è l'unione dell'informazione di uscita del blocco precedente;
                \item definendo l'informazione in uscita dal blocco che è l'informazione in ingresso, modificata dalle operazioni eseguite nel blocco;
                \item queste definizioni vengono poi combinate nell'equazione del punto fisso.
            \end{itemize}
            Le analisi di \textit{data-flow} seguono il seguente schema:
            \begin{figure}[H]
                \centering
                \includegraphics[scale=0.376]{FB}
            \end{figure}

        \newpage
        \subsection{Soluzioni MFP - MOP - IDEAL}
            Per le equazioni di \textit{data-flow analysis} esistono 3 tipi di soluzioni:
            \begin{itemize}
                \item \textit{\textbf{MFP} (maximum fixed point)}: è la soluzione che combina i valori dell'analisi quando il CFG ha dei nodi in cui convergono due o più percorsi; questa soluzione approssima la \textit{MOP}.
                \item \textit{\textbf{MOP} (merge over all paths)}: è la soluzione più precisa rispetto alla \textit{MFP} ($MOP \sqsupseteq MFP$) poiché combina i valori dell'analisi di tutti i possibili percorsi del CFG dopo averli attraversati tutti. In generale, questa soluzione non è computabile perché ci posso essere un numero esponenziale (o infinito) di percorsi possibili:
                \begin{itemize}
                    \item loop con guardia sempre vera;
                    \item un programma che contiene $N$ \textit{if} statement avrà $2^N$ percorsi di esecuzione;
                \end{itemize}
                \item \textbf{\textit{IDEAL}}: è la soluzione migliore ma non è computabile. A differenza della \textit{MOP}, prende in considerazione solamente i percorsi che verrano attraversati sicuramente da almeno qualche esecuzione. Calcola il valore alla fine di ogni possibile percorso di esecuzione e calcola poi il \textit{meet} di questi valori.
                \begin{itemize}
                    \item ogni soluzione più grande di \textit{IDEAL} è scorretta;
                    \item ogni soluzione più piccola di \textit{IDEAL} è conservativa (\textit{safe});
                \end{itemize}
            \end{itemize}
            Se la funzione di trasferimento di ogni arco è \textbf{\textit{distributiva}} ($f(x \cup y) = f(x) \cup f(y)$) (e ogni program point è raggiungibile dall'entry point), allora la soluzione delle equazioni di \textit{data-flow} è la stessa per \textit{MOP} e \textit{MFP} ($MOP = MFP$). Dunque per le funzioni di trasferimento distributive, è possibile calcolare la soluzione \textit{MOP} attraverso l'algoritmo iterativo del punto fisso.\\
            I \textbf{problemi \textit{distributivi}} sono i cosiddetti problemi "\textit{semplici}", come ad esempio: \textit{\textbf{live variables}}, \textit{\textbf{available expressions}}, \textit{\textbf{reaching definitions}} e \textit{\textbf{very busy expressions}} (tutte proprietà che ci dicono \textit{COME} un programma viene eseguito).\\
            I \textbf{problemi \textit{non-distributivi}} sono quelli che ci dicono \textit{COSA} calcola un programma (ad esempio che l'output è costante, valori positivi, intervalli etc.). Un esempio di problema non distributivo è la \textit{\textbf{constant propagation analysis}}.

            \subsection{Data Flow Analysis}
                Insieme di tecniche che raccolgono informazione su come i dati fluiscono durante l'esecuzione.

                \subsubsection{Available Expressions}
                    L'espressione $e$ è \textit{available} se è valutata e assegnata ad una variabile prima di $v$ (uso della variabile). Tra la valutazione e $v$ non vengono ridefinite le variabili dell'espressione e \textit{x} (\textit{x:=e}).\\
                    \\
                    \noindent
                    \textit{\underline{Proprietà}}: Forward \& Definite\\
                    \\
                    \noindent
                    \underline{\textit{Punto fisso:}}
                    \begin{align*}
                        AvailIn(n) &= 
                        \begin{cases}
                            \emptyset &\text{ se } n = n_0 \\
                            \bigcap_{m\in pred(n)} AvailOut(m) &\text{ altrimenti}
                        \end{cases}\\ \\
                        AvailOut(n) &= Gen(n) \cup (AvailIn(n)\backslash Kill(n))\\
                        AvailIn(n) &= \bigcap_{m\in pred(n)} Gen(m) \cup (AvailIn(m)\backslash Kill(m))
                    \end{align*}

                    \noindent
                    \underline{\textit{Semantica:}}
                    Dominio astratto = Ass = \{assegnamenti $x\leftarrow e ~|~ x\notin Var(e)$\}
                    $A\subseteq Ass$
                    \begin{align*}
                        \llbracket ; \rrbracket^\sharp A &= A\\
                        \llbracket NonZero(e) \rrbracket^\sharp A &= \llbracket Zero(e) \rrbracket^\sharp A = A\\
                        \llbracket x\leftarrow e \rrbracket^\sharp A &= \begin{cases}
                            (A\backslash Occ(x)) \cup \{x\leftarrow e \} &\text{ se } x\notin Var(e) \\
                            A\backslash Occ(x) &\text{ altrimenti}
                        \end{cases}\\
                        \llbracket x\leftarrow M[e] \rrbracket^\sharp A &= A\backslash Occ(x)\\
                        \llbracket M[e_1]\leftarrow e_2 \rrbracket^\sharp A &= A
                    \end{align*}

                    $Occ(x) = $ \{Assegnamenti che coinvolgono $x$ a destra o a sinistra\}

                    $ \begin{aligned}
                        Gen(n) = \{ &\text{espressioni valutate nel blocco } n e \text{ nessun operando di } e \text{ è}\\
                        &\text{definito nuovamente tra l'ultima valutazione di } e \text{ in } n \text{e la fine di } n \}
                    \end{aligned} $

                    $Kill(n) = $ \{espressioni uccise da una nuova definizione di $n$\}

                \subsubsection{Liveness}
                $x$ è \textit{live} all'uscita del blocco $b$ se verrà usata successivamente. $x$ non è \textit{live} (o \textit{dead}) se viene ridefinita prima di un successivo uso.

                \noindent
                $x$ è \textit{live} in un cammino $\pi$ ($v\rightarrow exit$) se:
                \begin{itemize}
                    \item $\pi$ non contiene \textit{Def(x)}
                    \item esiste almeno un uso di $x$ in $\pi$ che segue la \textit{Def(x)};
                \end{itemize}
                \noindent
                $x$ è \textit{live} se si trova tra una definizione ed un uso.

                \noindent
                Dice se $a$ e $b$ possono essere memorizzate nella stessa locazione, cioè se $a$ e $b$ non sono mai \textit{live} insieme, allora posso sostituire $a$ con $b$.

                \begin{itemize}
                    \item $x\in Use(n) \Rightarrow$ x \textit{LiveIn} in $n$
                    \item $x$ è \textit{LiveOut} in $n$ e $x\notin$ \textit{VarKill(n)} $\Rightarrow$ $x$ \textit{LiveIn} in $n$;
                    \item $x$ è \textit{LiveIn} in almeno un \textit{Succ(n)} $\Rightarrow$ $x$ \textit{LiveOut(n)};
                \end{itemize}

                \noindent
                \textit{\underline{Falsi positivi}}:
                \begin{itemize}
                    \item $x$ è accessibile attraverso altri nomi $\Rightarrow$ Liveness fallisce;
                    \item analizzi anche cammini non possibili;
                    \item inizializzazione in altre procedure (perché questa analisi è intra-procedurale);
                \end{itemize}

                \noindent
                \textit{\underline{Proprietà}}: Backward \& Possible
                \newline

                \noindent
                \underline{\textit{Punto fisso:}}
                \begin{align*}
                    LiveOut(n) &=
                    \begin{cases}
                        \emptyset &\text{ se $n= exit$} \\
                        \bigcup_{m\in Succ(n)} LiveIn(m) &\text{ altrimenti}
                    \end{cases}\\
                    LiveIn(n) &= Use(n) \cup (LiveOut(n)\backslash VarKill(n))\\
                    LiveOut(n) &= \bigcup_{m\in Succ(n)} Use(m) \cup (LiveOut(m)\backslash VarKill(m))
                \end{align*}

                \noindent
                \underline{\textit{Semantica:}}

                Dominio astratto = $\mathcal{P}(Var)$

                $L\subseteq Var$
                \begin{align*}
                    \llbracket ; \rrbracket^\sharp L &= L\\
                    \llbracket NonZero(e) \rrbracket^\sharp L &= \llbracket Zero(e) \rrbracket^\sharp L = L \cup Var(e)\\
                    \llbracket x\leftarrow e \rrbracket^\sharp L &= Var(e) \cup (L\backslash\{x\})\\
                    \llbracket x\leftarrow M[e] \rrbracket^\sharp L &= Var(e) \cup (L\backslash\{x\})\\
                    \llbracket M[e_1]\leftarrow e_2 \rrbracket^\sharp L &= L \cup Var(e_1) \cup Var(e_2)
                \end{align*}

                $\begin{aligned}
                    LiveIn(n) = \{ &\text{sono le variabili } \textit{live} \text{ in } n \text{, } \textit{live} \text{ su almeno un arco entrante\}}
                \end{aligned}$

                $\begin{aligned}
                    LiveOut(n) = \{\text{sono le variabili } \textit{live} \text{ in } n \text{ che sono } \textit{live} \text{ su almeno un arco uscente}\}
                \end{aligned}$

                $VarKill(n) = Def(n)$, cioè le definizioni presenti in n\\
                \\
                \underline{\textit{True Liveness:}} un \textit{true use} è un uso in un assegnamento ad una variabile \textit{live}. Se assegno $x$ ad una variabile \textit{non-live}, allora anche $x$ non è \textit{live}.

            \subsubsection{Very Busy Expressions}
                Un assegnamento è \textit{busy} su un cammino $\pi$ se $\pi = \pi_1 ~k~ \pi_2$ con:
                \begin{itemize}
                    \item $k$ è un assegnamento $x\leftarrow e$;
                    \item $\pi_1$ non contiene usi di $x$;
                    \item $\pi_2$ non contiene modifiche di $\{x\}\cup Var(e)$.
                \end{itemize}
                Un assegnamento è \textit{very busy} se è \textit{busy} su ogni percorso da $v$ a \textit{exit}.\\
                Dice come e quali espressioni anticipare.\\
                Un assegnamento è ucciso in un blocco $n$ se una delle sue variabili è modificata o se $e$ viene usata.\\
                Un assegnamento è generato in un blocco $n$ se si trova nel blocco e l'espressione non contiene la variabile che si sta assegnando.\\
                \textit{\underline{Proprietà}}: Backward \& Definite\\
                \\
                \underline{\textit{Punto fisso:}}
                \begin{align*}
                    VB_{exit}(p) &= 
                    \begin{cases}
                        \emptyset &\text{ se } p = v_{exit} \\
                        \bigcap_{q\in succ(p)} VB_{entry}(q) &\text{ altrimenti}
                    \end{cases}\\ \\
                    VB_{entry}(p) &= Gen(p) \cup (VB_{exit}(p)\backslash Kill(p))\\
                    VB_{exit}(p) &= \bigcap_{q\in succ(p)} Gen(q) \cup (VB_{exit}(q)\backslash Kill(q))
                \end{align*}
                \\
                \underline{\textit{Semantica:}}

                $B = 2^{Ass} = \mathcal{P}(Ass)$
                \begin{align*}
                    \llbracket ; \rrbracket^\sharp B &= B\\
                    \llbracket NonZero(e) \rrbracket^\sharp B &= \llbracket Zero(e) \rrbracket^\sharp B = B \backslash Ass(e)\\
                    \llbracket x\leftarrow e \rrbracket^\sharp B &= \begin{cases}
                        B\backslash (Occ(x) \cup Ass(e)) \cup \{x\leftarrow e \} &\text{ se } x\notin Var(e) \\
                        B\backslash (Occ(x) \cup Ass(e)) &\text{ altrimenti}
                    \end{cases}\\
                    \llbracket x\leftarrow M[e] \rrbracket^\sharp B &= B\backslash (Occ(x) \cup Ass(e))\\
                    \llbracket M[e_1]\leftarrow e_2 \rrbracket^\sharp B &= B\backslash (Ass(e_1) \cup Ass(e_2))
                \end{align*}

                $Use(n) = $ \{occorrenza di una variabile sul lato destro di uno statement\}

            \subsubsection*{Copy Propagation}
                L'analisi ad ogni program point tiene traccia delle copie di $x$.\\
                Se ho un assegnamento $T\leftarrow x+1$ e poi $y\leftarrow T$, allora quest'ultimo è inutile.\\
                \\
                \textit{\underline{Proprietà}}: Forward \& Definite\\
                \\
                \underline{\textit{Punto fisso:}}
                \begin{align*}
                    Copie_{entry}(n) &= \bigcap_{m\in Pred(n)} Copie_{exit}(m)\\
                    Copie_{exit}(n) &= \bigcap_{m\in Pred(n)} Gen(m) \cup (Copie_{exit}(m)\backslash Kill(m))
                \end{align*}
                \\
                \underline{\textit{Semantica:}}
                Dominio astratto = $\mathcal{V}_x$ = $\{V \subseteq Var ~|~ x\in V\}$ perché $x$ è copia di se stesso.

                $V\subseteq Var$

                Entry $V_0=\{x\}$ perché $x$ è copia di se stesso e cerco le altre sue copie.
                \begin{align*}
                    \llbracket ; \rrbracket^\sharp V &= V\\
                    \llbracket NonZero(e) \rrbracket^\sharp V &= \llbracket Zero(e) \rrbracket^\sharp V = V\\
                    \llbracket x\leftarrow e \rrbracket^\sharp V &= \llbracket x\leftarrow M[e]\rrbracket^\sharp V = \{x\}\\
                    \llbracket z\leftarrow y \rrbracket^\sharp V &=
                    \begin{cases}
                        V \cup \{z\} &\text{ se } y\in V \text{(y è copia di x)} \\
                        V\backslash \{z\} &\text{ altrimenti}
                    \end{cases}\\
                    \llbracket y\leftarrow e \rrbracket^\sharp V &= V\backslash \{y\}\\
                    \llbracket M[e_1]\leftarrow e_2 \rrbracket^\sharp V &= V
                \end{align*}
                $Gen(n) = \{(x == y) ~|~ n$ contiene $x\leftarrow y \}$\\
                $Kill(n) = \{(x == y) ~|~ x$ è ridefinita in $n \}$

            \subsubsection{Reaching Definition}
                Dato un program point $p$ vogliamo identificare le definizioni di variabili che raggiungono $p$.\\
                Viene usata in \textit{code motion}: se uso un assegnamento in tutto il ciclo senza modificarlo, allora lo sposto all'entrata del ciclo.\\
                \\
                \textit{\underline{Proprietà}}: Forward \& Possible\\
                \\
                \underline{\textit{Punto fisso (non c'è la semantica):}}
                \begin{align*}
                    RD_{entry}(n) &=
                    \begin{cases}
                        i=\{(x, ?) ~|~ x\in Var \} &\text{ se $n= entry$} \\
                        \bigcup_{m\in Pred(n)} RD_{exit}(m) &\text{ altrimenti}
                    \end{cases}\\
                    RD_{exit}(n) &= Gen(n) \cup (RD_{entry}(n)\backslash Kill(n))
                \end{align*}

                $\{(x, p) ~|~ x\in Vars$, $p$ punto di programma$\}$\\
                \\
                \textit{Inizializzazione}: $i=\{(x, ?) ~|~ x\in Vars$, variabile non inizializzata)  $\}$\\
                $Gen(n) =$ \{definizioni $(x, l)$ dentro $n$ e disponibili alla fine di $n$ \}\\
                $Kill(n) = \{(x,p) ~|~ x$ è ridefinita in $n \}$

            \subsubsection{Riepilogo}
                \begin{center}
                    \begin{tabular}{c|c|c}
                        &\thead{\textbf{Possible $(\bigcup)$}}&\textbf{Definite $(\bigcap)$}\\ \hline
                        \textbf{Forward}&Reaching Definition&\makecell{Available Expr, \\Copy Propagation}\\ \hline
                        \makecell{\textbf{Backward}\\}&Liveness&Very Busy Expr\\
                    \end{tabular}
                \end{center}

                \textit{\underline{Available Expressions}}:
                \begin{align*}
                    AvailIn(n) &= 
                    \begin{cases}
                        \emptyset &\text{ se } n = n_0 \\
                        \bigcap_{m\in pred(n)} AvailOut(m) &\text{ altrimenti}
                    \end{cases}\\ \\
                    AvailOut(n) &= Gen(n) \cup (AvailIn(n)\backslash Kill(n))
                \end{align*}
                \\

                \textit{\underline{Very Busy}}:
                \begin{align*}
                    VB_{exit}(p) &= 
                    \begin{cases}
                        \emptyset &\text{ se } p = v_{exit} \\
                        \bigcap_{q\in succ(p)} VB_{entry}(q) &\text{ altrimenti}
                    \end{cases}\\ \\
                    VB_{entry}(p) &= Gen(p) \cup (VB_{exit}(p)\backslash Kill(p))
                \end{align*}
                \\

                \textit{\underline{Liveness}}:
                \begin{align*}
                    LiveOut(n) &=
                    \begin{cases}
                        \emptyset &\text{ se $n= exit$} \\
                        \bigcup_{m\in Succ(n)} LiveIn(m) &\text{ altrimenti}
                    \end{cases}\\
                    LiveIn(n) &= Use(n) \cup (LiveOut(n)\backslash VarKill(n))
                \end{align*}
                \\

                \textit{\underline{Reaching Definition}}:
                \begin{align*}
                    RD_{entry}(n) &=
                    \begin{cases}
                        i=\{(x, ?) ~|~ x\in Var \} &\text{ se $n= entry$} \\
                        \bigcup_{m\in Pred(n)} RD_{exit}(m) &\text{ altrimenti}
                    \end{cases}\\
                    RD_{exit}(n) &= Gen(n) \cup (RD_{entry}(n)\backslash Kill(n))
                \end{align*}

    \newpage
    \section{Interpretazione astratta}
        \subsection{Connessione di Galois}
            Imponiamo il vincolo che $\alpha$ e $\gamma$ siano monotone, allora concludiamo che: \begin{itemize}
                \item $\gamma \circ \alpha: C \to C$ è \textbf{estensiva}: $\gamma(\alpha(c)) \geq c$;
                \item $\alpha \circ \gamma : A \to A$ è \textbf{riduttiva}: $\alpha(\gamma(a)) \leq a$.
            \end{itemize}

            Le definizioni qui sopra dicono rispettivamente che:
            \begin{itemize}
                \item $\alpha$ perde informazione, e $\gamma$ non la può recuperare;
                \item $\gamma$ non perde informazione.
            \end{itemize}

            \begin{definit}[Connessione di Galois]
                Dati due poset $\langle A , \leq_A \rangle$ e $\langle C , \leq_C \rangle$, e due funzioni monotone $\alpha: C \to A$ e $\gamma: A \to C$, diciamo che $\galoistuple$ è una connessione di Galois se:
                \begin{itemize}
                    \item $\forall c \in \mathcal{C}: c \leq_C \gamma(\alpha(c))$
                    \item $\forall a \in \mathcal{A}: \alpha(\gamma(a)) \leq_A a$
                \end{itemize}
                
                Se inoltre vale che $\forall a \in \mathcal{A}: \alpha(\gamma(a)) = a$, allora $\galoistuple$ è un'inserzione di Galois.
            \end{definit}
            Una connessione e un'inserzione di Galois sono rappresentate rispettivamente come \[  C \galois{\alpha}{\gamma} A \qquad C \galoiS{\alpha}{\gamma} A \]
            La funzione $\alpha$ è detta \textit{aggiunta sinistra}, mentre la funzione $\gamma$ è detta \textit{aggiunta destra}.
            
            \begin{thm}
                Data una connessione di Galois $ C \galois{\alpha}{\gamma} A$, sono equivalenti:
                \begin{itemize}
                    \item $C \galoiS{\alpha}{\gamma} A$;
                    \item $\alpha$ è suriettiva;
                    \item $\gamma$ è iniettiva.
                \end{itemize}
            \end{thm}

            Inoltre, dati due domini astratti, non esistono due coppie $(\alpha, \gamma)$ che formino una connessione di Galois; quindi la connessione di Galois tra due domini è \textbf{unica}, e le funzioni sono identificabili attraverso:
            \begin{align*}
                \alpha(c) &= \bigwedge \lbrace a \in A \vert c \leq_C \gamma(a) \rbrace \\
                \gamma(a) &= \bigvee \lbrace c \in C \vert \alpha(c) \leq_A a \rbrace
            \end{align*}
	
        \subsection{Famiglie di Moore}
            \begin{definit}[Famiglia di Moore]
                Sia $L$ un reticolo completo. $X \subseteq L$ è una famiglia di Moore di $L$ se \[ X = \mathcal{M}(X) = \Big\{ \bigwedge S\ \vert\ S \subseteq X \Big\} \] dove \[ \bigwedge \emptyset = \top \in \mathcal{M}(X) \]
            \end{definit}
            
            Da questa definizione segue che, ipotizzando che ogni proprietà concreta abbia una migliore astrazione $\overline{P} \in A$, implica che il dominio $A$ è una famiglia di Moore.
            
        \subsection{Upper closure operator}
            \begin{definit}[Upper closure operator]
                Una funzione $f:P \to P$ su un poset $\langle P, \leq_P \rangle $ è un upper closure operator (uco) se soddisfa le seguenti proprietà:\begin{itemize}
                    \item estensività: $\forall x \in P: x \leq_P \rho(x)$
                    \item monotonia: $\forall x,y \in P: (x \leq_P y) \Rightarrow (\rho(x) \leq_P \rho(y)$
                    \item idempotenza: $\forall x \in P: \rho(x) = \rho(\rho(x))$
                \end{itemize}
            \end{definit}

            I lower closure operator sono definiti in modo duale, specificando che $\rho$ deve essere \textit{riduttiva}, ovvero che $\forall x \in P: x \geq_P \rho(x)$.
            
            \begin{thm}
                Data una connessione di Galois $C \galois{\alpha}{\gamma} A$ si ha che $\gamma \circ \alpha$ è un uco e $\alpha \circ \gamma $ è un lco.
            \end{thm}
            \begin{thm}
                $C \galoiS{\alpha}{\gamma} A$ se e solo se $A$ è isomorfo \footnote{Con isomorofismo si intendono reticoli con la stessa struttura.} ad una Moore family di $C$.
            \end{thm}
            \begin{thm}
                Sia $\rho \in uco(c)$. Allora $\forall A \simeq \rho(C)$ si ha che $\exists \alpha, \gamma : C \galoiS{\alpha}{\gamma} A$
            \end{thm}
        
        \subsection{Reticolo delle interpretazioni astratte}
            I vari domini astratti possono essere comparati sulla base della loro precisione. In generale si può dire che un dominio astratto $A_1$ è più preciso di $A_2$ (indicato attraverso $A_1 \sqsubseteq A_2$) quando \[ \forall a_2 \in A_2, \exists a_1 \in A_1 \quad \text{ tali che } \quad \gamma_1(a_1) = \gamma_2(a_2) \] ovvero quando \[ \gamma(A_2) \subseteq \gamma(A_1) \]
            
            Collegando agli uco, possiamo dire che \[ A_1 \sqsubseteq A_2 \Leftrightarrow \rho_1 \sqsubseteq \rho_2 \Leftrightarrow \rho_2(C) \subseteq \rho_1(C) \]
            
            \begin{definit}[Reticolo delle int. astratte]
                Se $C$ è un reticolo completo o un cpo, allora \[ \langle uco(C), \sqsubseteq, \sqcup, \sqcap, \lambda x.\top, \lambda x.x \rangle \] è un reticolo completo dove $\forall \rho, \eta \in uco(C), \{ \rho_i \}_{i \in I} \subseteq uco(C)$ e $x \in C$:\begin{itemize}
                    \item $\rho \sqsubseteq \eta \Leftrightarrow \forall y \in C.\rho(y) \leq \eta(y) \Leftrightarrow \eta(C) \subseteq \rho(C)$
                    
                    \item $ \displaystyle \Big( \bigsqcap_{i \in I} \rho_i \Big)(x) = \bigwedge_{i \in I} \rho_i(x)$
                    
                    \item $ \displaystyle \Big( \bigsqcup_{i \in I} \rho_i \Big)(x) = x \Leftrightarrow \forall i \in I. \rho_i(x)=x$
                    
                    \item $\lambda x.\top, \lambda x.x$ sono rispettivamente top e bottom. 
                \end{itemize}
            \end{definit}

        \subsection{Computazioni astratte e concrete}
            \begin{definit}[Correttezza]
                Data un'inserzione di Galois $C \galoiS{\alpha}{\gamma} A$, una funzione concreta $f: C \to C$ e una funzione astratta $f^\sharp: A \to A$ diciamo che $f^\sharp$ è un'approssimazione corretta di $f$ se \[ \forall c \in C: \alpha(f(c)) \leq_A f^\sharp(\alpha(c)) \quad \text{backward} \] o equivalentemente \[ \forall a \in A: f(\gamma(a)) \leq_C \gamma(f^\sharp(a) \quad \text{forward} \]
            \end{definit}
            
            Rinforzando la definizione e imponendo uguaglianza si perde l'equivalenza delle due espressioni sopra. 
            \begin{definit}[Completezza]
                Data un'inserzione di Galois $C \galoiS{\alpha}{\gamma} A$, una funzione concreta $f: C \to C$ e una funzione astratta $f^\sharp: A \to A$ diciamo che $f^\sharp$ è: \begin{itemize}
                    \item backward-completa per $f$ se  $\forall c \in C: \alpha(f(c)) = f^\sharp(\alpha(c))$
                    \item forward-completa per $f$ se $\forall a \in A: f(\gamma(a)) = \gamma(f^\sharp(a)$
                \end{itemize}
            \end{definit}
            
            La definizione rappresenta una situazione ideale in cui non si ha perdita di precisione durante il calcolo astratto. Inoltre la backward-completezza lavora sull'astrazione dell'input delle operazioni, la forward-completezza sull'output.
            
            Le definizioni di completezza possono essere date anche usando gli uco: \begin{itemize}
                \item $\rho \in uco(C)$ è backward-completo per $f$ se $\rho \circ f = \rho \circ f \circ \rho$
                \item $\rho \in uco(C)$ è forward-completo per $f$ se $f \circ \rho = \rho \circ f \circ \rho$
            \end{itemize}

            Inoltre quando $\rho$ è sia backward che forward-completo allora vale che $\rho \circ f = f \circ \rho$.
            
            \begin{thm}
                Data $C \galoiS{\alpha}{\gamma} A$, una funzione concreta $f : C \to C$  e una funzione astratta $f^\sharp: A \to A$ allora  \[ \forall c \in C: \alpha(f(c)) \leq_A f^\sharp(\alpha(c)) \Leftrightarrow \alpha \circ f \circ \gamma \sqsubseteq f^\sharp \]
            \end{thm}

            \begin{definit}[Best correct approximation]
                Data $C \galoiS{\alpha}{\gamma} A$ e una funzione concreta $f : C \to C$ allora $\alpha \circ f \circ \gamma : A \to A$ è la best correct approximation di $f$ in $A$.
            \end{definit}
        
        \subsection{Correttezza}
            Consideriamo $C \galois{\alpha}{\gamma} A$, una funzione concreta $f: C\rightarrow C$ e una funzione astratta $f^{\sharp}: A\rightarrow A$. Possiamo dire che $f^{\sharp}$ è un'approssimazione corretta di f in A se:
            \begin{equation*}
            \forall c\in C: \alpha(f(c))\leq_A f^{\sharp}(\alpha(c))
            \end{equation*}
            
            \noindent
            oppure, equivalentemente:
            \begin{equation*}
            \forall a\in A: f(\gamma(a))\leq_C \gamma(f^{\sharp}(a))
            \end{equation*}
            
            Nel processo di astrazione è ammessa una perdita di informazioni, ciò non è possibile nel processo di concretizzazione, dunque possiamo dire che se $c\in C$. Possiamo  dire che $\alpha(c)$ è l'elemento astratto più preciso che rappresenta \textit{c}.
            
            \begin{multicols}{2}	
                \begin{figure}[H]
                    \centering
                    \includegraphics[scale=0.35]{Correttezza}
                    \caption{Condizione di correttezza: $\alpha(f(c))\leq_A f^{\sharp}(\alpha(c))$}
                    \label{Correct}
                \end{figure}
                \columnbreak
                \begin{figure}[H]
                    \centering
                    \includegraphics[scale=0.35]{CorrettezzaAstr}
                    \caption{Condizione di correttezza: $f(\gamma(a))\leq_C \gamma(f^{\sharp}(a))$}
                    \label{CorrectAbstr}
                \end{figure}
            \end{multicols}
        
        \subsection{Completezza}
            Consideriamo $C \galoiS{\alpha}{\gamma} A$, una funzione concreta $f: C\rightarrow C$ e una funzione astratta $f^{\sharp}: A\rightarrow A$. Possiamo dire che:
            \begin{itemize}
                \item $f^{\sharp}$ è backward-complete per f se: $\forall c\in C: \alpha(f(c))=f^{\sharp}(\alpha(c))$;
                \item $f^{\sharp}$ è forward-complete per f se: $\forall a\in A: f(\gamma(a))=\gamma(f^{\sharp}(a))$.
            \end{itemize}
            
            I due tipi di completezza rappresentano una situazione in cui non si verifica nessuna perdita di precisione durante l'astrazione. In particolare:
            \begin{itemize}
                \item La \textbf{B}-completezza considera l'astrazione sull'output delle operazioni e non si accumula nessuna perdita di precisione astraendo in \textit{p} gli argomenti di \textit{f};
                \item La \textbf{F}-completezza considera l'astrazione sull'input delle operazioni e non si accumula nessuna perdita di precisione approssimando il risultato della funzione \textit{f} calcolata in \textit{p}.
            \end{itemize}
            
            \begin{multicols}{2}	
                \begin{figure}[H]
                    \centering
                    \includegraphics[scale=0.33]{Backward}
                    \caption{Condizione di \textit{\textbf{B}-completezza}}
                    \label{Backward}
                \end{figure}
                \columnbreak
                \begin{figure}[H]
                    \centering
                    \includegraphics[scale=0.33]{Forward}
                    \caption{Condizione di \textit{\textbf{F}-completezza}}
                    \label{Forward}
                \end{figure}
            \end{multicols}

        \subsection{Accelerazione della convergenza}
            \subsubsection{Widening}
            Un widening \[ \nabla : P \times P \to P  \] su un poset $ \langle P, \leq_P \rangle $ è una funzione che soddisfa:
            \begin{itemize}
                \item $\forall x,y \in P : x \sqsubseteq (x \nabla y ) \wedge y \sqsubseteq (x \nabla y)$
                \item per ogni catena ascendente $x_0 \sqsubseteq x_1 \sqsubseteq ... \sqsubseteq x_n$ la catena definita come $y_0 = x_0, ..., y_{n+1} = y_n \nabla x_{n+1}$ non è strettamente crescente.
            \end{itemize}
            
            Dato che in interpretazione astratta è necessario garantire/accelerare la convergenza, viene usato il widening (che si sostituisce al least upper bound), dal momento che anche il calcolo astratto può divergere.
            Il risultato di un widening è un post-puntofisso  di $F^\nabla$, ovvero una sovra-approssimazione del punto fisso più piccolo di f $lfp^\sqsubseteq F$. 
            
            Ad esempio, il widening su intervalli funziona come segue:
            \begin{align*}
            \lbrack a, b \rbrack\ \nabla\ \lbrack c, d \rbrack = \lbrack e, f \rbrack \qquad \text{ tale che}
            \end{align*}
            
            \begin{align*}
            e = 
            \begin{cases}
            -\infty &\text{ se } c < a \\
            a &\text{ altrimenti}
            \end{cases}
            \text{ e } f = 
            \begin{cases}
            +\infty &\text{ se } b < d\\
            b &\text{ altrimenti }
            \end{cases}
            \end{align*}
        
            \subsubsection{Narrowing}
                Dato che il widening raggiunge un post-fixpoint, piuò capitare che si abbiano eccessive perdite di informazione, in questo caso viene usato il narrowing.
                
                \begin{definit}
                    Il narrowing è una funzione $ \triangle : P \times P \to P$ tale che:
                    \begin{itemize}
                        \item $\forall x, y \in \mathcal{P}: y \leq x \implies y \leq x\ \triangle\ y \leq x$
                        \item Per ogni catena discendente $x_0 \geq x_1 \geq ...$, la catena discendente $y_0=x_0, ..., y_{i+1} = y_i\ \triangle\ x_{i+1}$ non è strettamente decrescente.
                    \end{itemize}
                \end{definit}

                Per gli intervalli il narrowing funziona come segue:
                \begin{align*}
                \lbrack a, b \rbrack\ \triangle\ \lbrack c, d \rbrack = \lbrack e, f \rbrack \qquad \text{ tale che}
                \end{align*}
                \begin{align*}
                e = 
                \begin{cases}
                c &\text{ se } a = -\infty \\
                a &\text{ altrimenti}
                \end{cases}
                \text{ e } f = 
                \begin{cases}
                d &\text{ se } b = +\infty\\
                b &\text{ altrimenti }
                \end{cases}
                \end{align*}

        \newpage
        \subsection{Problemi Non-Distributivi}
            \subsubsection{Costanti}
                Ogni singoletto non è confrontabile con gli altri. Se una costante assume due valori va in $\top$. \MakeUppercase{è} un reticolo completo poiché contiene $\emptyset$ ed è \textit{ACC} perché è finito in altezza.
                \begin{figure}[H]
                    \centering
                    \includegraphics[scale=0.32]{Const}
                \end{figure}

                Dominio concreto: $\mathbb{V}\rightarrow \mathbb{Z}$

                Dominio astratto: $\mathbb{V}\rightarrow \mathcal{P}(\mathbb{Z})$
                \newline

                \noindent
                \underline{\textit{Semantica astratta delle espressioni:}}
                \begin{align*}
                    op &= operatore\\
                    a ~op~ b &=
                    \begin{cases}
                        a ~op~ b &\text{ se a e b sono costanti}\\
                        \top &\text{ se $a=\top$ $\lor~$ $b=\top$}
                    \end{cases}\\
                    \llbracket c \rrbracket^\sharp D &= c\\
                    \llbracket op~e \rrbracket^\sharp D &= op^\sharp\llbracket e\rrbracket^\sharp D\\
                    \llbracket e_1~op~e_2 \rrbracket^\sharp D &= \llbracket e_1\rrbracket^\sharp D ~op^\sharp~\llbracket e_2\rrbracket^\sharp D\\
                    \llbracket x\rrbracket^\sharp D &= D(x)
                \end{align*}

                \underline{\textit{Semantica astratta dei comandi:}}

                $D =$ memoria
                \begin{align*}
                    \llbracket ; \rrbracket^\sharp D &= D\\
                    \llbracket NonZero(e) \rrbracket^\sharp D &=
                    \begin{cases}
                        \bot &\text{ se } \llbracket e\rrbracket^\sharp D = 0 \\
                        D &\text{ se } \llbracket e\rrbracket^\sharp D \neq 0
                    \end{cases}\\
                    \llbracket Zero(e) \rrbracket^\sharp D &=
                    \begin{cases}
                        D &\text{ se } 0\subseteq \llbracket e\rrbracket^\sharp D \\
                        \bot &\text{ se } 0\not\subseteq \llbracket e\rrbracket^\sharp D
                    \end{cases}\\
                    \llbracket x\leftarrow e \rrbracket^\sharp D &= D[x\mapsto \llbracket e\rrbracket^\sharp D]\\
                    \llbracket x\leftarrow M[e] \rrbracket^\sharp D &= D[x\mapsto \top] \text{\hspace{0.5cm} non so cos'è M[e] perché lo valuterò dopo}\\
                    \llbracket M[e_1]\leftarrow e_2 \rrbracket^\sharp D &= D
                \end{align*}

            \subsubsection{Segni}
                Dominio rappresentato da un semipiano (un insieme di punti), quindi non va subito a $\top$.

            \subsubsection{Intervalli}
                Il dominio degli Intervalli non è \textit{ACC}, dunque non garantisce la terminazione: per questo viene introdotto il \textit{widening}.

                \begin{center}
                    $[a, b]$ dove $a\leq x\leq b$ (convessi)
                    
                    $\mathbb{I} = \{[l, u] ~|~ l\in \mathbb{Z}\cup \{-\infty\}, u\in\mathbb{Z}\cup \{+\infty\}, ~l\leq u\}$
                \end{center}

                \noindent
                \textit{\underline{Semantica astratta delle espressioni:}}
                \begin{itemize}
                    \item $[l_1, u_1] +^\sharp [l_2, u_2] = [l_1 + l_2, u_1 + U_2]$
                    \item $-^\sharp[l, u] = [-u, -l]$
                    \item $[l_1, u_1] *^\sharp [l_2, u_2] = [a, b]$ dove:
                    \begin{itemize}
                        \item $a=min(l_1*l_2, l_1*u_2, l_2*u_1, l_2*u_2)$
                        \item $b=max(l_1*l_2, l_1*u_2, l_2*u_1, l_2*u_2)$
                    \end{itemize}
                    \item $[l_1, u_1] =^\sharp [l_2, u_2] =
                    \begin{cases}
                    [1, 1] &\text{ se } l_1=l_2=u_1=u_2 (costanti) \\
                    [0, 0] &\text{ se } u_1 < l_2 \lor ~u_2 < l_1\\
                    [0, 1] &\text{ altrimenti (intervalli uguali che approssimano valori diversi) }
                    \end{cases}$
                    \item $[l_1, u_1] <^\sharp [l_2, u_2] =
                    \begin{cases}
                    [1, 1] &\text{ se } u_1<l_2 \\
                    [0, 0] &\text{ se } u_2 \leq l_1 \\
                    [0, 1] &\text{ altrimenti }
                    \end{cases}$
                \end{itemize}

                \underline{\textit{Semantica astratta dei comandi:}}

                $D : \mathbb{V} \rightarrow \mathbb{I}$
                \begin{align*}
                    \llbracket ; \rrbracket^\sharp D &= D\\
                    \llbracket NonZero(e) \rrbracket^\sharp D &=
                    \begin{cases}
                        \bot &\text{ se } [0, 0] = \llbracket e \rrbracket^\sharp D \\
                        D &\text{ se } [0, 0] \neq \llbracket e \rrbracket^\sharp D~ \text{ (contiene anche altri valori)}
                    \end{cases}\\
                    \llbracket Zero(e) \rrbracket^\sharp D &=
                    \begin{cases}
                        D &\text{ se } [0, 0] \subseteq \llbracket e \rrbracket^\sharp D~ \text{ (lo $0$ è uno dei possibili valori)} \\
                        \bot &\text{ se } [0, 0] \not \subseteq \llbracket e \rrbracket^\sharp D~ \text{ (l'intervallo $e$ non contiene $0$)}
                    \end{cases}\\
                    \llbracket x\leftarrow e \rrbracket^\sharp D &= D[x\mapsto \llbracket e\rrbracket^\sharp D]\\
                    \llbracket x\leftarrow M[e] \rrbracket^\sharp D &= D[x\mapsto [-\infty, +\infty]~~ \text{ (elemento $\top$ degli intervalli)}\\
                    \llbracket M[e_1]\leftarrow e_2 \rrbracket^\sharp D &= D
                \end{align*}

    \section{Analisi Dinamica}
        L'analisi dinamica di un programma si basa sulla sua esecuzione e viene utilizzati in vari ambiti: \textit{testing}, \textit{debugging}, \textit{emulation/virtualization}, \textit{profiling/tracing}, \textit{monitoring}, \textit{dynamic slicing}.\\
        Nelle sezioni seguenti ne analizziamo alcuni nel dettaglio.

        \subsection{Testing}
            Si tratta principalmente dell'esecuzione di un programma basata su un campione di dati (molto piccolo) passato come input.

            L'\textbf{obiettivo} è la ricerca di bug/errori/difetti del software, senza correggerli. Questa operazione viene svolta nella fase di testing da professionisti con un'esperienza nella ricerca e identificazione dei bug.
            \newline
            \newline
            \noindent
            Durante la fase di testing si devono ricercare:
            \begin{itemize}
                \item \textbf{mistake}: un'azione umana che ha prodotto un risultato scorretto;
                \item \textbf{fault}: un passaggio scorretto (una definizione di variabile...) all'interno del programma;
                \item \textbf{failure}: la mancata abilità da parte del sistema di svolgere le funzioni richieste;
                \item \textbf{errori}: la differenza tra il valore atteso e il valore effettivamente calcolato/osservato;
                \item \textbf{specifiche}: un documento che specifica, in modo completo e preciso, le richieste e le caratteristiche del sistema e/o dei componenti e spesso delle procedure per verificare quali delle disposizioni sono state soddisfatte.
            \end{itemize}

        \subsection{Debugging}
            L'\textbf{obiettivo} è l'identificazione, l'isolamento e la risoluzione dei problemi/bug. Questa operazione si può svolgere durante la fase di sviluppo del software oppure in una fase apposita in cui vengono sistemati i bug riportati dopo i test.

        \subsection{Program Slicing}
            Si tratta di una tecnica di decomposizione che trasforma un programma originale, cancellandone alcune istruzioni che non hanno alcun effetto sulle \textit{variabili di interesse} nei \textit{punti di interesse}.

            Lo \textit{slice} è il programma trasformato secondo il \textit{criterio di slicing} che descrive i parametri di interesse: \textit{V} (insieme delle variabili di interesse) e \textit{n} (punti di interesse del programma).

            Ci sono diversi motivi per i quali effettuare il \textit{program slicing}: \textit{program debugging}, \textit{testing} (lo slicing riduce i costi del \textit{regresssion testing} dopo una trasformazione del codice), \textit{parallelizzazione},	\textit{compresione di una programma} (effettuare lo slicing aiuta a comprendere come viene eseguito un programma e quali variabili verranno modificate nei vari percorsi) e \textit{mantenimento del software} (per modificare il codice senza \textit{side effects} indesiderati in giro per il programma).
            \newline
            \newline
            \noindent
            Esistono \textbf{diversi tipi di program slicing}:
            \begin{itemize}
                \item \textit{\textbf{Static slicing}}: l'equivalenza tra programma originale e slice deve, implicitamente, essere valida per ogni possibile input;
                \item \textit{\textbf{Conditioned slicing}}: preserva il significato del programma originale per un insieme di input che soddisfa una particolare condizione $\phi$;
                \item \textit{\textbf{Dynamic slicing}}: considera una particolare computazione, e dunque un particolare input, in modo da preservare il significato del programma unicamente per quell'input.
            \end{itemize}

            \noindent
            Esistono, inoltre, \textbf{diverse forme di program slicing}:
            \begin{itemize}
                \item \textit{\textbf{Korel \& Laski} (KL)}: è una forma di slicing molto forte in cui il programma e lo slice devono seguire \textit{paths} identici. Il programma e lo slice hanno la stessa semantica operazionale. Il \textit{path} seguito dallo slice deve essere un \textit{subpath} dell'esecuzione originale.
                \item \textit{\textbf{Iteration Count} (IC)}: richiede che lo slice e il programma si pareggino solo ad una certa iterazione $k$ di un program point $n$ (cioè quando lo statement al program point $n$ viene eseguito per la $k$-esima volta), e non per tutte le iterazioni dello stesso program point.
                \item \textit{\textbf{KL-IC}}(combinazione dei precedenti): richiede che il programma e lo slice seguano \textit{paths} identici e siano uguali solamente ad una particolare iterazione di un certo program point.
            \end{itemize}
\end{document}