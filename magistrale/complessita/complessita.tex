\documentclass[a4paper]{article}
\usepackage[italian]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{csquotes}
\renewcommand{\mkbegdispquote}[2]{\itshape}
\usepackage{palatino}
\usepackage{frontespizio}
\usepackage{mathtools, nccmath}
\usepackage{amsmath}
\usepackage{multicol}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{amssymb}
\usepackage{enumitem}
\usepackage{ifthen}
\usepackage[margin=3cm]{geometry}
\usepackage{booktabs,caption}
\usepackage{subcaption}
\usepackage{fixltx2e}
\usepackage{float}
\usepackage{wrapfig}
\usepackage{epigraph}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{graphicx}
\usepackage[dvipsnames]{xcolor}
\usepackage{subcaption}
\usepackage{tikz}
\usepackage[makeroom]{cancel}
\usepackage{textcomp}
\usetikzlibrary{patterns}
\usetikzlibrary{shapes,arrows,positioning,calc}
\usetikzlibrary{decorations.pathreplacing}
\usepackage{lipsum}
\lstset{language = C,
	basicstyle=\ttfamily\linespread{5} ,
	tabsize = 4,
	morekeywords={VerifyHamCycle, foreach},
	escapechar=",
	showstringspaces=false}
\renewcommand{\lstlistingname}{Algorithm}

\pagestyle{fancy}
\lhead{\nouppercase{\leftmark}}
\rhead{\nouppercase{\rightmark}}
\chead{}
\lfoot{}
\cfoot{\thepage}
\rfoot{}
\renewcommand{\headrulewidth}{0.4pt}
\newtheorem{thm}{Teorema}[subsection]
\newtheorem{coroll}{Corollario}[subsection]
\theoremstyle{definition}
\newtheorem{esempio}{Esempio}[subsection]
\newtheorem{definit}{Definizione}[subsection]
\newtheorem{prop}{Proposizione}[subsection]
\newtheorem{obs}{Osservazione}[subsection]


\usepackage{hyperref}
\usepackage{xcolor}
\hypersetup{
	hidelinks, 
	colorlinks = true,
	linkcolor = black,
}
\usepackage[bottom]{footmisc}

\usepackage[OT1]{eulervm}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Exp}{\mathbf{Exp}}
\newcommand{\p}{\mathbf{P}}
\newcommand{\tim}{\mathbf{Time(n)}}
\newcommand{\np}{\mathbf{NP}}
\newcommand{\npc}{\mathbf{NPC}}
\newcommand{\conp}{\mathbf{CO}\text{-}\mathbf{NP}}
\newcommand{\ph}{\mathbf{PH}}
\newcommand{\ntime}{\mathbf{NTIME}}
\newcommand{\nexp}{\mathbf{NEXP}}
\newcommand{\DP}{\mathbf{DP}}
\newcommand{\Space}{\mathbf{SPACE}}
\newcommand{\pspace}{\mathbf{PSPACE}}
\newcommand{\nspace}{\mathbf{NSPACE}}
\newcommand{\npspace}{\mathbf{NPSPACE}}
\newcommand{\apx}{\mathbf{APX}}
\newcommand{\prob}[1]{\mathbb{#1}}
\newcommand{\instance}[1]{\mathcal{I}(\prob{#1})}
\newcommand{\alg}[1]{\mathcal{#1}}
\newcommand{\compl}[2]{T_\alg{#1}( \vert #2 \vert)}
\newcommand{\compld}[3]{T_\alg{#1}( \vert #2 \vert + \vert #3 \vert)}

\newcommand{\tikzmark}[1]{\tikz[overlay,remember picture,baseline=(#1.base)]
	\node (#1) {\strut};}

\tikzstyle{box} = [rectangle, 
rounded corners, minimum width=1cm, minimum height=1cm,text centered, draw=black]

\newcount\mycount
\begin{document}
 \clearpage
 \begin{titlepage}
 	\centering
 	\vspace*{\fill}
 	{\scshape\LARGE Università degli Studi di Verona \par}
 	\vspace{1.5cm}
 	\line(1,0){145} \\
 	{\huge\bfseries Complessità\par}
 	\line(1,0){145} \\
 	\vspace{0.5cm}
 	{\scshape\Large Riassunto dei principali argomenti\par}
 	\vspace{2cm}
 	{\Large\itshape Matteo Danzi, Marco Colognese, Davide Bianchi\par}
 	\vspace{1cm}
 	
 	\vspace{5cm}
 	\vspace*{\fill}
 	% Bottom of the page
 	{\large \today\par}
 \end{titlepage}
  \thispagestyle{empty}
  \newpage
	
	\tableofcontents
	\listoffigures
	\lstlistoflistings
	
	\newpage

	\section{Introduzione}
	
	\subsection{Cos'è la complessità computazionale}
		Nella teoria della complessità ci si pone la seguente domanda:
		
		\begin{displayquote}
		Come scalano le risorse necessarie per risolvere un problema all'aumentare delle dimensioni del problema?
		\end{displayquote} 

		La teoria della \textit{complessità computazionale} è una parte dell’informatica teorica che si
		occupa principalmente di classificare i problemi in base alla quantità di \textit{risorse computazionali} (come il tempo di calcolo e lo spazio di memoria) che essi richiedono per
		essere risolti. Tale quantità è detta anche \textit{costo computazionale} del problema.
		
	\subsection{Problemi \textit{facili} e \textit{difficili}}
		Vediamo quattro esempi di problemi che classificheremo come facili o difficili:
		\begin{enumerate}
			\item (\textbf{Eulerian Cycle}) Esiste un modo per attraversare ogni arco di un grafo una e una sola volta?
			
			\begin{itemize}
				\item Il problema si può vedere anche nella forma più piccola del problema dei \textit{sette ponti di Königsberg}:
			
				A Königsberg ci sono 7 ponti, esiste un percorso che attraversa tutti i ponti una e una sola volta per poi tornare al punto di partenza?
			
				Se avessi $ n $ ponti e su ogni riva partissero 2 ponti avrei $ 2^n $ possibili percorsi.
			
				\item La \textbf{soluzione di Eulero} dice che un grafo connesso non orientato ha un percorso che parte e inizia esattamente nello stesso vertice e attraversa ogni arco esattamente una volta se e solo se ogni vertice ha grado dispari (grado = numero di archi uscenti).
				
				Se ci sono esattamente due vertici $ v $ e $ u $, di grado dispari, allora esiste un percorso che parte da $ u $ e attraversa ogni arco esattamente una volta e finisce in $ v $.
				
				\item Seguendo quindi la soluzione di Eulero, \textit{quanto costa decidere} se un grafo G ha un tour Euleriano?
				\begin{lstlisting}[basicstyle=\footnotesize\ttfamily]
odd-vertex-num = 0;
foreach vertex v of G
	if (deg(v) is odd)
		increment odd_vertex-num
If(odd-vertex-num is neither 0 nor 2)
	output no Eulerian tour
output Eulerian	
				\end{lstlisting}
				Questo algoritmo ha complessità: $ O(|E| + |V|) $
				
				Il costo e l'algoritmo sono gli stessi se vogliamo \textit{provare} che $ G $ \textit{non} ha un tour Euleriano.
				
			\end{itemize}
			
			\item (\textbf{Hamiltonian Cycle}) Esiste un modo per attraversare ogni nodo di un grafo una e una sola volta? 
			
			Esistono diverse soluzioni:
			\begin{itemize}
				\item Provo tutte le possibilità ogni volta, costo: $ O(2^n) $
				\item Provo tutte le possibili permutazioni, costo: $ O(n!) $
				\item La soluzione migliore ad oggi è: $ O(1.657^n) $
			\end{itemize}
			Alla domanda: \textit{Quanto costa decidere se un grafo ha un tour hamiltoniano?} Non sappiamo rispondere. Non sappiamo dire se il problema ha una soluzione non esponenziale. Per quanto ne sappiamo meglio di $ O(1.657^n) $ non sappiamo fare.
			
			Non sappiamo nemmeno dire se Hamiltonian Cycle è più difficile di Eulerian Cycle.
			\item N è un numero primo?
			
			Il migliore algoritmo conosciuto per decidere se N è un numero primo impiega $ O((\log N)^{6 + \epsilon}) $
			\item Quali sono i fattori primi di un numero?
			
			Ad oggi non conosciamo una procedure per fattorizzare un numero molto grande nei suoi divisori, che non sia provare tutte le possibilità.
		\end{enumerate}
		
		\subsection{Risolvere vs Verificare}
			La seguente tabella riassume in modo generico quanto detto nella sezione precedente riguardo alla difficoltà di risolvere problemi e verificare tali problemi su un istanza.
			
			\begin{table}[h]
				\centering
				\caption{Risolvere vs Verificare}
				\label{tab:intro}
				\begin{tabular}{lcc}
					\toprule
					\textbf{Problema} & \textbf{Risolvere} & \textbf{Verificare} \\
					\midrule
					Eulerian Cycle & \textit{facile} & \textit{facile} \\
					Hamiltonian Cycle & \textit{difficile?} & \textit{facile} \\
					N è primo? & \textit{facile} & \textit{facile} \\
					N ha un numero piccolo di fattori? & \textit{difficile?} & \textit{facile} \\
					\bottomrule
				\end{tabular}
			\end{table}
		
	\section{Problema computazionale}
		Un problema computazionale è una semplice relazione $ p $ che mappa l'insieme \textit{infinito} di possibili input (domande o istanze) con un insieme \textit{finito} (non vuoto) di output, cioè di risposte o soluzioni alle istanze.
		\[
			p\ \colon\ \text{istanze infinite}\ \mapsto\ \text{soluzioni finite alle istanze} 
		\]
		Un problema computazionale non è una singola domanda, ma è una \textbf{famiglia di domande}:
		\begin{itemize}
			\item Una domanda per ogni possibile istanza
			\item Ogni domanda è dello stesso tipo (appartiene alla stessa classe)
		\end{itemize}
		
		\begin{esempio}
			Il seguente esempio è un problema computazionale:
			\begin{itemize}
				\item Input: Qualsiasi grafo G
				\item Domanda: Il grafo G contiene un ciclo Euleriano?
			\end{itemize}
		\end{esempio}
		\begin{esempio}
			Il seguente esempio \textit{non} è un problema computazionale:
			\begin{itemize}
				\item Domanda: È vero che il bianco vince sempre a scacchi, sotto l'ipotesi della giocata perfetta?
			\end{itemize}
			Non è un problema computazionale perché non ho un insieme infinito di possibili partite in input.
		\end{esempio}
		
		\subsection{Risolvere un problema computazionale}
			Risolvere un problema computazionale significa trovare un \textbf{algoritmo}, cioè una procedura che risolve il problema matematico in un numero finito di passi (di computazione elementare), che solitamente include la ripetizione di un operazione. È un procedimento deterministico che mappa l'input sull'output.
			\epigraph{
				Un algoritmo è una procedura \textit{finita}, \textit{definita}, \textit{efficace} e con un input e un output.}{\textit{Donald Knuth -- The Art of Computer Programming }}
			
		\subsection{Complessità di un problema computazionale}
		\paragraph{Misura della complessità.}
			Come misuro la complessità di un problema computazionale? Come faccio a dire quanto è facile rispetto ad altri problemi?
			\begin{itemize}
				\item Do un \textbf{upper bound}: trovo un algoritmo qualsiasi che risolve il problema in modo da calcolare qual è il suo costo.
				\item Do un \textbf{lower bound}: trovo la minima quantità di risorse che ogni algoritmo utilizza per risolvere il problema. Tutti gli algoritmi sono \textit{al minimo} complessi come il limite inferiore che abbiamo stabilito. Nessuno può fare di meglio.
			\end{itemize}
			
			\begin{figure}[h]
				\centering
				\begin{tikzpicture}
					\draw (0,0) rectangle (3,-3);
					\draw[ultra thick, pattern=north east lines, pattern color=gray] (0,-.5) rectangle (3,-2.5);
					\draw[ultra thick] (-.15,-.5) -- (3.15,-.5) node[right, xshift=.1cm] {$ O(n^2) $}; 
					\draw[ultra thick] (-.15,-2.5) -- (3.15,-2.5) node[right, xshift=.1cm] {$ \Omega (n) $};
				\end{tikzpicture}
			\end{figure}
			
			\subsection{Trattabilità di un problema.} La crescita della complessità di un problema è riducibile a 2 categorie fondamentali.
			
			\paragraph{Crescita polinomiale.} Un problema ha crescita polinomiale quando le risorse necessarie alla sua risoluzione sono limitate ad $n^k$, per qualche $k$. Se la taglia del problema aumenta, la sua complessità aumenta di un qualche fattore costante. Infatti, se la taglia dell'input va da $n$ a $2n$ allora la complessità del problema si modifica in $(2n)^k = 2^kn^k$, ovvero aumenta di un fattore $2^k$ (costante). Raggruppiamo nella classe $\p$ i problemi di questo tipo.
			
			\paragraph{Crescita esponenziale.} Un problema ha crescita esponenziale se la necessità di risorse necessarie alla sua risoluzione è proporzionale a $c^n$, per qualche costante $c > 1$. Se la taglia dell'input va da $n$ a  $2n$ allora la richiesta di risorse diventa da $c^n$ a $c^{2n} = c^n * c^n$, aumentando quindi di un fattore che cresce con l'aumentare di $n$. Raggruppiamo nella classe $\Exp$ i problemi di questo tipo.
			
			\section{Le classi di problemi computazionali}
			\paragraph{Notazione e idee di base.}
			Formalmente definiamo un problema come un elemento $ \prob{A} $ di una relazione 
			\[ 
				\mathcal{R} \subseteq \instance{A} \times Sol 
			\] 
			dove: 
			\begin{itemize}
				\item $\instance{A}$ è l'insieme delle istanze del problema $\prob{A}$
				\item $Sol$ è l'insieme delle soluzioni delle istanze di $\prob{A}$
			\end{itemize}
			Si può quindi dire che 
			\[ 
				\forall x \in \instance{A},\ Sol(x) = \lbrace \text{Soluzioni di } x \rbrace 
			\]
			
			Non è restrittivo restringersi ai \textbf{problemi di tipo decisionale}, ovvero quei problemi che hanno come soluzione una risposta del tipo \textit{si} o \textit{no}, quindi i problemi del tipo \[ \prob{A} : \instance{A} \to \lbrace yes, no \rbrace \]
			
			
			L'algoritmo $\alg{A}$ per un problema $\prob{A}$ è un algoritmo che dato il problema, $\forall x \in \instance{A},\ \alg{A}(x) = \prob{A}(x)$. Inoltre, dato un algoritmo $ \alg{A} $, definiamo $\compl{A}{x}$ la sua \textbf{complessità}, cioè il \textit{tempo che impiega} $\alg{A}$ sull'istanza di taglia $\vert x \vert$. Notare che $\vert x \vert$ è la taglia dell'istanza $x$.
			
			\subsection{Classe $ \p $} 
			Intuitivamente la classe $\p$ è definita come la classe di problemi di \textbf{complessità polinomiale}. Introduciamo qui la definizione formale.
			
			\begin{definit}[Classe P]
				Definiamo la classe di problemi $\p$ come l'insieme dei problemi di complessità polinomiale, ovvero 
				\[ 
					\p = \big\lbrace \prob{A}\ \vert\ \exists \alg{A}\ t.c.\ \exists c \text{ costante e }\ \forall x \in \instance{A},\ \ \alg{A}(x) = \prob{A}(x)\ \text{ e }\ \compl{A}{x} \leq \vert x \vert ^ c \big\rbrace 
				\]
			\end{definit}
			
			\begin{esempio}[Eulerian Cycle]
				Un semplice esempio di problema appartenente alla classe $\p$ è il problema del tour euleriano. Per questo problema infatti abbiamo che è un problema computazionale di decisione:
				\begin{itemize}
					\item Input: grafo $ G $
					\item Output: $ yes \Leftrightarrow \exists $ Eulerian Cycle in $ G $.
				\end{itemize}
				Come abbiamo già visto quindi:
				\[
					\exists \alg{A}\ t.c.\ \compl{A}{G} = O(\vert E\vert + \vert V\vert) = O(\vert G\vert) 
				\] 
				Eulerian Cycle $ \in \p\ $ perché $\ \exists \alg{A}\ $ che impiega un tempo che è nell'ordine della taglia di $ G $, in particolare $ \ \exists c \text{ costante } $ dove $ c=1 $.
			\end{esempio}
			
			
			\begin{esempio}[Hamiltonian Cycle]
				Ci chiediamo allora se anche Hamiltonian Cycle $ \in \p\ $ ? La risposta è che non lo sappiamo dire. Quello che sappiamo per questo problema è che:
				\[
					\exists \alg{A}\ t.c.\ \compl{A}{G} = O(a^{\vert G \vert})
				\]
				dove $ a $ è costante.
			\end{esempio}
			
			\subsection{Classe $ \Exp $}
			Dal momento che non sappiamo se alcuni problemi stiano oppure no nella classe $\p$ (dal momento che non si conosce un algoritmo che li risolva in tempo polinomiale), si definisce la classe $\Exp$, che racchiude tutte le istanze di questa tipologia di problemi di \textbf{complessità esponenziale}.
			
			\begin{definit}[Classe $ \Exp $]
				Definiamo la classe di problemi $\Exp$ come la classe di problemi di complessità esponenziale, ovvero 
				\[ 
					\Exp = \big\lbrace \prob{A}\ \vert\ \exists \alg{A}\ t.c.\ \forall x \in \instance{A},\ \alg{A}(x) = \prob{A}(x)\ \text{ e }\ \compl{A}{x} \leq 2^{\vert x \vert ^ c} \big\rbrace 
				\]
			\end{definit}
			
			\begin{esempio}[Hamiltonian Cycle]
				Ci chiediamo se Hamiltonian Cycle $ \in \Exp$ ? Se prendiamo l'algoritmo che prova tutte le combinazioni di archi cioè $ \binom{\vert E \vert}{n} $ per vedere se formano un ciclo hamiltoniano. La complessità di quest'algoritmo è al massimo $\ 2^{\vert E \vert^2} $. 
				
				Se invece prendiamo l'algoritmo che considera tutte le possibili permutazioni dei vertici del grafo abbiamo che la complessità è $ n! $. Quindi il problema Hamiltonian Cycle $ \notin \Exp $
			\end{esempio}
			
			\paragraph{Relazione tra $ \p $ ed $ \Exp $.} La domanda che sorge spontanea è $ \p \subseteq \Exp $ ?
			
			La risposta alla domanda è banalmente \textbf{si}, in quanto, dato un algoritmo $ \alg{B} $ con complessità $\compl{B}{x}$, possiamo dire che 
			\[ 
				\compl{B}{x} = O(\vert x \vert ^ c) = O(2^{\vert x \vert ^ c}) \Rightarrow \prob{A} \in \Exp 
			\]
			
			\paragraph{Problema K-Graph-Colouring.} Analizziamo ora il problema della K-colorabilità di un grafo $ G $:
			\begin{itemize}
				\item Input: $ G $ non orientato.
				\item Output: $ yes \Leftrightarrow \exists\ $ colorazione \textit{propria} dei vertici di $ G $ ovvero:
				\[
					\exists f\ \colon\ v \mapsto \{0,\dots, k-1 \}\quad t.c.\quad \forall (u,v)\in E(G)\quad f(u) \neq f(v)
				\]
			\end{itemize}
			
			\begin{figure}[h!]
				\centering
				\begin{subfigure}{.5\textwidth}
					\centering
					\begin{tikzpicture}
						\node[draw, circle] (a) at (0,0) {};
						\node[draw, circle, fill=black] (b) at (1.5,1) {};
						\node[draw, circle] (c) at (3,0) {};
						\node[draw, circle, fill=black] (d) at (1.5,-1) {};
						\draw (a) -- (b) -- (c) -- (d) -- (a) -- (c);
					\end{tikzpicture}
					\caption{Grafo con colorazione \textit{non} propria}
				\end{subfigure}%
				\begin{subfigure}{.5\textwidth}
					\centering
					\begin{tikzpicture}
						\node[draw, circle, fill=gray] (a) at (0,0) {};
						\node[draw, circle, fill=black] (b) at (1.5,1) {};
						\node[draw, circle] (c) at (3,0) {};
						\node[draw, circle, fill=black] (d) at (1.5,-1) {};
						\draw (a) -- (b) -- (c) -- (d) -- (a) -- (c);
					\end{tikzpicture}
					\caption{Grafo con colorazione propria}
				\end{subfigure}%
				\caption{Esempi di grafi per Graph Colouring}
			\end{figure}
			
			\paragraph{Problema 2-Graph-Colouring.}
			Consiste nel trovare se esiste una 2 colorazione del grafo dato in input in modo tale che un arco non si trovi tra due vertici dello stesso colore. Questo problema corrisponde a dire se il grafo è \textbf{bipartito}, cioè se \textit{posso suddividere il grafo in due classi diverse}. \\
			Per vedere se è bipartito si effettua una \textbf{BFS}, cioè una visita in ampiezza, e si controlla se c'è un ciclo dispari. Se c'è allora non è bipartito e quindi nemmeno 2-colorabile.\\
			
			\noindent
			È 2-colorabile $ \Leftrightarrow $ è Bipartito $ \Leftrightarrow $ non contiene un ciclo dispari. La visita BFS ha una complessità pari a $ O(\vert E \vert + \vert V \vert) $, perciò il problema è risolvibile in tempo polinomiale, perciò possiamo concludere che 2-Graph-Colouring $ \in \p $.
			
			\paragraph{Problema 3-Graph Colouring}
			Il problema 3-Graph Colouring $ \in \p $? Non sappiamo rispondere a questa domanda, poiché non sappiamo se esiste un algoritmo che lo svolga in tempo polinomiale.\\
			Il problema 3-Graph Colouring $ \in \Exp $? Se consideriamo l'algoritmo che prova tutte le possibili colorazioni abbiamo che:
			\[
				3^n \text{ sono le colorazioni dei vertici, dove }\ n = \vert V(G) \vert 
			\]
			Bisogna vedere se ci sono archi monocolore e quindi la complessità diventa:
			\[
				O(3^n\cdot\vert E \vert) = O(3^{2n}) = O((2^{\log_2 3})^{2n}) = O(2^{2n\log_2 3})
			\]
			Perciò possiamo concludere che il problema 3-Graph Colouring $ \in \Exp $.
		
			\subsection{Classe Time(n)}
			
			\begin{definit}[Classe Time(n)]
				Definiamo la classe $ \tim $ come l'insieme dei problemi di complessità lineare, ovvero
				\[
					\tim = \big\lbrace \prob{A}\ \vert\ \exists \alg{B} \text{ per } \prob{A}\quad t.c.\quad
					\forall x \in \instance{A}\quad \compl{\alg{B}}{x} = O(n) = O(f(\vert x \vert))\ \big\rbrace  
				\]
			\end{definit}
			
			\begin{thm}
				$ \forall \alg{B}\quad t.c.\quad \alg{B}(x) = \prob{A}(x)\quad \compl{\alg{B}}{x} > \vert x \vert^c\quad \forall c\text{ costante} $
			\end{thm}
			
			\begin{thm}
				\label{thm:sort}
				Qualsiasi \textbf{algoritmo di ordinamento} che usa \textit{confronti} su $ n $ elementi ha tempo di esecuzione pari a
				\[
					\Omega(n\log n)
				\]
			\end{thm}
			
			\noindent
			Possiamo dire quindi che:
			\begin{itemize}
				\item \textbf{Eulerian Cycle} $ \in \tim $ perché esiste un problema che lo risolve in tempo lineare.
				\item \textbf{Sorting} $ \notin \tim $ per il teorema \ref{thm:sort}.
			\end{itemize}
			
			\begin{figure}[h]
				\centering\vspace{-.2cm}
				\begin{tikzpicture}[scale=.5,every node/.style={scale=0.8}]
					\draw (0,0) circle (3cm);
					\draw (-.5,0) circle (2cm);
					\draw (-1,0) circle (1cm);
					\node at (2.25,0) {$ \Exp $};
					\node at (.75,0) {$ \p $};
					\node at (-1,0) {$ \tim $};
				\end{tikzpicture}
			\end{figure}
			
			\newpage
			
			Possiamo riassumere quindi che:
			\begin{itemize}
				\item \textbf{Eulerian Cycle} $ \in \p $, \textbf{Eulerian Cycle} $ \in \tim $.
				\item \textbf{Hamiltonian Cycle} $ \in \Exp $
				\item \textbf{Hamiltonian Cycle} $ \in \p $ ? non lo sappiamo dire.
				\item \textbf{K-Colouring} $ \in \Exp $
				\item \textbf{K-Colouring} $ \in \p $? \\
				per $ k\geq 3 $ non lo sappiamo dire\\
				per $ k = 2 $ sì.
			\end{itemize}
			Inoltre, con la definizione della classe $ \tim $ si può dire che:
			\[
				\p = \bigcup_{k \geq 0} \mathbf{Time(n^k)}
			\]
			\[
				\Exp = \bigcup_{k\geq 0} \mathbf{Time(2^{n^k})}
			\]
			
		\subsection{Classe $ \np $}
			La classe $ \np $ (\textit{non deterministic polinomial time}) è la classe di problemi tali che se la soluzione per un'istanza del problema è \textit{yes}, allora è facile verificarlo.
			
			\begin{definit}(Classe $ \np $)
				\begin{align*}
					\np = \big\lbrace & \prob{A} \quad \big| \quad \exists \alg{B}(\stackrel{x}{\cdot}, \stackrel{w}{\cdot})\quad t.c.\quad 
					\compld{\alg{B}}{x}{w}= O((\vert x\vert + \vert w\vert)^c) \\
					& \forall x \in \instance{\prob{A}}\quad \prob{A}(x) = yes\ \Leftrightarrow\ \exists w\ t.c.\quad \vert w \vert = O(\vert x\vert^d)\ \text{ e }\ \alg{B}(x, w) = yes 
					\big\rbrace
				\end{align*}
					
				dove:
				\begin{itemize}
					\item $ \alg{B}(\stackrel{x}{\cdot}, \stackrel{w}{\cdot}) $ è detto \textbf{verificatore} per $ \prob{A} $. Se la risposta di $ \prob{A} $ esiste, allora $ \alg{B} $ dice \textit{yes}. Il verificatore impiega \textbf{tempo polinomiale} nella taglia dell'istanza per rispondere.
					\item $ x $ è l'istanza
					\item $ w $ è il certificato.
				\end{itemize}
				
			\end{definit}
			
			\paragraph{Hamiltonian Cycle $ \in $ NP ?} Per vedere se il problema Hamiltonian cycle appartiene alla classe $ \np $ dobbiamo costruire un verificatore $ \alg{B} $ che agisca in tempo polinomiale.
			
			\newpage
			\begin{lstlisting}[mathescape=true, frame=tb, caption={Verificatore per HamCycle}]
VerifyHamCycle(G = (V,E), C=$ x_1, \dots, x_n $)
	if r != |V|: return $ no $ "\tikzmark{a}"
	foreach v$ \in $ V 
		if v non appare in C: return $ no $ "\tikzmark{c}"
	for i=1 to n-1
		if $ ( x_i, x_{i+1} )\notin $ E: return $ no $ "\tikzmark{b}"
	if $ ( x_1, x_n )\notin $ E: return $ no $ "\tikzmark{d}"
	return $ yes $
			\end{lstlisting}
			\begin{tikzpicture}[overlay, remember picture,decoration={brace,amplitude=2pt}]
				\draw[decorate,thick] ($ (a.east) +(2.7,-0.1) $) -- ($ (a.east) +(2.7,-.5) $)
				node [midway,right, xshift=.2cm] {$ O(\vert w\vert) $};
				\draw[decorate,thick] ($ (c.east) +(0,.4) $) -- ($ (c.east) +(0,-.5) $)
				node [midway,right, xshift=.2cm] {$ O(\vert V\vert\cdot\vert C\vert) $};
				\draw[decorate,thick] ($ (b.east) +(1.5,.4) $) -- ($ (b.east) +(1.5,-.5) $)
				node [midway,right, xshift=.2cm] {$ O(\vert C\vert) $};
				\draw[decorate,thick] ($ (d.east) +(2.6,-0.1) $) -- ($ (d.east) +(2.6,-.5) $)
				node [midway,right, xshift=.2cm] {$ O(1) $};
			\end{tikzpicture}
		Il tempo di esecuzione del verificatore è polinomiale e quindi posso dire che Hamiltonian Cycle $ \in \np$ .
			
		\paragraph{K-Colouring $ \in $ NP ?} Per vederlo costruisco il verificatore:
		\begin{lstlisting}[mathescape=true, frame=tb, caption={Verificatore per K-Colouring}]
VerifyK-Colouring(G = (V,E), $ f(v_1), \dots, f(v_n) $)
	foreach $ E(u,v)  $
		if $ f(u) = f(v) $: return $ no $ "\tikzmark{a}"
	for i=1 to n
		if $ f(v_i) \geq K $: return $ no $ "\tikzmark{b}"
	return $ yes $
		\end{lstlisting}
		\begin{tikzpicture}[overlay, remember picture,decoration={brace,amplitude=2pt}]
			\draw[decorate,thick] ($ (a.east) +(0,.4) $) -- ($ (a.east) +(0,-.5) $)
			node [midway,right, xshift=.2cm] {$ O(\vert E\vert) $};
			\draw[decorate,thick] ($ (b.east) +(0.2,.4) $) -- ($ (b.east) +(0.2,-.5) $)
			node [midway,right, xshift=.2cm] {$ O(\vert V\vert) $};
		\end{tikzpicture}
		Il tempo di esecuzione del verificatore è polinomiale e quindi posso dire che K-Colouring $ \in \np$ .
		
		\paragraph{P $ \subseteq $ NP ?} Vogliamo capire in che classe è $ \np $. Se include la classe $ \p $ allora significa che un problema che appartiene a quest'ultima, se lo sappiamo risolvere, lo sappiamo anche verificare. Infatti se $ \prob{A} \in \p $ dobbiamo dimostrare che esiste un verificatore. Tale verificatore per $ \prob{A} $ sarà: $\quad \alg{B}'(x,w) = \alg{B}(x)\ $ privo di certificato.
		Dobbiamo dimostrare che se l'istanza è \textit{yes} allora $ \alg{B}(x) = yes $ altrimenti $ \alg{B}(x) = no $.
		
		\paragraph{NP $ \subseteq $ Exp ? } Vogliamo capire in che classe è $ \np $
		
		Possiamo supporre che $ \p \subseteq \np \subseteq \Exp $.
		
		\begin{figure}[h!]
			\centering
			\begin{tikzpicture}
			\draw (0,0) ellipse (3.5cm and 2cm);
			\draw (-.5,0) ellipse (2.5cm and 1.5cm);
			\draw (-1,0) ellipse (1cm and 1cm);
			\node at (2.5,.5) {$ \Exp $};
			\node (np) at (.75,.5) {$ \np $};
			\node (p) at (-1,.5) {$ \p $};
			\node at ($ (p.south) +(0,-.2) $) {eulercycle};
			\node at ($ (p.south) +(0,-.5) $) {2-colouring};
			\node[rotate=20] at ($ (np.south) +(0,-.7) $) {hamcycle};
			\node[rotate=20] at ($ (np.south) +(-.5,-1.2) $) {k-colouring};
		\end{tikzpicture}
		\end{figure}
		
	\section{Riduzione alla Karp tra problemi di decisione}
		\begin{definit}[Riduzione alla Karp]
			Un problema di decisione $ \prob{A} $ si riduce alla Karp al problema $ \prob{B} $: $ \quad \prob{A} \leqslant_K \prob{B} \quad $ se esiste un algoritmo polinomiale $ \alg{A} $ tale che 
			\[
				\forall x \in \instance{A},\ \prob{B}(\alg{A}(x)) = yes \ \Leftrightarrow \ \prob{A}(x) = yes
			\]
		\end{definit}
	ossia se è possibile tramite $\alg{A}$ ridurre un'istanza dell'insieme $\instance{A}$ ad un'istanza del problema $\prob{B}$. L'algoritmo $\alg{A}$ è l'algoritmo di riduzione.\\
	NB: La riduzione alla Karp serve a dimostrare che $\prob{B}$ NON è più facile di  $\prob{A}$\\
		
		\begin{prop}
			Se $ \prob{A} \leqslant_K \prob{B} \quad\text{ e }\quad \prob{B}\in \p \quad \Rightarrow\quad \prob{A}\in\p $
		\end{prop} 
		\begin{prop}
			Se $ \prob{A} \leqslant_K \prob{B} \quad\text{ e }\quad \prob{B}\in \np \quad \Rightarrow\quad \prob{A}\in\np $
		\end{prop} 
		\begin{prop}
			Se $ \prob{A} \leqslant_K \prob{B} \quad\text{ e }\quad \prob{A}\notin \p \quad \Rightarrow\quad \prob{B}\notin\p $
		\end{prop} 
		
		%Come effettivamente svolgiamo le trasformazioni?
		
		\subsection{Problema SAT}
			\begin{definit}[SAT]
				Il problema di soddisfacibilità di una formula booleana è definito nel seguente modo:
				\begin{itemize}
					\item Input: formula booleana : $ \phi (x_1, \dots, x_n) = C_1 \wedge C_2 \wedge \dots \wedge C_n $\\
					Dove: \begin{itemize}
						\item $ C_i = l_{i1} \vee l_{i2} \vee \dots \vee l_{ik} $ (clausola)
						\item $ l_{ij} = x_k \text{ oppure } \bar{x}_k $ (letterale)
					\end{itemize}
					\item Output: \textit{yes} $ \Leftrightarrow\quad\exists a_1\dots a_n \in {T,F}^n\quad t.c.\quad \phi(a_1,\dots, a_n) = T $ 
				\end{itemize}
			\end{definit}
			
			\begin{esempio}
				$ \phi(x_1, x_2, x_3) = (x_1\vee \bar{x}_2\vee x_3)\wedge (\bar{x}_1\vee\bar{x}_2\vee x_3) \wedge (x_1\vee \bar{x}_3) $ \\
				Assegnamento che soddisfa la formula booleana $ \phi(x_1, x_2, x_3) $:
				\begin{align*}
					x_1 =& T\quad x_2 = F\quad x_3 = F \\
					a_1 =& T\quad a_2 = F\quad a_3 = F
				\end{align*}
			\end{esempio}
			
		\paragraph{SAT $ \in $ NP ?} Ci chiediamo se il problema SAT sta nella classe $ \np $. Vediamo dunque se esiste un certificato e un verificatore che attesta, dato una formula booleana, se essa è soddisfacibile in tempo polinomiale.
		\begin{itemize}
			\item Si può notare facilmente che il certificato è un assegnamento per la formula booleana, dunque è polinomialmente correlato alla grandezza delle variabili della formula, sarà al massimo $ n $.
			\item Il verificatore viene costruito analizzando la formula booleana, controllando ogni letterale di ciascuna clausola. Ho quindi $ m\times n \times n $ controlli, dove $ m = $ numero di clausole, $ n = $ numero di letterali. Il verificatore è quindi polinomiale.
		\end{itemize}
		Possiamo concludere che il problema SAT $ \in \np $. Questa affermazione si può tradurre con: \textit{data una formula booleana di cui sappiamo essere soddisfacibile, allora è facile (polytime) costruire un verificatore che attesta che essa è SAT.}
		
		\paragraph{Problema K-SAT:} è il problema SAT in cui l'input ha come restrizione il vincolo che ogni clausola ha esattamente $ k $ letterali.
		
		\begin{esempio}[3-SAT]
			$ \phi(x_1, x_2, x_3) = (x_1\vee x_2 \vee x_3)\wedge (\bar{x}_1\vee x_2 \vee x_3 ) \wedge (\bar{x}_1 \vee x_2\vee \bar{x}_3) $
		\end{esempio}
		  
		\subsection{Alcuni esempi di riduzioni tra problemi}
			\paragraph{K-colouring $ \leq_K $ (K+1)-colouring} Vediamo se il problema (K+1)-colouring non è più facile del problema K-colouring. Dobbiamo in sostanza dimostrare che decidere se possiamo colorare un grafo con $ k+1 $ colori non è più facile che decidere se possiamo colorare un grafo con $ k $ colori. \textbf{N.B.:} da notare che i due grafi non sono necessariamente uguali, parliamo di qualsiasi grafo che appartiene al problema.
			
			\begin{align*}
				\alg{A}\ : \quad & x\in \mathcal{I}(K-COL)\quad \mapsto\quad \alg{A}(x)\in \mathcal{I}((K+1)-COL) \\
							 & K-COL(x) = yes\quad \Leftrightarrow\quad (K+1)-COL(\alg{A}(x)) = yes   
			\end{align*}
			
			Prendiamo quindi il grafo $ G' $:
			
			\begin{center}
				\begin{tikzpicture}[scale=0.7,every node/.style={scale=0.8}]
					\draw (0,0) ellipse (3cm and 2cm);
					\draw (-1,-.5) circle (1cm);
					\node at (0,1.7) {$ G' = \alg{A}(x) $};
					\node at (-1,-.5) {$ G = x$};
					\node[draw, circle] (a) at (-.5,0) {}; \node[draw, circle] (b) at (-.5,-.9) {};
					\node[draw, circle] (c) at (-1.3,0) {};
					\node[draw, circle] (d) at (1,1) {};
					\draw[bend right] (d) to (c); \draw[bend left] (d) to (b); \draw (d) -- (a);
				\end{tikzpicture}
			\end{center}
			per cui
			\begin{align*}
				G &= (V, E) \\
				G'&= (V \cup \{v'\}, E \cup {(v, u')\ \vert\ v \in V})
			\end{align*}
			in tempo lineare e quindi sotto il polinomiale riesco a costruire il grafo G'.\\
			Se G è K-colorabile allora G' è (K+1)-colorabile. Mi basta assegnare a $ v' $ il colore $ k $ (il k+1-esimo colore) e mantenere la colorazione di G.\\
			Se G non è K-colorabile allora G' non è K+1-colorabile. Equivale a dire che se G' è K+1-colorabile allora G è k-colorabile. Quindi se $ v' $ ha un colore $ f(v') = x $ allora ogni $ v \in V(G) $ ha un colore $ f(v') \neq x $, al più usano k colori.
			
			Da questa dimostrazione ricaviamo anche che 2-col $ \leq_K $ 3-col $ \leq_K $ 4-col $ \leq_K $ 5-col
			
			
			\paragraph{SAT $ \leq_K $ 3-SAT} Vogliamo dimostrare che data una formula booleana $ \phi $ CNF esiste una trasformazione polytime che mi porta a una formula booleana $ \phi' $ 3CNF (ogni clausola ha esattamente 3 letterali). E inoltre che $ \phi $ è soddisfacibile se e solo se $ \phi' $ è soddisfacibile.
			
			Possiamo iniziare dicendo che $ \ (x_1 \vee x_2) \equiv (x_1 \vee x_1 \vee x_2) $. Le clausole più piccole possono essere espanse. Seguendo questa intuizione arriviamo a dire che:
			\begin{align*}
				&(l_1 \vee l_2 \vee l_3 \vee \dots \vee l_k)\quad \rightsquigarrow\quad \\
				&(l_1\vee l_2\vee z_1) \wedge (\bar{z}_1\vee l_3 \vee z_2) \wedge (\bar{z}_2 \vee l_4\vee z_3)
				\wedge (\bar{z}_3 \vee l_5 \vee z_4) \wedge \dots \wedge (\bar{z}_{k-1} \vee l_{k+1} \vee z_k)
			\end{align*}
			
			Dimostriamo che se $ \phi $ non è soddisfacibile allora non lo è neanche $ \phi' $.
			\begin{itemize}
				\item Prendiamo $ \phi = (x_1 , \dots, x_n) $. Per questa formula prendiamo un assegnamento $ a_1, \dots, a_n $ che non la rende soddisfacibile, quello in cui ogni letterale viene assegnato a F.
				\item Prendiamo dunque $ \phi' = (x_1, \dots, x_n, z_1, \dots z_r) $. Per questa formula prendiamo lo stesso assegnamento di $ \phi $ e vediamo cosa succede con i letterali $ z $:
			\[
				(\underset{F}{l_1} \vee \underset{F}{l_2}\vee \underset{V}{z_1}) 
				\wedge (\underset{F}{\bar{z}_1}\vee \underset{F}{l_3} \vee \underset{V}{z_2}) 
				\wedge (\underset{F}{\bar{z}_2}\vee \underset{F}{l_4} \vee \underset{V}{z_3}) 
				\wedge (\underset{F}{\bar{z}_3}\vee \underset{F}{l_5} \vee \underset{V}{z_4})  \wedge 
				\dots 
				\wedge (\underset{F}{\bar{z}_{k-3}}\vee \underset{F}{l_{k-1}} \vee \underset{F}{l_{k}}) 
			\]
			risulta che l'ultimo letterale $ z_{k-3} $ è falso, e quindi $ \phi' $ non è soddisfacibile.
 			\end{itemize}
 			
 			\paragraph{K-COL $ \leq_K $ K-SAT} Vogliamo dimostrare che il problema di colorare un grafo con k colori è riducibile al problema di soddisfacibilità di una formula booleana k-CNF.
 			
 			Cerchiamo un modo per esprimere in modo logico il fatto che due nodi adiacenti non abbiano lo stesso colore.
 			Supponiamo che il nodo $ v $ abbia colore $ i $ e il nodo $ u $ abbia colore $ i $ con $ i= 0,1, \dots, k-1 $.
 			Per ogni $ v \in V $: $ \quad x_0^{(v)} \ x_1^{(v)} \ x_2^{(v)} \dots \ x_{k-1}^{(v)}  $ dove $ x_i^{(v)} = T $ se il vertice $ v $ ha colore $ i $.
 			
 			Ci chiediamo quindi quand'è che la formula è K-colorabile?
 			\[
	 			\forall v \in V
	 			\begin{cases}
		 			x_0^{(v)} \vee x_1^{(v)} \vee x_2^{(v)} \vee \dots \vee x_{k-1}^{(v)} \quad \text{ogni vertice ha un colore}\\ \\
		 			\overline{x_i^{(v)} \wedge x_j^{(v)}} = \overline{x_i^{(v)}} \vee \overline{x_j^{(v)}} \quad \forall i,j
	 			\end{cases}
 			\]
	 		\[
		 		\forall e =(u, v) \in E\ \text{ i due vertici non devono avere lo stesso colore}
	 		\]
	 		\[
		 		\forall i \quad \overline{x^{(v)}_i \wedge x_i^{(u)}} =
		 		\overline{x_i^{(v)}} \vee \overline{x_i^{(u)}}
	 		\]
	 		
	 		\begin{esempio}

	 			Prendiamo per esempio il seguente grafo:	 
	 			\begin{center}
					\begin{tikzpicture}
						\node[draw, circle] (u) at (0,0) {u};
						\node[draw, circle] (v) at (0,-1.5) {v};
						\node[draw, circle] (z) at (1.5,-.75) {z};
						\draw (u) -- (v) -- (z) -- (u);
					\end{tikzpicture}
				\end{center}
	 			La formula booleana corrispondente sarà:
	 			\begin{align*}
		 			&\tikzmark{a}(x_0^{(u)} \vee x_1^{(u)} \vee x_2^{(u)}) \wedge 
		 			\tikzmark{c}(\overline{x_0^{(u)}} \vee \overline{x_1^{(u)}}) \wedge
		 			(\overline{x_0^{(u)}} \vee \overline{x_2^{(u)}}) \wedge
		 			(\overline{x_1^{(u)}} \vee \overline{x_2^{(u)}})\tikzmark{d} \wedge \\
		 			&(x_0^{(v)} \vee x_1^{(v)} \vee x_2^{(v)}) \wedge 
		 			(\overline{x_0^{(v)}} \vee \overline{x_1^{(v)}}) \wedge
		 			(\overline{x_0^{(v)}} \vee \overline{x_2^{(v)}}) \wedge
		 			(\overline{x_1^{(v)}} \vee \overline{x_2^{(v)}}) \wedge \\
		 			&\tikzmark{b}(x_0^{(z)} \vee x_1^{(z)} \vee x_2^{(z)}) \wedge 
		 			(\overline{x_0^{(z)}} \vee \overline{x_1^{(z)}}) \wedge
		 			(\overline{x_0^{(z)}} \vee \overline{x_2^{(z)}}) \wedge
		 			(\overline{x_1^{(z)}} \vee \overline{x_2^{(z)}}) \wedge \\
		 			&\tikzmark{e}(\overline{x_0^{(v)}} \vee \overline{x_0^{(u)}}) \wedge
		 			(\overline{x_1^{(v)}} \vee \overline{x_1^{(u)}}) \wedge
		 			(\overline{x_2^{(v)}} \vee \overline{x_2^{(u)}}) \wedge \\
		 			&(\overline{x_0^{(v)}} \vee \overline{x_0^{(z)}}) \wedge
		 			(\overline{x_1^{(v)}} \vee \overline{x_1^{(z)}}) \wedge
		 			(\overline{x_2^{(v)}} \vee \overline{x_2^{(z)}}) \wedge \\
		 			&\tikzmark{f}(\overline{x_0^{(z)}} \vee \overline{x_0^{(u)}}) \wedge
		 			(\overline{x_1^{(z)}} \vee \overline{x_1^{(u)}}) \wedge
		 			(\overline{x_2^{(z)}} \vee \overline{x_2^{(u)}})
	 			\end{align*}
				
				\begin{tikzpicture}[overlay, remember picture,decoration={brace,amplitude=3pt}]
					\draw[decorate,thick] ($ (b) +(-0.3,-.2) $) -- ($ (a) +(-0.3,.2) $)
					 node[midway, left, align=left] {Ogni vertice\\ ha un colore}; 
					\draw[decorate,thick] ($ (f) +(-0.3,-.2) $) -- ($ (e) +(-0.3,.2) $)
					 node[midway, left, align=left] {Ogni arco ha\\ colori diversi}; 
					\draw[decorate,thick] ($ (c) +(0,.5) $) -- ($ (d) +(0,.5) $)
					node[midway, above, align=left] {Un vertice non\\ può avere 2 colori}; 
					
				\end{tikzpicture}
	 		\end{esempio}
	 	La trasformazione è polinomiale? La complessità della trasformazione è:
	 	\[
		 	\vert V \vert \cdot \Big(K + 2 \binom{k}{2}\Big) + \vert E \vert K\cdot 2 \quad \leq\quad
		 	(\vert E \vert + \vert V \vert) K^2
	 	\]
		Quindi è polinomiale.
	 	
	 \subsection{Problema NAE-K-SAT}
		 \paragraph{NAE-K-SAT (Not All Equivalent-K-SAT):} 
		 \begin{itemize}
		 	\item Input: $ \phi $ K-CNF $ \quad \phi:\ \{T,F\}^n \mapsto \{T,F\} $
		 	\item Output: $ yes \ \Leftrightarrow \ \exists \underline{a} \in \{T,F\}^n \quad t.c.\quad \phi(\underline{a}) = T \ $ e, in ogni clausola $ \ C_i = l^{(i)}_1 \vee l^{(i)}_2 \vee \dots \vee l^{(i)}_k \ $ con $ \ \underline{a} \ $, almeno un $ \ l^{(i)}_j \ $ è vero e almeno un $ \ l^{(i)}_j \ $ è falso.
 		 \end{itemize}
 		 
 		 \begin{esempio}
 		 	\[
	 		 	\phi(x_1, x_2, x_3) = (\overline{x_1} \vee x_2 \vee x_3) \wedge (\overline{x_1} \vee \overline{x_2} \vee \overline{x_3})
 		 	\]
		 	\begin{align*}
	 		 	x_1 =& F \quad x_2 = F \quad x_3 = F \quad \text{\textit{non} è NAE-K-SAT}\\
	 		 	x_1 =& F \quad x_2 = T \quad x_3 = F \quad \text{è NAE-K-SAT}\\
			\end{align*}
		\end{esempio}
 		 
		\begin{prop}
			Se $ \ \underline{a} \ $ è un assegnamento che soddisfa $ \phi $ (è NAE), allora anche il negato $ \ \overline{\underline{a}} \ $ soddisfa  $ \phi $ (è NAE).
		\end{prop}
 		 
		\paragraph{3-SAT $ \leq_K $ NAE-4-SAT} Vogliamo dimostrare che data una qualsiasi formula $\ \phi \ $ 3-CNF la trasformo in una formula $\ \psi \ $ 4-CNF in tempo polinomiale.
		\[
	 		 \phi \ \text{3-CNF} \ \longmapsto \ \psi \ \text{4-CNF}
		\]
		\begin{align*}
			\phi &= C_1 \wedge C_2 \wedge \dots \wedge C_n \quad C_i = l^{(i)}_1 \vee l^{(i)}_2 \vee l^{(i)}_3 \quad i = 1 \dots n \\
			\psi &= C'_1 \wedge C'_2 \wedge \dots \wedge C'_n \quad C'_i = l^{(i)}_1 \vee l^{(i)}_2 \vee l^{(i)}_3 \vee z \quad i = 1 \dots n \\
		\end{align*}
		Per creare $ \psi $ espando le variabili e ne aggiungo sempre una. 
		La trasformazione da $ \phi $ a $ \psi $ è polinomiale nella taglia della formula $ \phi $, perché la scorro tutta per creare $ \psi $.\\
		Ora dobbiamo dimostrare che se $ \phi $ è soddisfacibile allora anche $ \psi $ è soddisfacibile:
		\begin{itemize}
			\item $ \phi $ è soddisfacibile $ \ \Rightarrow \ \exists \underline{a} \in \{T,F\}^n \quad t.c.\quad \phi(\underline{a}) = T $.
			\item Se prendiamo l'assegnamento $ \ \underline{b} = \underline{a} \quad z = F \quad \psi(\underline{b}) = T\ $ e ogni clausola ha un letterale a FALSE.
			\item Vogliamo dimostrare che se esiste un assegnamento $ \underline{b} $ che soddisfa $ \psi $ allora esiste un assegnamento $ \underline{a} $ che soddisfa $ \phi $.
			\item Se secondo $ \underline{b}\quad z = F\ $ allora, la parte rimanente di $ \underline{b} $ soddisfa $ \psi $
			\item Se secondo $ \underline{b}\quad z = T\ $ allora, lo nego e torno al primo caso. Perciò se $ \psi $ è nae-soddisfatta con $ \ z = F\ $ allora $ \phi $ è soddisfatta. 
		\end{itemize}
		
		\paragraph{NAE-3-SAT $ \leq_K $ 3-COL } Vogliamo dimostrare che data la formula $ \phi $ 3-CNF esiste una trasformazione polinomiale che la rende un grafo $ G $ tale che $ \phi $ è NAE-soddisfacibile se e solo se il grafo $ G $ è 3-colorabile.
			 		
 		Mappo variabili (letterali) che possono valere T o F, su vertici (elementi del grafo) che hanno colore $ 0, 1, 2 $.
 		
 		\begin{tikzpicture}
	 		\node (x) at (0,0) {$ x $}; \node (t) at ($ (x) +(.75,.5)$) {$ T $}; \node (f) at ($ (x) +(.75,-.5)$) {$ F $}; 
	 		\draw (x) -- (t); \draw (x) -- (f); 
	 		\node at ($ (x) +(2,0)$) {$ \longmapsto $};
	 		\node (r) at ($ (x) +(3,0)$) {$ r $}; \node (0) at ($ (r) +(.75,.75)$) {$ 0 $}; \node (1) at ($ (r) +(.75,0)$) {$ 1 $};\node (2) at ($ (r) +(.75,-.75)$) {$ 2 $}; 
	 		\draw (r) -- (0); \draw (r) -- (1); \draw (r) -- (2); 
 		\end{tikzpicture}
 		 
 		 Partendo dalla formula $ \ \phi(x_1, x_2, x_3) = (x_1\vee x_2\vee x_3)\wedge(\overline{x}_1\vee x_2\vee\overline{x}_3) \ $ costruiamo il grafo nel seguente modo:
 		 \begin{itemize}
 		 	\item Creo un nodo per ogni letterale e per il suo negato, poi aggiungo un vertice perché per ogni vertice $ x $ uso la stessa coppia di colori.
 		 	\item Per ogni clausola metto un triangolo che corrisponde ai letterali della clausola
 		 	\item Se ho una 3-colorazione ho un assegnamento corrispondente per la clausola che mi mette un letterale T e uno F.
 		 	\item Ora aggiungo gli archi, collego i letterali che hanno valori di verità opposti.
 		 \end{itemize}

		Se associamo $ 0\mapsto T $, $ 1\mapsto F $, e 2 libero, abbiamo il seguente risultato:
 		 
 		 \begin{figure}[h!]
 		 	\centering
 		 	\begin{tikzpicture}
	 		 	\node[draw, circle] (s) at (5,1.5) {$ 2 $};
			 	\node[draw, circle] (x1) at (0,0) {$ x_1 $}; \node[draw, circle] (nx1) at (2,0) {$ \overline{x}_1 $}; 
			 	\node[draw, circle] (x2) at (4,0) {$ x_2 $}; \node[draw, circle] (nx2) at (6,0) {$ \overline{x}_2 $}; 
			 	\node[draw, circle] (x3) at (8,0) {$ x_3 $}; \node[draw, circle] (nx3) at (10,0) {$ \overline{x}_3 $}; 
			 	\draw (s) -- (x1); \draw (s) -- (x2); \draw (s) -- (x3); \draw (s) -- (nx1); \draw (s) -- (nx2);
			 	\draw (s) -- (nx3); \draw (x1) -- (nx1); \draw (x2) -- (nx2); \draw (x3) -- (nx3); 
			 	\node[draw, circle] (c1) at (3,-1) {$ x_1 $}; \node[draw, circle] (c2) at (2,-2.5) {$ x_2 $}; 
			 	\node[draw, circle] (c3) at (4,-2.5) {$ x_3 $};
			 	\node[draw, circle] (b1) at (7,-1) {$ \overline{x}_1 $}; \node[draw, circle] (b2) at (6,-2.5) {$ x_2 $}; 
			 	\node[draw, circle] (b3) at (8,-2.5) {$ \overline{x}_3 $};
			 	\draw (c1) -- (c2); \draw (c1) -- (c3);  \draw (c2) -- (c3);
			 	\draw (b1) -- (b2); \draw (b1) -- (b3);  \draw (b2) -- (b3);
			 	\draw (c1) -- (nx1); \draw (c2) -- (nx2); \draw (c3) -- (nx3);
			 	\draw (b1) -- (x1); \draw (b2) -- (nx2); \draw (b3) -- (x3);
			 	\node at ($ (x1.north) +(0,.3) $) {0};\node at ($ (nx1.north) +(0,.3) $) {1}; 
			 	\node at ($ (x2.north) +(0,.3) $) {0};\node at ($ (nx2.north) +(0,.3) $) {1};
			 	\node at ($ (x3.north) +(0,.3) $) {1};\node at ($ (nx3.north) +(0,.3) $) {0};
			 	\node at ($ (c1.east) +(.3,0) $) {0};
			 	\node at ($ (c2.north) +(0,.3) $) {1};
			 	\node at ($ (c3.north) +(0,.3) $) {2};
			 	\node at ($ (b1.north) +(0,.3) $) {1};
			 	\node at ($ (b2.west) +(-.3,0) $) {2};
			 	\node at ($ (b3.east) +(.3,0) $) {0};
	 		\end{tikzpicture}
 		 \end{figure}
 		 
	 Perciò la trasformazione garantisce che se $ \exists \underline{a} \ \ t.c.\ \ \phi(\underline{a}) $ è nae-soddisfatta allora esiste una 3-colorazione per il grafo G che associa ai valori di verità i colori in modo tale da rendere G 3-colorabile. È facile vedere anche l'implicazione nel verso opposto.
	 
	 \subsection{Transitività della riduzione alla Karp}
		 La riduzione $ \leq_K $ è transitiva, ciò implica che:
		 \[
			 \prob{A} \leq_K \prob{B}\ \text{ e }\ \prob{B}\leq_K \prob{C} \ \Rightarrow \ \prob{A}\leq_K \prob{C}
		 \]
		 in particolare abbiamo che:
		 \begin{align*}
			 \prob{A} &\leq_K \prob{B} \quad \exists \alg{A} \text{ polytime } \ x\in \instance{A},\ \alg{A}(x)\in \instance{B}\quad \prob{A}(x) = yes \Leftrightarrow \prob{B}(\alg{A}(x)) = yes \\
			 \prob{B} &\leq_K \prob{C} \quad \exists \alg{B} \text{ polytime } \ y\in \instance{B},\ \alg{B}(y)\in \instance{C}\quad \prob{B}(y) = yes \Leftrightarrow \prob{C}(\alg{B}(y)) = yes
		 \end{align*}
		 Perciò
		 \[
			 \forall x \in \instance{A},\ \alg{B}(\alg{A}(x)) \in \instance{C} \quad \prob{A}(x) = yes \Leftrightarrow
			 \prob{C}(\alg{B}(\alg{A}(x))) = yes \quad \Rightarrow \ \ \prob{C}(x) = \alg{B}(\alg{A}(x))
		 \]

 	\subsection{Problema Reachability}
	 	\begin{itemize}
	 		\item Input: Grafo G diretto, due nodi $ s $ e $ t $.
	 		\item Output: $ yes $ $ \Leftrightarrow $ esiste un cammino che va da $ s $ a $ t $.
	 	\end{itemize}
	 	Quanto costa risolvere Reachablity?\\
	 	Una possibile soluzione potrebbe essere applicare BFS partendo da $ s $. Se si trova $ t $, allora ritorno $ yes $, altrimenti $ no $. Questo procedimento richiede $ O(\vert V\vert+\vert E\vert) $. Quindi \textit{Reachability} $ \in \p $ 
	 	
	 \section{Riduzione alla Turing tra problemi di decisione}
		 \begin{definit}[Riduzione alla Turing]
		 	$ \prob{A}\leq_T \prob{B} \ $ se esiste un algoritmo con complessità polinomiale $ \alg{A} $ che data un'istanza $ \ x \in \instance{A} \ $ utilizzando chiamate ad un \textit{oracolo} per $ \prob{B} $ che hanno costo $ O(1) $, $ \ \alg{A}(x) = \prob{A}(x) $.\\
		 	\textit{2-SAT} $\leq_T$ \textit{Reachability}: non vale la riduzione alla \textit{Karp} perché faccio più chiamate a \textit{Reachability}.
		 \end{definit}
	 
	\section{Classe di problemi NP-Completi}
		\begin{definit}(Classe NPC)
			Un problema $\ \prob{A}\ $ è NP-completo (NPC) se
			\begin{itemize}
				\item $ \prob{A} \in \np $
				\item $ \prob{A}\ $ è \textit{NP-hard}, cioè se $ \ \forall \prob{B} \in \np \quad \prob{B}\leq_K \prob{A} $
			\end{itemize}
		
		\begin{align*}
			\mathbf{NP}\text{\textbf{-completo}}\ = \big\lbrace & \exists p(x) = x^k,\ \exists V(\cdot, \cdot) \quad t.c.\quad T_V(a, b) = \mathcal{O}\big(p(|a|+|b|)\big) \\
			&\text{ e } \ \forall x \in \mathcal{I}(\mathbb{A}),\ \mathbb{A}(x)=yes \Leftrightarrow \exists w \in \{0, 1 \}^{p(|x|)},\ V(x, w)=yes \big\rbrace
		\end{align*}
		Se $\mathbb{A}$ è \textit{NP-Completo} e $\mathbb{A}\in P$, allora \textit{P = NP}.
		\end{definit}
		
	\subsection{Circuito Booleano}
		\begin{definit}[Circuito Booleano]
			Un circuito booleano è un grafo aciclico orientato (DAG) $ C_n $ con $ n $ input e ha le seguenti caratteristiche:
			\begin{itemize}
				\item $ \exists n $ vertici che hanno \textit{in-degree} = 0
				\item $ \exists 1 $ vertice che ha \textit{out-degree} = 0
				\item Ogni altro vertice ha \textit{in-degree} = 1 o 2 ed è etichettato con $ and, or, not $.
				\item La taglia di $ C_n $ è il numero di vertici.
			\end{itemize}
		\end{definit}
		
		\begin{esempio}
			Per $ n = 4 $ abbiamo $ C_4(x_1, x_2, x_3, x_4) $:
			\begin{figure}[h!]
				\centering
				\begin{tikzpicture}[>=latex]
					\node[draw, circle] (a) at (0,0) {0};\node[draw, circle] (b) at (2,0) {1};
					\node[draw, circle] (c) at (4,0) {1};\node[draw, circle] (d) at (6,0) {1};
					\node[draw,circle] (out) at (3,-4) {0};
					\node[draw,rectangle] (and) at (1,-1) {and};\node[draw,rectangle] (or) at (5,-1) {or};
					\node[draw,rectangle] (not) at (4,-2) {not};\node[draw,rectangle] (and1) at (3,-3) {and};
					\draw[->] (a) -- (and);\draw[->] (and) -- (and1); \draw[->] (b) -- (and);
					\draw[->] (c) -- (or);\draw[->] (d) -- (or); \draw[->] (or) -- (not); \draw[->] (not) -- (and1); 
					\draw[->] (and1.south) -- (out);
					\node[xshift=.2cm] at (and.east) {0};\node[xshift=.2cm] at (or.east) {1};\node[xshift=.2cm] at (not.east) {0};\node[xshift=.2cm] at (and1.east) {0};
				\end{tikzpicture}
				\caption{Esempio di circuito booleano con 4 input, il nodo finale di output è detto nodo \textit{sink}.}
			\end{figure}
		\end{esempio}
		
	\subsection{Problema Circuit-SAT}
		\begin{itemize}
			\item Input: Circuito booleano $ C_n $
			\item Output: $ yes \ \Leftrightarrow \ \exists \underline{x} \ t.c. \ C(x) = 1 \ $ (il circuito booleano è soddisfacibile).
		\end{itemize}
		Definiamo una famiglia di circuiti $ C_{n\geq 0} $ (per ogni numero di input) di complessità $ T(n) $ tale che la taglia di $ C_n $ è $ O(T(n)) $.
		
		Vogliamo mappare il verificatore di ogni problema in $ \np $ in un circuito:
		\begin{align*}
			\prob{A} \qquad &\longmapsto \qquad V(\cdot, \cdot)\\ \\
			\prob{A}(x) = yes\ &\Leftrightarrow\ \exists w \ t.c.\ V(x, w) = yes
		\end{align*}
		Dove $ V(x, w) $ è un circuito che prende $ x $ in input e che mi dice se esiste un certificato $ w $ tale che rende soddisfatto il circuito.
		
		\begin{thm}
			\label{thm:circfam}
			Se $ \prob{A} \in TIME(f(n)) $ allora esiste una famiglia di circuiti $ C_{n\geq 0} $ di complessità $ T(n) = O(f(n)^2) $ tale che $ \ \forall \underline{x} \in \instance{A}\ $ e $ \ n = \vert x \vert\ $ $ C_n(x) = \prob{A}(x)\ $ e $ C_n $ è costruibile in tempo polinomiale.
		\end{thm}
		
		\begin{coroll}
			Se $ \prob{A} \in \p $ ($ f(n) $ è un polinomio in $ TIME(f(n)) $) allora esiste una famiglia di circuiti di complessità polinomiale ($ T(n) = n^k $) tale che $ \ \forall\underline{x} \in \instance{A} \ $ e $ \ n = \vert x \vert \ \ $ $ C_n(\underline{x}) = \prob{A}(x) \ $ e $ C_n $ è costruibile in tempo polinomiale in $ \vert x \vert = n $. 
		\end{coroll}
		
		\paragraph{Circuit SAT è NP-completo} Dimostriamo prima a parole che Circuit-SAT $ \in \np $. Forniamo il verificatore $ V(x,w) $ verifica se un'istanza soddisfa il problema. Il certificato $ w $ è l'assegnamento che soddisfa il circuito, mentre il verificatore scorre ogni nodo e ne valuta il valore, ritorna $ yes $ se il nodo finale (sink) è a 1, altrimenti $ no $.
		
		Ora dimostriamo che Circuit-SAT è NP-hard, ovvero che $ \ \forall \prob{A} \in \np \quad \prob{A} \leq_K \text{Circuit-SAT} $. Dobbiamo mostrare dunque che esiste tale trasformazione polinomiale:
		\[
			\underline{x} \in \instance{A} \ \longmapsto \ C\in \instance{\text{Circuit-SAT}}
		\]
		e vale anche che:
		\[
			\prob{A} = yes \ \Leftrightarrow \ \exists w \ t.c. \ C(w) = 1 (\text{C è soddisfacibile})
		\]
		Sia $ \prob{A} \in \np $ allora $ \exists V_{\prob{A}}(x, w) $ per le istanze $ x \in \instance{A} $, tale che $ V_{\prob{A}} $ ha complessità $ O(p(\vert x\vert)) = \vert w \vert $ (polinomiale). Allora per il teorema \ref{thm:circfam} sappiamo che esiste una famiglia di circuiti $ C_m $ che fa esattamente ciò che fa il verificatore $ V_{\prob{A}} $ :
		\[
			C_m = V_{\prob{A}} \quad m = \vert x \vert + p(\vert x\vert)
		\]
		perciò, se consideriamo $ C_x'(x) = C_m(x, w) $
		\[
			\prob{A}(x) = yes \ \Leftrightarrow \ \exists w\ t.c. \ V_{\prob{A}}(x, w) = yes \ \Leftrightarrow \ \exists w\ t.c. \ C_m(x, w) = 1 \ \Leftrightarrow \ \exists w\ t.c. \ C_x'(x) = 1 
		\]
		
		\paragraph{SAT è NP-completo} Vogliamo dimostrare che dato un circuito booleano soddisfacibile esiste una riduzione che lo trasforma in tempo polinomiale in una formula booleana soddisfacibile.
		\begin{align*}
			 \text{Circuit-SAT } &\leq_K \text{ SAT} \\
			\forall C \in \instance{\text{Circuit-SAT}} \ &\longmapsto \ \phi(\dots)\\
			C \text{ è soddisfacibile } &\Leftrightarrow \ \phi \text{ è soddisfacibile }
		\end{align*}
		
		\begin{obs}
			Ogni funzione di gate ($ and, or, not, \dots $) può essere espressa con una formula booleana CNF $ \phi $:
			\begin{align*}
				&c = a\ and\ b \quad \quad (\overline{c}\vee a)\wedge(\overline{c}\vee b)\wedge(c\vee \overline{a}\vee\overline{b}) \\
				&c = a\ or\ b \quad \quad (\overline{c}\vee a\vee b)\wedge(c\vee\overline{b})\wedge(c\vee\overline{a})\\
				&c = not\ a \quad \quad (\overline{c}\vee\overline{a})\wedge(c\vee a)
			\end{align*}
			Quindi un circuito booleano è soddisfatto quando ogni formula è soddisfatta e il nodo sink è soddisfatto (= 1).
		\end{obs}
		Perciò se ogni funzione di gate sottoforma di circuito booleano rappresenta ogni clausola della formula CNF $ \phi $, allora possiamo mettere in and tutte le clausole e dire che il circuito $ C $ è soddisfatto se e solo se $ \phi $ è soddisfatta.\\
		Con questo e con la dimostrazione che Circuit-SAT è NP-completo possiamo dire che
		\[
			\forall \prob{B} \in \np \quad \prob{B}\leq_K\text{Circuit-SAT}\leq_K \text{SAT}
		\]
		Perciò, per la proprietà transitiva della riduzione alla Karp tra problemi di decisione, deduciamo che SAT è NP-completo.
		
	\subsection{Relazione tra $ \p $, $ \np $, e $ \np$-completo}
		Distinguiamo principalmente due casi che rappresentano le relazioni tra le classi di problemi $ \p, \np $ e NP-completo:
		\begin{figure}[h!]
			\centering
			\begin{tikzpicture}[scale=0.6]
				\draw (0,0) ellipse (3cm and 2cm) node[yshift=.7cm] {$ \np $};
				\draw (-1.3,0) circle (1cm) node {$ \p $};
				\draw (1.3,0) circle (1cm) node {$ \npc $};
				\node at (4.5,0) {oppure};
				\draw (9,0) ellipse (3cm and 2cm) node {$ \npc \equiv \np \equiv \p $};
			\end{tikzpicture}
		\end{figure}
		
		\begin{thm}
			Se $\ \npc \cap \p \neq \emptyset\ $ e $\ \prob{A} \in \np \quad t.c. \ \prob{A} $ \textbf{non è banale}, ovvero 
			\begin{align*}
			&\exists x \in \instance{A} \quad t.c. \ \prob{A}(x) = yes\\ 
			&\exists y \in \instance{A} \quad t.c. \ \prob{A}(y) = no 
			\end{align*}
			Allora $ \prob{A} \in \npc $
		\end{thm}
		\begin{proof}
			Se $\ \npc \cap \p \neq \emptyset\quad \exists \prob{B}\ \text{ Np-hard }\ t.c.\ \prob{B}\in\p \wedge \forall \prob{C}\in \np \ \ \prob{C} \leq_K \prob{B} $. Perciò deduciamo che $ \prob{C}\in\p $, quindi ogni problema che è in $ \np $ è anche in $ \p $ e viceversa. Quindi $ \p \equiv \np $.
			
			Dobbiamo quindi dimostrare che ogni problema in $ \np $ si riduce polinomialmente ad $ \prob{A} $\\
			Prendiamo come esempio il seguente problema \textit{bit}:
			\begin{itemize}
				\item Input: Bit $ b $
				\item Output: $ yes \Leftrightarrow b = 1 $ 
			\end{itemize}
			Sia $ \prob{D} $ un problema $ \prob{D} \in \np $ e quindi $ \prob{D} \in \p $ (c'è un risolutore polinomiale per $ \prob{D} $). Dobbiamo trovare una trasformazione $ f(x) $ tale che riduce il problema $ \prob{D} $ al problema \textit{bit}:
			\[	
				f(x) = 
				\begin{cases}
					1 & \mbox{ se } \prob{D}(x) = yes \\
					0 & \mbox{ altrimenti}
				\end{cases}
			\]
			dove $ x \in \instance{D} $.\\
			Sappiamo quindi risolvere $ f(x) $ in tempo polinomiale perché sappiamo risolvere $ \prob{D} $ in tempo polinomiale poiché $ \prob{D} \in \np \wedge \prob{D} \in \p  $. Quindi siano $ x $ e $ y $
			\begin{align*}
				&x_{yes}\in \instance{A} \quad t.c.\ \prob{A}(x_{yes}) = yes\\
				&x_{no}\in \instance{A} \quad t.c.\ \prob{A}(x_{no}) = no
			\end{align*}
			allora la trasformazione $ f(x) $ sarà:
			\[
				f(x) = 
				\begin{cases}
					x_{yes} & \mbox{ se } \prob{D}(x) = yes \\
					x_{no}  & \mbox{ se } \prob{D}(x) = no
				\end{cases}
			\]
		\end{proof}
		
	\section{Classe di problemi $ \conp $}
		\begin{definit}(Classe $ \conp $)
			L'insieme dei problemi $ \conp $ è definito nel seguente modo:
			\[
				\conp = \{\prob{A}\ \big| \ \overline{\prob{A}} \in \np \}
			\]
			Sono quei problemi per cui è ``facile'' verificare le istanze $ no $.
		\end{definit}
		Di seguito forniamo un paio di esempi di problemi:
		\begin{esempio} Problema:
			\begin{itemize}
				\item Input: Grafo G
				\item Output: $ yes $ se G non è colorabile con 7 colori.
			\end{itemize}
			Questo problema è il complemento del problema 7-COL. Quest'ultimo appartiene alla classe $ \np $ quindi il problema in esempio è in $ \conp $.
		\end{esempio}
		
		\begin{esempio} Problema:
			\begin{itemize}
				\item Input: formula booleana $ \phi $
				\item Output: $ yes $ se $ \forall \underline{a} \ \phi(a) = T $
			\end{itemize}
			Per questo problema è facile vedere che esiste un'istanza $ no $ poiché basta che ci sia almeno una clausola con tutti i letterali a false. Quindi appartiene a $ \conp $.
		\end{esempio}
		
	\subsection{Relazione tra $ \p$,$ \np $ e $ \conp $}
		\begin{thm}
			Se $ \exists \prob{A} \ t.c. \ \prob{A} \in \npc \cap \conp \ $ allora $ \np \equiv \conp $.   
		\end{thm}
		\begin{proof}[$ \conp \subseteq \np $]
			Supponiamo che $ \prob{A}\in \npc $ allora $ \prob{A} \in \np \ $ e $ \ \forall \prob{C}\in \np \quad \prob{C}\leq_K\prob{A} $.\\
			Se prendiamo il problema $ \prob{B}\in \conp \quad \overline{\prob{B}}\in\np $.\\
			Allora esiste una riduzione alla Karp $ \overline{\prob{B}}\leq_K \prob{A} $ che mappa le istanze $ yes $ di $ \prob{B} $ alle istanze $ no $ di $ \prob{A} $ ed esiste anche una riduzione $ \prob{B}\leq_K \overline{\prob{A}} $ che è duale alla precedente.\\
			Poiché $ \prob{A}\in \conp $ allora $ \overline{\prob{A}}\in \np $. Quindi $ \prob{B} $ si riduce polinomialmente ad un problema in $ \np $. Quindi $ \prob{B}\in\np $. Quindi per estensione $ \conp \subseteq\np $.
 		\end{proof}
 		\begin{proof}[$ \np \subseteq \conp $] 
 			Sia $ \prob{C}\in \np\quad \prob{C}\leq_K \prob{A}\quad \overline{\prob{C}}\leq_K\overline{\prob{A}} $. Poiché $ \prob{A}\in \conp $ allora $ \overline{\prob{A}}\in \np $. Quindi $ \overline{\prob{C}}\in\np \ \Rightarrow\ \prob{C}\in\conp \ \Rightarrow \ \np \subseteq \conp $.
 		\end{proof}
 		
 		\begin{figure}[h!]
 			\centering
 			\begin{tikzpicture}[scale=0.6]
	 		\draw (0,0) ellipse (3cm and 2cm) node[xshift=-.5cm] {$ \np $};
	 		\draw (3,0) ellipse (3cm and 2cm) node[xshift= .7cm] {$ \conp $};
	 		\draw (1.5,0) circle (1cm) node {$ \p $};
 		\end{tikzpicture}
 		\end{figure}
 		
 		\paragraph{Cosa succede se $ \p\equiv\conp $ ?} Se abbiamo l'equivalenza di queste due classi di problemi si ha che:
 		\begin{align*}
	 		\prob{A}(x) \in \np \qquad & \alg{A}(x) = \exists w \ B(x,w) \in \p \\
	 		\prob{A}(x) \in \conp \quad & \alg{A}(x) = \forall w \ B(x,w) \in \p
 		\end{align*}
 		
 		\begin{itemize}
 			\item Se $ \np\neq \conp \ \Rightarrow \ \p\neq\np $
 			\item Se $ \p = \np\ $ siccome $ \ \p = \conp\quad \forall \prob{A}\in \np , \prob{A}\in \p \ \Rightarrow \ \overline{\prob{A}}\in \p = \np \quad \Rightarrow \ \np = \conp $ 
 		\end{itemize}
 		
 		\begin{definit}[Hardness del problema $ \prob{A} $ nella classe $ \conp $]
 			$ \prob{A}\ $ è $ \ \conp\text{\textbf{-completo}} $ se $ \prob{A}\in \conp\ $ e $ \ \forall \prob{B} \in \conp \ \ \prob{B}\leq_K\prob{A} $. 
 		\end{definit}
 		
 		\begin{thm}
 			Se $ \prob{A}\ $ è $ \ \np\text{\textbf{-completo}} $ allora $ \overline{\prob{A}}\ $ è  $ \ \conp\text{\textbf{-completo}} $ e viceversa.
 		\end{thm}
 		
 		\begin{proof}
 			Se $ \prob{A}\ $ è $ \ \np\text{\textbf{-completo}} $, allora
 			\begin{itemize}
 				\item $ \prob{A}\in\np $
 				\item $ \forall \prob{B} \in \np \ \ \prob{B}\leq_K\prob{A} $
 			\end{itemize}
 			Dalla prima deduciamo che $\  \Rightarrow\quad \overline{\prob{A}}\in\conp $ \\
  			Dalla seconda invece, se $ \prob{C}\in\conp,\quad \overline{\prob{C}}\in \conp \quad \Rightarrow \quad
  			\overline{\prob{C}}\leq_K\prob{A}\quad \Rightarrow \prob{C}\leq_K\overline{\prob{A}} $\\
  			$ \Rightarrow \ \forall\prob{C}\in\conp \quad \Rightarrow \prob{C}\leq_K\overline{\prob{A}}  $\\
  			Da queste due deduzioni abbiamo quindi la definizione di $ \conp\text{\textbf{-completo}} $ per $ \overline{\prob{A}} $
 		\end{proof}
 		
 		\begin{enumerate}
 			\item Se vogliamo dimostrare che è $ \conp\text{\textbf{-completo}} $ possiamo dimostrare che \textit{il complemento} è $ \np\text{\textbf{-completo}} $.
 			\item Per dimostrare che $ \prob{A} $ è $ \np\text{\textbf{-completo}} $
 			\begin{enumerate}
 				\item $ \prob{A} \in \np $
 				\item $ \forall\prob{B} \quad \prob{B}\leq_K \prob{A} $
 			\end{enumerate}
 		\end{enumerate}
 	
 	\noindent
 	\textit{\textbf{Tautologia} (TAU)} è \textbf{CO-NP-completo}
 	\begin{itemize}
 		\item \textit{Input}: una formula booleana $\psi$
 		\item \textit{Output}: yes $\Leftrightarrow \forall \underline{a} \in \{ T, F \}^n ~~ \psi(\underline{a} = T)$
 	\end{itemize}
 	
 	\noindent
 	Si dimostra che $\overline{TAU}$ è \textbf{NPC} ($\exists \underline{a}$ t.c. $\psi(\underline{a}) = F$)
 		
	 \subsection{Problema Minimo circuito booleano}
		 \begin{itemize}
		 	\item Input: Circuito booleano $ C_n $ (con $ n $ input)
		 	\item Output: $ yes \ \Leftrightarrow \ \nexists \ $ circuito $ C' \quad t.c.\quad \forall x \ C'(x) = C(x) \ $ con  $ \vert C'\vert < \vert C \vert $ 
		 \end{itemize}
		 Consideriamo l'algoritmo $ \alg{A} $
		\[
			\alg{A}(x) = \forall w_1 \exists w_2 \quad B(x, w_1, w_2) = yes \quad \text{ con }\ B\in \p \
			\text{ e } \ \vert w_i \vert = O(p_i(\vert x \vert))
		\]
		Se minimo circuito booleano $ \in \np \ $ allora: $ \ \forall w_1 \exists w_2 \quad B(x, w_1, w_2) \ \equiv \ 
		\exists w'\quad B'(x, w') $.\\
		Se minimo circuito booleano $ \in \conp \ $ allora: $\ \forall w''\quad B''(x, w'') $.
		
	\section{Gerarchia Polinomiale}
		\begin{definit}[Classe di problemi $ \Pi_i P $]
			\[
				\Pi_i \p = \{ \alg{A}(x) = \forall w_1\exists w_2 \forall w_3 \exists w_4 \dots Q_i w_i \quad B(x, w_1, \dots, w_i) \quad \text{ dove } \ \vert w_i \vert = O(p_i(\vert x \vert)) \ \text{ e } \ B\in\p \}
			\]
		\end{definit}
		
		\begin{definit}[Classe di problemi $ \Sigma_i P $]
			\[
			\Sigma_i \p = \{ \alg{A}(x) = \exists w_1\forall w_2 \exists w_3 \forall w_4 \dots Q_i w_i \quad B(x, w_1, \dots, w_i) \quad \text{ dove } \ \vert w_i \vert = O(p_i(\vert x \vert)) \ \text{ e } \ B\in\p \}
			\]
		\end{definit}
		Dalla definizione di queste classi di problemi deduciamo che:
		\begin{align*}
			&\Pi_0 \p = \Sigma_0 \p = \p \qquad \alg{A}(x) = \alg{B}(x) \text{ non ho quantificatori} \\
			&\Pi_1 \p = \conp \\
			&\Sigma_1 \p = \np \\
			&\text{Minimo circuito booleano } \in \Pi_2 \p
		\end{align*}
		
		\begin{obs}
			$ \alg{A}(x) \in \Pi_i \p \quad \Leftrightarrow \quad \overline{\alg{A}(x)} \in \Sigma_i \p $.
		\end{obs}
		
		\begin{obs}
			$ \Pi_i \p \subseteq \Sigma_{i+1} \p \quad $ e $ \quad \Sigma_i \p \subseteq \Pi_{i+1} \p $.  \\
			Infatti se aggiungo un quantificatore all'inizio, ho che
			\begin{align*}
				\alg{A}(x) &\in \Pi_i \p \\ 
				\alg{A}(x) &= \forall w_1 \exists w_2 \dots Q_i w_i \quad B(x, w_1, w_2, \dots, w_i) \\
				\Sigma_{i+1} \p &= \exists w^* \forall w_1 \exists w_2 \dots Q_i w_i \quad B'(x, w^*, w_1, w_2, \dots, w_i)
			\end{align*}
			Perciò $ B'(\dots) = B(\dots) $
		\end{obs}
		
		\begin{obs}
			Per lo stesso motivo dell'osservazione precedente vale che:\\
			$ \Pi_i \p \subseteq \Pi_{i+1} \p \quad $ e $ \quad \Sigma_i \p \subseteq \Sigma_{i+1} \p $.  
		\end{obs}
		
		\begin{obs}
			Se $ \p \equiv \np \quad \Rightarrow \quad \forall i \ \Sigma_i \p = \p \ \wedge \ \Pi_i \p = \p $ \\
			cioè abbiamo che:
			\[
				B(x, w_1, w_2, \dots, w_i) = B'(x) \ \text{ (elimino tutte le quantificazioni)}
			\]
		\end{obs}
		
		\begin{prop}
			Se $ \np = \conp \quad \Rightarrow \quad \Sigma_1 \p = \Pi_1 \p $.\\
			Quindi $ \ \Sigma_i \p = \Pi_i \p = \Sigma_1 \p = \Pi_1 \p \quad \forall i \geq 1 $.\\
			Tutte le classi sopra collassano sulla classe 1. 
		\end{prop}
		
		\begin{proof}
			Assumiamo che $ \np \equiv \conp $: \\
			$ \alg{A}(x) = \exists w_1 \quad B(x, w_1) \ \Leftrightarrow \ \alg{A}(x) = \forall w_1' \quad B'(x,w_1) $ \\
			Sia $ \alg{A}'(x) \in \Sigma_2 \p \qquad \alg{A}'(x) = \exists w_2 \forall w_1 \quad C(x, w_1, w_2) = \alg{D}_{w_2}(x) $. \\
			$ \alg{D}_{w_2}(x) \in \conp \equiv \np \quad $ quindi $ \ \alg{D}_{w_2}(x) = \exists w_1'\quad C'(x, w_1', w_2) \ $ perciò diventa:
			\begin{align*}
				\prob{A}'(x) &= \exists w_2 \exists w_1'' \quad C'(x, w_1'', w_2) \\
							 &= \exists w_{1 2} \quad C'(x, w_{1 2}) \quad \in \np
			\end{align*}
			Quindi deduciamo che se $ \np \equiv \conp \quad \Rightarrow \quad \Sigma_2 \p = \Sigma_1 \p $\\
			Inoltre se $ \np \equiv \conp \quad \Rightarrow \quad \Pi_2 \p = \Pi_1 \p $
		\end{proof}
		
		\begin{definit}[Gerarchia Polinomiale]
			Definiamo gerarchia polinomiale la classe $ \ph $ delle proprietà $ \prob{A} $ che possono essere espresse da una formula con quantificatori contenente un numero costante di quantificatori alternati:
			\[
				\ph = \bigcup_k \Sigma_k \p = \bigcup_k \Pi_k \p
			\]
		\end{definit}
		
		\begin{thm}[Collasso della gerarchia polinomiale]
			Se 
			\[
				\p = \np \quad \Rightarrow \quad \np = \conp = \p \quad \Rightarrow \quad \Sigma_i \p = \Pi_i \p = \p \quad \forall i
			\]
			la gerarchia polinomiale collassa in $ \p $.\\
			Se $ \ \np = \conp \quad \Rightarrow \quad \ph = \np = \conp $.
		\end{thm}
		
		\begin{thm}
			Se $ \ \Pi_i \p = \Sigma_i \p \quad \Rightarrow \quad \ph = \Pi_i \p = \Sigma_i \p $
		\end{thm}
		
	\subsection{Funzione time-costruibile}
	
		\begin{prop}
			Nel modello computazionale in oggetto è possibile simulare $ t $ passi di un algoritmo (programma) mentre controlliamo che $ \leq t $ passi sono fatti in $ s(t) $ passi.
		\end{prop}
		
		\begin{esempio}
			Se il modello computazionale è la Macchina di Turing, allora $ s(t) = O(t\log t) $.
		\end{esempio}
		\begin{esempio}
			Se il modello computazionale è la RAM, allora $ s(t) = O(t) $
		\end{esempio}
		
		\begin{definit}
			Diciamo che $ f(n) $ è \textbf{Time-costruibile} se esiste un programma (algoritmo) che calcola $ f(n) $ in $ O(f(n)) $.
		\end{definit}
	
		\begin{thm}
			Data l'assunzione precedente, per ogni funzione $ f(n) $ \textit{time-costruibile} e per ogni $ g(n) = o(f(n)) $ la classe \textbf{TIME(g(n))} $ \subset $ \textbf{TIME(s(f(n)))}
		\end{thm}
		\begin{figure}[h!]
			\centering
			\begin{tikzpicture}[scale=0.7,every node/.style={scale=0.7}]
			\draw (0,0) ellipse (2.5cm and 1.7cm) node[yshift=1.3cm] {\textbf{TIME(s(f(n)))}};
			\draw (0,0) ellipse (1.5cm and 1cm) node {\textbf{TIME(g(n))}};
			\draw[fill=black] (2,0) circle (.02cm) node[above] {$ \prob{A} $};
			\end{tikzpicture}
		\end{figure}
		
	\subsection{Problema Catch 22}
		\begin{itemize}
			\item Input: $ \Pi $ (programma)
			\item Output: se $ \Pi(\Pi) $ termina in meno di $ f(\vert \Pi \vert) $ passi allora ritorna $ \overline{\Pi(\Pi)} $ altrimenti ritorna $ 0 $.
		\end{itemize}
		
		Supponiamo che esista un algoritmo $ \Pi_{22} $ tale che risolve il problema Catch 22 in $ g(n) $ passi, dove $ g(n) < f(n) $. Questo è equivalente a dire che Catch 22 $ \in $ \textbf{TIME(g(n))}.\\
		Se $ \Pi_{22}(\Pi_{22}) = \text{Catch 22}(\Pi_{22}) $ siccome ci mette meno di $ f(\Pi_{22}) $ passi, allora e uguale a $ \overline{\Pi_{22}(\Pi_{22})} $. Questo è assurdo perché non può essere che $ \Pi_{22}(\Pi_{22}) = \overline{\Pi_{22}(\Pi_{22})} $, quindi \textit{non} esiste l'algoritmo $ \Pi_{22} $ che impiega $ g(n) < f(n) $ passi.
		
		\bigskip
		
		Supponiamo che il programma $ \Pi $ risolve Catch 22 se e solo se $ \ \forall x \in \instance{\text{Catch 22}} \quad \Pi(x) = \text{Catch 22}(x) $. Se $ \Pi $ termina in $ \leq f(n) $ passi per ogni $ x $, allora $ \ \exists x \ t.c. \quad \Pi(x)\neq \text{Catch 22}(x) $. 
		
		\begin{prop}
			Per ogni algoritmo esistono infiniti programmi $ \Pi $ che implementano l'algoritmo (fanno la stessa cosa) di lunghezza arbitrariamente grandi.
		\end{prop}
		
		\begin{prop}
			Per ogni $ n \geq \vert \Pi_{22} \vert $ fissato esiste un altro $ \Pi_{22}' $ tale che $ \vert \Pi_{22}' \vert = n $. Quindi $ \ \Pi_{22}'(\Pi_{22}') = \Pi_{22}(\Pi_{22}) $.
		\end{prop}
		
	\section{Teorema di Ladner}
		Ci chiediamo se esiste un problema $ \np $ che non appartiene nè alla classe $ \p $	nè alla classe $ \npc $.
		\begin{figure}[h!]
			\centering
			\begin{tikzpicture}[scale=0.7,every node/.style={scale=0.7}]
				\draw (0,0) ellipse (3cm and 2cm) node[yshift=1cm] {$ \np $};
				\draw (-1.3,0) circle (1cm) node {$ \p $};
				\draw (1.3,0) circle (1cm) node {$ \npc $};
				\draw[fill=black] (0,-1) circle (.02cm) node[above] {$ \prob{A} $};
			\end{tikzpicture}
			\caption{Esiste il problema $ \prob{A} $?}
		\end{figure}
		
		\begin{thm}[Teorema di Ladner]
			Se $ \p \neq \np $ allora esiste un problema $ \prob{A} \in \np \setminus (\p \cup \npc) $.
		\end{thm}
		
		\begin{proof}
			Vediamo un problema esempio che soddisfa il \textit{teorema di Ladner}:\\
			\textbf{Graph Isomorphism}
			\begin{itemize}
				\item Input: $ G_1, G_2 \ $ grafi
				\item Output: $ yes \Leftrightarrow \ G_1 \ $ è \textit{isomorfo} a $ \ G_2 $.
			\end{itemize}
			\begin{definit}[Isomorfismo]
				$ \exists f: \quad V(G_1) \mapsto V(G_2) $ \\ $ t.c.\quad (v,u) \in E(G_1) \Leftrightarrow (f(v), f(u))\in E(G_2) $
			\end{definit}
			
			\begin{esempio}[Grafi isomorfi]
				Ecco un esempio di due grafi isomorfi:
				\begin{figure}[h!]
					\centering
					\begin{tikzpicture}[scale=0.7,every node/.style={scale=0.7}]
						\node[draw, circle] (1) at (0,0) {1};\node[draw, circle] (2) at (2,0) {2};
						\node[draw, circle] (3) at (3,1) {3};\node[draw, circle] (4) at (2,-2) {4};
						\node[draw, circle] (a) at (5,0) {a};\node[draw, circle] (b) at (7,0) {b};
						\node[draw, circle] (c) at (7,-2) {c};\node[draw, circle] (d) at (5,-2) {d};
						\draw (1) -- (2) -- (3) -- (4) -- (2);\draw (1) -- (3);
						\draw (a) -- (b) -- (c) -- (d) -- (b);\draw (a) -- (d);
					\end{tikzpicture}
				\end{figure}
				\begin{align*}
					f(1) = a \quad f(2) &= b \\
					f(3) = c \quad f(4) &= d
				\end{align*}
			\end{esempio}
			
			\[
				\prob{A}(x)=
				\begin{cases}
					SAT(x) & \mbox{ se } f(\vert x\vert) \text{ è pari} \\
					0	   & \mbox{ se } f(\vert x\vert) \text{ è dispari}
				\end{cases}
			\]
			Vogliamo far vedere che:
			\begin{enumerate}
				\item $ \prob{A} \in \np $
				\item $ \prob{A} \notin \p $, cioè $ \ \forall \Pi \ $ polinomiale $ \ \exists x \ t.c. \ \Pi(x) \neq \prob{A}(x) $.
				\item $ \prob{A} \notin \npc $, cioè $ \ \forall \Pi \ $ polinomiale $ \ \exists x \ t.c. \ SAT(x) \neq \prob{A}(\Pi(x)) $.\\ Se $\mathbb{A}$ è $ \npc $ sappiamo che $ SAT\leq_K \prob{A} $
			\end{enumerate}
		\end{proof}
		
	\subsection{Problema Clique}
		\begin{itemize}
			\item Input: grafo $ G = (V, E), K $
			\item Output: $ yes\ \Leftrightarrow \ G\ $ contiene una clique di taglia $ K $
		\end{itemize}
		\textbf{Clique} è un insieme di vertici tutti connessi a due a due da un arco.
		
		\bigskip
		
		\paragraph{Clique $ \in \npc $} Facciamo vedere che il problema Clique appartiene alla classe $ \npc $ e che quindi appartiene alla classe $ \np $ e che esiste la riduzione $ \text{3-SAT } \leq_K $ Clique che trasforma in tempo polinomiale una formula $ \phi $ CNF in un grafo per il problema  Clique.
		
		\subparagraph{Clique $ \in \np $} Creiamo un verificatore per il problema Clique:
		\begin{itemize}
			\item Conta i vertici del grafo C. $ \quad \left[ O(n) \right] $
			\item Per ogni $ (u, v) \in C \ $ verifica che $ (u, v) \in E $. 
			$ \quad \left[ O(\vert K \vert^2 \times \vert E \vert ) \right] $
		\end{itemize}
		Questo verificatore è polinomiale. \\
		Il certificato per il verificatore è una clique $ C $ di taglia K in G, tale clique ha taglia polinomiale perché $ K $ può essere al massimo $ n $. Perciò Clique $ \in \np $.
		
		\subparagraph{$ \text{3-SAT } \leq_K $ Clique} Vediamo la seguente riduzione che mappa la formula 
		\[
			\phi= (x_1\vee \overline{x}_2\vee x_3) \wedge (\overline{x}_1\vee \overline{x}_2\vee x_3) \wedge (\overline{x}_1\vee x_2\vee \overline{x}_3)
		\]
		in un grafo che soddisfa il problema Clique.
		
		\begin{figure}[h!]
			\centering
			\begin{tikzpicture}
				\node[draw, circle] (a) at (0,0) {$ x_1 $}; 
				\node[draw, circle] (b) at (3,0) {$ \overline{x}_1 $}; 
				\node[draw, circle] (c) at (6,0) {$ \overline{x}_1 $}; 
				\node[draw, circle] (1) at (-1,-2) {$ x_3 $}; \node[draw, circle] (2) at (1,-2) {$ \overline{x}_2 $}; 
				\node[draw, circle] (3) at (2,-2) {$ x_3 $}; \node[draw, circle] (4) at (4,-2) {$ \overline{x}_2 $}; 
				\node[draw, circle] (5) at (5,-2) {$ \overline{x}_3 $}; \node[draw, circle] (6) at (7,-2) {$ x_2 $};

				\foreach \i in {a,b,c}
				{
					\foreach \x in {1,2,...,6}
					{
						\ifthenelse{\(\equal{\i}{a} \AND \x = 2\) \OR 
							\(\equal{\i}{b} \AND \x = 3\) \OR
							\(\equal{\i}{b} \AND \x = 4\) \OR
							\(\equal{\i}{c} \AND \x = 5\)}{}{\draw (\i) -- (\x);};
					}
				}
				\draw[color=white, ultra thick] (1) -- (a);\draw[color=white, ultra thick] (6) -- (c);
				\draw (b) -- (c);\draw (2) -- (3);\draw (4) -- (5);
				\draw[bend right] (1) to (3);\draw[bend right] (1) to (4);\draw[bend right] (1) to (6);
				\draw[bend right] (2) to (4);\draw[bend right] (2) to (5);
				\draw[bend right] (3) to (6);
			\end{tikzpicture}
			\caption{Grafo in cui c'è un arco per ogni letterale diverso dal proprio negato e che non appartiene alla stessa clausola}
		\end{figure}
	
	\noindent
	Sappiamo che se:
	\begin{itemize}
		\item se $\phi$ è soddisfacibile $\Rightarrow G$ ha una clique di taglia 3;
		\item se $G$ ha una clique di taglia 3 $\Rightarrow \phi$ è soddisfacibile.
	\end{itemize}		
		\noindent
		Il grafo mostra le seguenti caratteristiche:
		\begin{itemize}
			\item Numero di vertici: $\ \vert V \vert = 3m \ $ con $ \ \phi = C^{(1)}\wedge\dots\wedge C^{(m)} $.
			\item Numero di archi: $ \ \vert E \vert \leq 9m^2 $
		\end{itemize}
		Quindi il grafo, e di conseguenza la riduzione, è costruibile in tempo polinomiale.
		
		\bigskip
		
		Dimostriamo ora che se $ \phi $ è soddisfacibile allora esiste un assegnamento $ a_1, a_2,\dots, a_n $ per $\ x_1, \dots, x_n $ tale che in ogni clausola un letterale è posto a T.\\
		Siano $ v_{i1}^{(1)} v_{i2}^{(2)}\cdots v_{in}^{(n)} $ i vertici corrispondenti ai letterali posti a T dell'assegnamento (uno per clausola). Tali vertici rappresentano nel grafo una clique.
		
		\bigskip
		
		Dimostriamo ora che se $ G $ ha una clique di taglia $ m $ allora $ \phi $ è soddisfacibile. Supponiamo che $ G $ abbia una clique $ C $ è taglia $ m $.
		\begin{enumerate}
			\item Gli $ m $ vertici di $ C $ sono uno per tripla. Le triple corrispondono alle clausole.
			\item Due vertici in $ C $ non corrispondono a letterali opposti di $ \phi $.
		\end{enumerate}
		Dall'ultimo punto in questione costruiamo un assegnamento che soddisfa $ \phi $. Se prendiamo i vertici di $ C $ e li assegniamo a T, gli altri vengono assegnati di conseguenza:
		\begin{align*}
			\overline{x}_2 &= T \quad x_2 = F \\
			\overline{x}_3 &= T	\quad x_3 = F \\
						   &    \quad x_1 = F 
		\end{align*}
		Perciò abbiamo che
		\[
			\phi(F,F,F) =
			(\underset{F}{x_1} \vee \underset{T}{\overline{x}_2}\vee \underset{F}{x_3}) 
			\wedge (\underset{T}{\overline{x}_1}\vee \underset{F}{x_2} \vee \underset{F}{x_3}) 
			\wedge (\underset{T}{\overline{x}_1}\vee \underset{F}{x_2} \vee \underset{F}{x_3}) = T
		\]
		
	\subsection{Problema Independent Set}
		\begin{itemize}
			\item Input: Grafo $ G = (V, E), k $
			\item Output: $ yes\ \Leftrightarrow\  $ in $\ G\ $ c'è un Indipendent Set di taglia $\ \geq k $.
		\end{itemize}
		\begin{definit}[Independent Set]
			Un indipendent set è un insieme $ I $:
			\[
				I\subseteq V\quad t.c.\quad \forall (u,v)\in I\qquad (u,v)\notin E
			\]
			
		\end{definit}
		\begin{esempio}[Independent Set]
			Vediamo un esempio di independent set:\\
			\begin{figure}[h!]
				\centering
				\begin{tikzpicture}
					\node[draw, circle, fill=gray] (a) at (0,0) {}; \node[draw, circle] (b) at (2,0) {};
					\node[draw, circle] (c) at (0,-2) {}; \node[draw, circle, fill=gray] (d) at (2,-2) {};
					\node[draw, circle] (e) at (1,-1) {}; \node[draw, circle, fill=gray] (f) at (3,-1) {};
					\draw (a) -- (b) -- (d) -- (c) -- (a); \draw (a) -- (e) -- (d); \draw (b) -- (f) -- (e);
				\end{tikzpicture}
			\end{figure}
		\end{esempio}
		
		\paragraph{IndSet $ \in \npc $} Esiste una riduzione Clique $ \leq_K $ IndSet tale che
		\[
			\big( G = (V, E), k\big) \ \mapsto \ \big(G' = (V, E), k\big)
		\]
		
		\paragraph{Problema TreeIndependentSet} Dimostriamo che il seguente problema appartiene alla classe $ \p $:
		\begin{itemize}
			\item Input: grafo \textit{connesso} e \textit{aciclico} $ G = (V, E), k $.
			\item Output: $ yes\ \Leftrightarrow\ G $ ha un Independent Set di taglia $ k $.
		\end{itemize}
		
		\begin{figure}[h!]
			\centering
			\begin{tikzpicture}[scale=0.6]
				\node[draw, circle] (r) at (3,2) {};
				\node[draw, circle] (a) at (0,0) {}; \node[draw, circle] (b) at (3,0) {}; 
				\node[draw, circle] (c) at (6,0) {}; \node[draw, circle] (1) at (-1,-2) {}; 
				\node[draw, circle] (2) at (1,-2) {}; \node[draw, circle, fill=gray] (3) at (2,-2) {}; 
				\node[draw, circle] (4) at (4,-2) {}; \node[draw, circle, fill=gray] (5) at (5,-2) {}; 
				\node[draw, circle] (6) at (7,-2) {}; 
				\node[draw, circle, fill=gray] (7) at (-1.5,-4) {}; \node[draw, circle, fill=gray] (8) at (-.5,-4) {}; 
				\node[draw, circle, fill=gray] (9) at (1.5,-4) {}; \node[draw, circle, fill=gray] (10) at (.5,-4) {}; 
				\node[draw, circle, fill=gray] (11) at (3.5,-4) {}; \node[draw, circle, fill=gray] (12) at (4.5,-4) {}; 
				\node[draw, circle, fill=gray] (13) at (6.5,-4) {}; \node[draw, circle, fill=gray] (14) at (7.5,-4) {}; 
				\draw (r) -- (a) -- (1) -- (7); \draw (a) -- (2) -- (10); \draw (1) -- (8); \draw (2) -- (9); 
				\draw (r) -- (b) -- (3); \draw (b) -- (4) -- (11); \draw (4) -- (12);
				\draw (r) -- (c) -- (5); \draw (c) -- (6) -- (13); \draw (6) -- (14);
			\end{tikzpicture}
			\caption{Esempio di Tree independent Set}
		\end{figure}
		
		\begin{obs}
			Si può osservare che le \textit{foglie} di un albero (grafo connesso e aciclico) rappresentano un independent set massimo.
		\end{obs}
		
		Costruiamo quindi l'algoritmo che dimostra che il problema è in $ \p $:
		\begin{lstlisting}[frame=tb, mathescape= true, caption={Algoritmo che risolve TreeIndependentSet}]
TreeIndSetSolver($ G =(V, E),\ k $)
	$ I\ \leftarrow\ \emptyset $
	while $\ V\neq \emptyset $:
		foreach $ \ v \quad t.c.\quad d(v)\leq 1 $:
			$I\ \leftarrow\ I \cup \{v\} $
			remove i vicini $ v $ da $ G $
	if $\ \big| I\big| \geq k \ $ return yes
	else return no
		\end{lstlisting}
		
		\begin{figure}[h!]
			\centering
			\begin{tikzpicture}
				\node[draw, circle] (a) at (6, 3.75) {}; 
				\node[draw, circle, fill=gray] (b) at (3.25, 2.75) {}; \node[draw, circle, fill=gray] (c) at (8.75, 2.75) {}; 
				\node[draw, circle] (d) at (1.75, 1.75) {}; \node[draw, circle] (e) at (4.75, 1.75) {}; 
				\node[draw, circle] (f) at (7.25, 1.75) {}; \node[draw, circle] (g) at (10.25, 1.75) {}; 
				\node[draw, circle, fill=gray] (h) at (.75, .75) {}; \node[draw, circle, fill=gray] (i) at (1.75, .75) {}; 
				\node[draw, circle, fill=gray] (l) at (2.75, .75) {}; \node[draw, circle, fill=gray] (m) at (4.25, .75) {}; 
				\node[draw, circle, fill=gray] (n) at (5.25, .75) {}; \node[draw, circle, fill=gray] (o) at (6.75, .75) {}; 
				\node[draw, circle, fill=gray] (p) at (7.75, .75) {}; \node[draw, circle, fill=gray] (q) at (10.25, .75) {};
				\draw (a) -- (b) -- (d) -- (h); \draw (d) -- (i); \draw (d) -- (l);
				\draw (b) -- (e) -- (m); \draw (e) -- (n);
				\draw (a) -- (c) -- (g) -- (q); \draw (c) -- (f) -- (o); \draw (f) -- (p);
				\foreach \x in {a,d,e,f,g}{
					\draw (\x.south west) -- (\x.north east);\draw (\x.south east) -- (\x.north west);
				}
				\foreach \x in {h,m,o}{
					\node[below,yshift=-.1cm] at (\x.south) {$ 1 $};
				}
				\foreach \x in {i,l,n,p,q}{
					\node[below, align=center, yshift=-.1cm] at (\x.south) {$ \cancel{1} $\\$ 0 $};
				}
				\node[right] at (d.east) {4}; \node[right] at (e.east) {3}; \node[right] at (f.east) {3};
				\node[right] at (g.east) {2};\node[above] at (a.north) {2};
				\node[right] at (b.east) {$ \cancel{3}\ \cancel{2}\ 1 $};
				\node[right] at (c.east) {$ \cancel{3}\ \cancel{2}\ 1 $};
			\end{tikzpicture}
			\caption{Esempio di esecuzione dell'algoritmo che risolve Tree independent Set\\
				Di lato ad ogni nodo è scritto il suo grado.}
		\end{figure}
		
		\paragraph{Problema Only Small Independent Set} Vediamo ora il problema OSIS:
		\begin{itemize}
			\item Input: $ G = (V, E), k $
			\item Output: $ yes\ \Leftrightarrow\ $ ogni Independent Set $ I,\ \big| I \big| \leq k $.
		\end{itemize}
		
		Se esiste un algoritmo $ \alg{A} $ che risolve questo problema in tempo polinomiale allora 
		\[ 
			\np \cap \p \neq \emptyset\quad \Rightarrow\quad \p = \np 
		\]
		Perciò avremmo che
		\[
			\forall (G, k)\quad \alg{A}(G, k) = yes\ \Leftrightarrow\ OSIS(G, k) = yes
		\]
		dove la taglia di $ \alg{A} $ è 
		$ \ T_{\alg{A}} = \Big( O\big(\big| G \big| + (\log \big|k \big|)^c\big) \Big) $.\\
		
		Abbiamo dunque un algoritmo $\ \alg{B}^{\text{IndSet}} = \overline{\alg{A}(G, k-1)} $.
		
		\begin{obs}
			Osserviamo che è facile verificare il $ no $ di istanze del problema OSIS, inoltre si può vedere che tale problema è il duale di IndSet, il quale appartiene alla classe $ \npc $.\\
			Concludiamo dunque dicendo che OSIS $ \in \text{\textbf{CO-}}\npc $.
		\end{obs}
		
		\newpage
		
	\section{Ricavare problemi di ottimizzazione e ricerca}
		
		\subsection{Independent Set}
		
		Vediamo ora diverse formulazioni per il problema Independent Set: 
		\begin{itemize}
			\item \textbf{Optimization Problem:} \textbf{IndSet-Opt}
			\begin{itemize}
				\item Input: $ G $
				\item Output: un IndSet di massima cardinalità
			\end{itemize}
			\item \textbf{Decision Problem:} \textbf{IndSet-Dec}
			\begin{itemize}
				\item Input: $ G, k\in \N $
				\item Output: $ yes\ \Leftrightarrow\ G\ $ ha un IndSet di cardinalità $ \geq k $
			\end{itemize}
			\item \textbf{Search Problem:} \textbf{IndSet-Search}
			\begin{itemize}
				\item Input: $ G, k\in N $
				\item Output: un IndSet di $ \ G\quad t.c.\quad \big| I \big|\geq k \ $ se esiste, altrimenti $\ no $.
			\end{itemize}
		\end{itemize}
		
		Dimostriamo che se $ \p = \np $ allora esiste un algoritmo che in tempo polinomiale trova un Independent Set di taglia massima in $ G $.\\
		Se $ \p = \np $ allora esiste un algoritmo $ \alg{A} $ polinomiale per \textbf{IndSet-Dec}:
		\begin{itemize}
			\item[$\Rightarrow$] $ \forall (G, k)\quad \alg{A}(G, k) = yes\ \Leftrightarrow\ $ esiste in $ G $ un IndSet di taglia $ k $.
			\item[$\Rightarrow$] In tempo polinomiale posso trovare $ k^* $ tale che esiste un IndSet in $ G $ di taglia $ k^* $ e ogni IndSet di $ G $ ha taglia al più 
			\[
				k^* = \max\{\ k\big| \exists I,\ \text{IndSet di } G,\ I = K \} 
			\]
			Per $ v\in V $ se in $ G - v - \{\ u\big| (u,v) \in E \} $ (i vicini di $ u $) non esiste un IndSet di taglia $ k^* - 1 $ allora nessun IndSet di taglia $ k^* $ contiene $ v $.
		\end{itemize}
		
		Per $ v\in V $ se in $ G - v - \{\ u\big| (u,v) \in E \} $ contiene un IndSet $ I' $ di taglia $ k^* - 1 $ allora $ I' \cup \{v \} $ è un IndSet di $ G $. Dove $ \ \big|I\cup\{v\}\big| = k^* $
		
		Vediamo ora l'algoritmo che permette di costruire un IndSet:
		
		\begin{lstlisting}[frame=tb, mathescape=true, caption={Algoritmo di Ottimizzazione per IndSet}]
CostruisciIndSet($ G $, $ k^* $)
	if $ \alg{A}(G,\ k^*) = no $:
		return $ no $
	else
		$ \tilde{G} \leftarrow G,\ I\leftarrow \emptyset $
		foreach $ v \in V $:
			if $ \alg{A}(\tilde{G} - v - N(v),\ k-1) = yes $:
				$ I\leftarrow I\cup \{v\} $
				$ \tilde{G}\leftarrow\tilde{G} - v - N(v) $
				$ k\leftarrow k - 1 $
		return $ I $
		\end{lstlisting}
		Dove $ N(v) = \{u\big| (u, v) \in E \} $\\
		Se $ \alg{A} $ utilizza tempo $ T_{\alg{A}}(G) $, il tempo di \lstinline|CostruisciIndSet| è $ O(nT_{\alg{A}}(G)) $\\
		Quindi sapendo risolvere il problema di decisione in tempo polinomiale, riusciamo a risolvere il problema di ottimizzazione in tempo polinomiale.
		
	\subsection{Problema SAT-Search}
		\begin{itemize}
			\item Input: $ \phi $ CNF
			\item Output: assegnamento $ \underline{a}\ t.c.\ \phi(\underline{a}) = T $, se esiste, altrimenti $ no $.
		\end{itemize}
		Vediamo ora che dato un algoritmo polinomiale $ \alg{A} $ per il problema \textbf{SAT-Dec}, riusciamo a trovare un algoritmo polinomiale per \textbf{SAT-Search}.
		
		L'idea è di procedere per passi. Prendiamo la seguente formula booleana CNF:
		\[
			\phi(x_1, x_2, x_3) = (x_1\vee x_2\vee x_3)\wedge(\overline{x_1}\vee\overline{x_2}\vee x_3)\wedge(\overline{x_1}\vee x_2\overline{x_3})
		\]
		Assegniamo $ x_1 = T $ ed eliminiamo così la prima clausola, poiché è sempre vera dato l'assegnamento:
		\[
			\phi'(x_2, x_3) = (\overline{x_2}\vee x_3)\wedge(x_2\vee \overline{x_3})
		\]
		L'algoritmo procede facendo lo stesso per $ x_2 $ e $ x_3 $. Infine otteniamo la formula $ \phi_{x_1 = a_1 \dots x_i = a_i} $ ottenuta dopo aver fissato ogni variabile.
		
		\begin{lstlisting}[frame = tb, mathescape=true, caption={Algoritmo di Ricerca per SAT}, label={lst:algo5}]
SAT-Solver($ \phi $)
	if $ \alg{A}(\phi) = no $:
		return $ no $
	for $ i = 1 $ to $ n $:
		$ a_i \leftarrow T $
		if $ \alg{A}(\phi_{x_1 = a_1 \dots x_i = a_i}) = no $:
			$ a_i \leftarrow F $
	return $ a_1, a_2, \dots, a_i $
		\end{lstlisting}
		Qual è la complessità? 
		$ T_{\text{\lstinline|SAT-Solver|}}(\vert \phi \vert) = O \big(\vert\phi \vert\cdot T_{\alg{A}}(\vert \phi \vert) \big) $, è quindi polytime.\\
		Abbiamo dimostrato quindi che se sappiamo risolvere il problema di decisione in tempo polinomiale, allora sappiamo risolvere anche il relativo problema di ricerca in tempo polinomiale.
		
	\subsection{Self Reduciblility}
		\begin{prop}
			Abbiamo visto che per ogni problema $ \npc $, se esiste un algoritmo polinomiale per il problema di \textit{decisione}, esiste un algoritmo polinomiale per il problema di \textit{ricerca} corrispondente.\\
			Se $ \p \neq \np $ esiste un problema in $ \np $ per cui \textit{non} vale "quanto sopra".
		\end{prop}
		
		\paragraph{Decision e search per i problemi in $ \np $} Vediamo le definizioni dei problemi di decisione e di ricerca per i problemi della classe $ \np $, cioè i problemi per cui
		\[
			\prob{A}\in \np \ \Leftrightarrow\ \exists V_{\prob{A}}(\cdot,\ \cdot)\ t.c.\ \prob{A}(x) = yes\ \Leftrightarrow\ \exists w\ V_{\prob{A}}(x, w) = yes
		\]
		
		Dato $ \prob{A} \in \np $ e il verificatore $ V_{\prob{A}}(\cdot,\ \cdot) $:
		\begin{definit}[problema di decisione-$\prob{A} $]
			Dato $ x\quad \exists w\quad t.c.\quad V_{\prob{A}}(x,\ w) = yes $
		\end{definit}
		\begin{definit}[problema di ricerca-$\prob{A} $]
			Dato $ x \text{ produci } w \text{, se esiste, } t.c. \quad V_{\prob{A}}(x,\ w) = yes $
		\end{definit}
		
		\bigskip
		
		\begin{definit}[Self Reducible]
			$ \prob{A}\in \np $ (rispetto a $ V_{\prob{A}} $) è \textbf{self reducible} se, dato un \textbf{oracolo} per il problema di decisione-$\prob{A} $, esiste un algoritmo polinomiale per il problema di ricerca-$\prob{A} $.
		\end{definit}
		
		\begin{definit}[Oracolo]
			Un \textbf{oracolo} è una black box che prende in input un'istanza di decisione-$\prob{A} $ e ritorna in tempo costante $ O(1) $ la soluzione (è specifico per il problema $ \prob{A} $).
		\end{definit}
		
		Abbiamo visto che \textbf{IndSet} è \textit{Self Reducible} e \textbf{SAT} è \textit{Self Reducible}.
		
		\begin{thm}
			Ogni problema $ \npc $ è \textbf{Self Reducible}
		\end{thm}
		
		Con la seguente dimostrazione vediamo come sfruttare un algoritmo \textit{"debole"} (decision) per costruirne uno \textit{"forte"} (search).
		
		\begin{proof}
			\textbf{Assunzione:} assumiamo che esista un oracolo $ \mathcal{O}_{\prob{A}} $ per il problema $ \prob{A} $.\\
			Data l'istanza $ x \in \instance{A} $ vogliamo un certificato $ w $ tale che $ \ V_{\prob{A}}(x, w) = yes $, se $ w $ esiste.
			
			Sappiamo che se $ \prob{A}\in \npc $ allora $ \prob{A}\leq_K SAT $.\\
			
			Partiamo dal teorema \textit{Cook-Levin} per cui Circuit-Sat $ \in \npc $ e SAT $ \in \npc $. Abbiamo che la riduzione da $ \prob{A} $ a SAT è tale che il certificato per l'istanza prodotta di SAT è un certificato per il verificatore $ V_{\prob{A}} $. 
			Inoltre sappiamo che possiamo trovare un certificato per SAT se abbiamo un oracolo per SAT.\\
			
			Se $ \prob{A}\in\npc $ allora $ SAT\leq_K\prob{A} $ e quindi \textit{un oracolo per $ \prob{A} $ implica un oracolo per SAT}.\\
			
			Prendiamo $ x\in\instance{A} $ e lo trasformiamo in $ \phi^{(x)} $ di SAT utilizzando il teorema \textit{Cook-Levin}. Sappiamo che
			\begin{align*}
				SAT(\phi^{(x)}) &= yes \ \Leftrightarrow\ \prob{A}(x) = yes \\
				V_{\prob{A}}(x, w) &= yes\ \Leftrightarrow\ V_{SAT}(\phi^{(x)}, \underline{w} ) = yes
			\end{align*}
			Possiamo produrre $ w $ usando l'algoritmo \lstinline|SAT-Solver| (\ref{lst:algo5}). La risposta di tale algoritmo sarà uguale alla risposta dell'oracolo
			\[
				\mathcal{O}_{\prob{A}}(f(\phi_{x_1 = a_1, \dots, x_i = a_i}))
			\]
			dove $ f $ è la riduzione polinomiale da SAT a $ \prob{A} $. In questo modo il certificato $ w $ che costruisce SAT-solver è lo stesso che serve a $ V_{\prob{A}} $.
		\end{proof}
		
		\begin{figure}[h!]
			\centering
			\begin{tikzpicture}[scale=0.7,every node/.style={scale=0.7}]
				\draw (0,0) ellipse (3cm and 2cm) node[yshift=1cm] {$ \np $};
				\draw (-1.3,0) circle (1cm) node {$ \p $};
				\draw (1.3,0) circle (1.2cm) node[align=center] {$ \npc $\\self reducible};
				\draw[fill=black] (0,-1) circle (.02cm) node[above] {};
			\end{tikzpicture}
		\end{figure}
		Vediamo ora un problema in $ \np $ che non crediamo sia in $ \npc $.
		
	\subsection{Problema Graph Isomorphism}
		Versione \textbf{Graph Isomorphism-Search}:
		\begin{itemize}
			\item Input: $ G_1 = (V_1, E_1),\ G_2 = (V_1, E_2) $ semplici e non diretti
			\item Output: una funzione $ f: v_1\mapsto v_2\quad t.c.\quad \forall (v, u) \in V_1 $\\
			$ (u,v)\in E_1\ \Leftrightarrow\ (f(u), f(v)) \in E_2 $. Se esiste una tale $ f $, altrimenti $ no $.
		\end{itemize}
		Dato un oracolo $ \mathcal{O}_{\text{GI-Dec}} $ per il problema Graph-Isomorphism-Decision, allora esiste un algoritmo polinomiale (che usa $ \mathcal{O}_{\text{GI-Dec}} $) per il problema di ricerca Graph-Isomorphism-Search.
		
		\begin{figure}[h!]
			\centering
			\begin{tikzpicture}[>=latex, scale=0.5]
				\node at (0,2.5) {$ G_1 $};
				\draw (0,0) circle (2cm);
				\node at (7,2.5) {$ G_2 $};
				\draw (7,0) circle (2cm);
				\draw[fill=black] (0,1) circle (.03cm) node[above] (v) {$ v $};
				\draw[fill=black] (7,1) circle (.03cm) node[above] (vt) {$ \tilde{v} $};
				\draw[fill=black] (0,-1) circle (.03cm) node[above] {$ u $};
				\draw[fill=black] (7,-1) circle (.03cm) node[above] {$ \tilde{u} $};
				\draw[->, bend right] (0,1) to (7,1);
				
				\draw[fill=black] (-2.5,0.25) circle (.03cm) node[above] {};
				\draw[fill=black] (-2.5,0.75) circle (.03cm) node[above] {};
				\draw[fill=black] (-2.5,1.25) circle (.03cm) node[above] {};
				\draw[fill=black] (-2.5,1.75) circle (.03cm) node[above] {};
				
				\draw[fill=black] (9.5,0.25) circle (.03cm) node[above] {};
				\draw[fill=black] (9.5,0.75) circle (.03cm) node[above] {};
				\draw[fill=black] (9.5,1.25) circle (.03cm) node[above] {};
				\draw[fill=black] (9.5,1.75) circle (.03cm) node[above] {};
				
				\foreach \i in {0.25, 0.75, ..., 1.75} {\draw[ultra thin, draw=gray] (0,1) -- (-2.5,\i);}
				\foreach \i in {0.25, 0.75, ..., 1.75} {\draw[ultra thin, draw=gray] (7,1) -- (9.5,\i);}
				
				\node at (0,-2.5) {$ \vert V_1 \vert = n $}; \node at (7,-2.5) {$ \vert V_1 \vert = n $};
			\end{tikzpicture}
			\vspace{-0.5cm}
		\end{figure}
		
		\begin{lstlisting}[frame=tb, mathescape=true, caption={Graph Isomorphism Search}]
GraphIsomorphismSearch($ G_1, G_2 $)
	if $ \mathcal{O}^{\text{GI-Decision}}(G_1, G_2) = no $:
		return $ no $
	foreach $ v_i\in V_1 $: // $\text{Fissiamo } v\in V_1, \tilde{v}\in V_2 $
		foreach $ \tilde{v}_i \in V_2 $: 
			$ \tilde{G}_1 \ \leftarrow\ \text{aggiungiamo } n \text{ vertici a } V_1 \text{ come vicini di } v $
			$ \tilde{G}_2 \ \leftarrow\ \text{aggiungiamo } n \text{ vertici a } V_2 \text{ come vicini di } \tilde{v} $
			if $ \mathcal{O}^{\text{GI-Decision}}(G_1, G_2) = yes $:
				$ f( v ) = \tilde{v} $
				$ G_1\ \leftarrow\ \tilde{G}_1,\ G_2\ \leftarrow\ \tilde{G}_2 $
				break
		\end{lstlisting}
		
		\begin{thm}
			Se $ \np\cap\conp \neq \p $ allora esiste un problema non self-reducible di ricerca il cui problema di decisione è in $ \np $.
		\end{thm}
		
		\begin{proof}
			Partiamo dunque dall'ipotesi che
			\[
				\exists \prob{A}\in\ (\np \cap \conp)\setminus \p\ \quad\ \prob{A}\notin\p,\ \prob{A}\in\np,\ \prob{A}\in\conp
			\]
			\begin{itemize}
				\item[$ \rightarrow $] $ \prob{A}\in\np $ esiste un verificatore $ V_{\text{yes}}(x, w) $ polinomiale per le istanze $ yes $ tale che 
				\[
					\forall x \in \instance{A},\ \prob{A}(x) = yes\ \Leftrightarrow\ \exists w\ \ V_{\text{yes}}(x, w) = yes
				\] 
				\item[$ \rightarrow $] $ \prob{A}\in\conp $ esiste un verificatore $ V_{\text{no}}(x, w') $ polinomiale per le istanze $ no $ tale che 
				\[
					\forall x \in \instance{A},\ \prob{A}(x) = no\ \Leftrightarrow\ \exists w'\ \ V_{\text{no}}(x, w') = yes
				\] 
			\end{itemize}
			Definiamo $ \ \forall x \in \instance{A} $ un verificatore 
			\[
				V^*(x, w) = yes \ \Leftrightarrow\ V_{\text{yes}}(x, w) = yes\quad OR\quad V_{\text{no}}(x, w) = yes
			\]
			$ V^* $ è polinomiale perché $ V_{\text{yes}}\ $ e $\ V_{\text{no}} $ sono polytime. Questo verificatore è associato al problema $ \prob{B}\in \np $ per cui $ \instance{A} = \instance{B},\ \forall x \in \instance{B}\ \prob{B}(x) = yes $.\\
			
			Il problema di ricerca associato a $ V^* $ è dato per qualche $ w $ tale che $ V^*(x, w) = yes $.\\
			
			Se in tempo polinomiale, dato $ x $, trovo un certificato $ w $ tale che  $ V^*(x, w) = yes $
			\begin{align*}
				&\text{se } V_{\text{yes}}(x, w) = yes\ \text{ allora } \prob{A}(x) = yes \\
				&\text{se } V_{\text{no}}(x, w) = yes\ \text{ allora } \prob{A}(x) = no
			\end{align*}
			Perciò risolvo $ \prob{A} $ in tempo polinomiale. Questa è una \textit{contraddizione} perché $ \prob{A}\notin \p $. Perciò il problema non è self reducible.
		\end{proof}
		
	\subsection{Problema No-small-Factor}
		\begin{itemize}
			\item Input: due numeri interi $ q, r $
			\item Output: $\ yes\ \Leftrightarrow\ q $ non ha un divisore $ \leq r $
		\end{itemize}
		Se sappiamo risolvere No-small-Factor in tempo polinomiale allora sappiamo fattorizzare in tempo polinomiale.\\
		
		Per trovare il minimo fattore di $ q $ ho un costo di $ O(\log_{10} q\cdot\log q)  $. Quindi è polinomiale in $ \vert q \vert $.\\
		
		Facciamo vedere che No-small-Factor $ \in \np $ e No-small-Factor $ \in \conp $.\\
		Nel primo caso il certificato è la fattorizzazione di $ q $
		\[
			q = a_1^{k_1}\times a_2^{k_2}\times \dots\times a_r^{k_r} \qquad a_i \text{ sono numeri primi}
		\]
		se per ogni $ i\quad a_i < r $ e la fattorizzazione è giusta e $ a_i $ sono primi, allora ritorno $ yes $. Tutto questo è fattibile in tempo polinomiale.\\
		Per verificare che il problema è in $ \conp $ il verificatore semplicemente controlla che ci sia un divisore più piccolo di $ r $ dividendo $ q $, tutto questo in polytime. Quindi il problema è qui\tikzmark{qui}
		
		\begin{figure}[h!]
			\centering
			\begin{tikzpicture}[scale=0.4]
				\draw (0,0) ellipse (3cm and 2cm) node[xshift=-.5cm] {$ \np $};
				\draw (3,0) ellipse (3cm and 2cm) node[xshift= .6cm] {$ \conp $};
				\draw (1.5,0) circle (1cm) node {$ \p $};
				\node[] at (1.3, -1.3) {\tikzmark{qui1}};
			\end{tikzpicture}
		\end{figure}
		\begin{tikzpicture}[>=latex, overlay, remember picture]
			\draw[->, bend left] (qui) to (qui1);
		\end{tikzpicture}
	\subsection{Problema Vertex Cover}
		\begin{itemize}
			\item Input: grafo $ G $ non diretto, $ k \in \N $
			\item Output: $ yes\ \Leftrightarrow\ \exists U\subseteq V\quad \vert U\vert \leq k,\quad \forall(u,v)\in E\quad \{u, v\}\cap U \neq \emptyset $
		\end{itemize}
		\begin{figure}[h!]
			\begin{subfigure}{.5\textwidth}
				\centering
				\begin{tikzpicture}
					\node[draw, circle, fill=gray] (a) at (0,0) {}; \node[draw, circle] (b) at (1,0) {};
					\node[draw, circle] (c) at (-.5,-1) {}; \node[draw, circle, fill=gray] (d) at (.5,-1) {};
					\node[draw, circle, fill=gray] (e) at (1.5,-1) {};
					\draw (a) -- (b) -- (d) -- (c) -- (a); \draw (b) -- (e) -- (d);
				\end{tikzpicture}
				\caption{è vertex cover}
			\end{subfigure}
			\begin{subfigure}{.5\textwidth}
				\centering
				\begin{tikzpicture}
				\node[draw, circle, fill=gray] (a) at (0,0) {}; \node[draw, circle] (b) at (1,0) {};
				\node[draw, circle] (c) at (-.5,-1) {}; \node[draw, circle, fill=gray] (d) at (.5,-1) {};
				\node[draw, circle] (e) at (1.5,-1) {};
				\draw (a) -- (b) -- (d) -- (c) -- (a); \draw (b) -- (e) -- (d);
				\end{tikzpicture}
				\caption{\textit{non} è vertex cover}
			\end{subfigure}
			\caption{Due esempi di grafi per vertex cover}
		\end{figure}
		
		Dimostriamo che il problema $ \in \npc $, partiamo col dimostrare che $ \in \np $:		
		\begin{itemize}
			\item Certificato: $ U,\ \vert U\vert \leq k,\ $ dove $ U $ è vertex cover.
			\item Verificatore:
			\begin{itemize}
				\item Conta i vertici in $ U $ (tempo: $ O(n) $)
				\item $ \forall (u, v)\in E $ controllo che $ \{u, v\}\cap U\neq \emptyset $
			\end{itemize}
			In tutto impiega $ O(n^2)\times O(n) = O(n^3) $. Quindi è polinomiale.
		\end{itemize}
		 
		
		Dimostriamo che il problema è $ \np-hard $: troviamo $ \prob{A}\in \npc\quad t.c.\quad \prob{A}\leq_K VC $.\\
		
		Utilizziamo $ \prob{A} = $ IndSet:
		
		Vogliamo dimostrare che\\ 
		dato $ G = (V, E)\,\ I\ $ è un IndSet di $ G\ \Leftrightarrow \ V\setminus I\ $ è un VC per $ \ G $. 
		\begin{itemize}
			\item[($ \Leftarrow $)] $ U $ è VC per $ G $, $ \ u, v \in U \ $ se $ \ (u,v)\in E\ \Rightarrow\ U $ non è VC
			$ \ \Rightarrow\ V\setminus U $ è un IndSet.
			\item[($ \Rightarrow $)] Sia $ I $ un IndSet per $ G $.\\
			Se $ \exists (u,v)\in E\quad t.c.\quad \forall w \in V\setminus I\ \ (w\neq u, w\neq v)\ \Rightarrow\ u, v\in I\ \Rightarrow\ I $ non è un IndSet.
		\end{itemize}
	
	\subsection{Problema Hitting Set}
		\begin{itemize}
			\item Input: $ U $, $ F = \{M_1, M_2, \dots, M_k\}\quad M_i\subseteq U,\quad m \in\N $
			\item Output: $ \ yes\ \Leftrightarrow\ \exists D\subseteq U, \quad \vert D\vert \leq m\quad t.c.\quad D\cap M_i \neq \emptyset\quad \forall i $.
		\end{itemize}
		Facciamo vedere che Hitting Set $ \in \npc $.
	
		\paragraph{Hitting Set $ \in \np $} Il problema Hitting Set appartiene alla classe $ \np $:
		\begin{itemize}
			\item Certificato: insieme $ D $ con $ \vert D \vert \leq m\quad t.c.\quad D\cap M_i \neq \emptyset\ \forall i $
			\item Verificatore: 
			\begin{itemize}
				\item conta gli elementi di $ D $ \hspace{2cm} $ O(\vert U \vert) $
				\item $ \forall M_i\  $ controlla che $ \ M_i\cap D \neq \emptyset $ \hspace{.7cm} $ O(k\times\vert U \vert) $
			\end{itemize}		
		\end{itemize}
		
		\paragraph{Hitting Set è $ \np$-hard} Dimostriamo che esiste la riduzione:
			\begin{align*}
				\text{\textbf{Vertex Cover}} &\leq_K \text{\textbf{Hitting Set}} \\
				G = (V, E), k &\Leftrightarrow (U, F, m)
			\end{align*}
			Dove $\ U \equiv V,\ F \equiv E,\ m \equiv k $. Possiamo dunque notare che Vertex Cover è un caso particolare di Hitting Set, il quale, invece di avere $ M_1, M_2, \dots $, ha un insieme di coppie.
			
	\section{Non determinismo e classe NTIME}
		
		\begin{definit}[Classe $ \np $] Diamo una definizione diversa della classe $ \np $:
			\[
				\np = \big\lbrace \prob{A}\ \big|\ \text{ esiste un algoritmo \textbf{non deterministico} che risolve istanze di } \prob{A} \text{ in tempo polinomiale} \big\rbrace
			\]
		\end{definit}
		
		\begin{definit}[Algoritmo non deterministico]
			Un algoritmo non deterministico è un programma (pseudocodice) che può usare un'istruzione (non deterministica) \lstinline|goto both x, y|. Il programma, grazie a questa istruzione, si sdoppia in due vie in parallelo. Tale programma ritorna $ yes $ se esiste almeno una traccia di computazione che ritorna $ yes $, altrimenti ritorna $ no $. 
		\end{definit}
			
			\begin{lstlisting}[mathescape= true, frame=tbLr,numbers=left,	stepnumber=1, firstnumber=0, numberstyle=\ttfamily\linespread{5}, caption={Esempio di algoritmo non deterministico} ]
SAT-Solver-ND($ \phi(x_1, \dots, x_n) $) "\hspace{.8cm}\tikzmark{zero}"
	for i = 1 to n
		$ a_i \leftarrow T $
		goto both 4, 5
		$ a_i \leftarrow F $
	end for
	if($ \phi(a_1, \dots, a_n) $ == $ T $)
		return $ yes $
	else
		return $ no $ 
		"\hspace{4.5cm}\tikzmark{nine}"
			\end{lstlisting}
			
		\begin{tikzpicture}[>=latex, overlay, remember picture, decoration={brace,amplitude=7pt}]
			\draw[decorate,thick] ($ (zero) +(-0.3,-.2) $) -- ($ (nine) +(-0.3,.2) $)
			node[midway, right, align=left, xshift=.3cm] {$ O(\vert x \vert^k) $}; 
		\end{tikzpicture}
			
		\begin{figure}[h!]
			\centering
			\begin{tikzpicture}[>=latex,scale=.7,every node/.style={scale=0.8}]
				\node[box, align = left] (a) at (0,0) {$ i\leftarrow 1 $\\$ a_1\leftarrow T $};
				\node[box, align = left] (b) at (-5,-2) {$ a_1\leftarrow F $\\$ i\leftarrow 2 $\\$ a_2\leftarrow T $};
				\node[box, align = left] (c) at (5,-2) {$ i\leftarrow 2 $\\$ a_2\leftarrow T $};
				\node[box, align = left] (d) at (-8,-5) {$ a_2\leftarrow F $\\
					\lstinline[mathescape= true]|if($ \phi(F,F) $ == $ T $)|\\
					\lstinline[mathescape= true]|	return $ yes $|\\
					\lstinline[mathescape= true]|else|\\
					\lstinline[mathescape= true]|	return $ no $|};
				\node[box, align = left] (e) at (-2,-5) {
					\lstinline[mathescape= true]|if($ \phi(F,T) $ == $ T $)|\\
					\lstinline[mathescape= true]|	return $ yes $|\\
					\lstinline[mathescape= true]|else|\\
					\lstinline[mathescape= true]|	return $ no $|};
				\node[box, align = left] (f) at (2,-5) {$ a_2\leftarrow F $\\
					\lstinline[mathescape= true]|if($ \phi(T,F) $ == $ T $)|\\
					\lstinline[mathescape= true]|	return $ yes $|\\
					\lstinline[mathescape= true]|else|\\
					\lstinline[mathescape= true]|	return $ no $|};
				\node[box, align = left] (g) at (8,-5) {
					\lstinline[mathescape= true]|if($ \phi(T,T) $ == $ T $)|\\
					\lstinline[mathescape= true]|	return $ yes $|\\
					\lstinline[mathescape= true]|else|\\
					\lstinline[mathescape= true]|	return $ no $|};
				\draw[->] (a.west) -- (b.north) node[midway, above] {\lstinline|4|};
				\draw[->] (a.east) -- (c.north) node[midway, above] {\lstinline|5|};
				\draw[->] (b.west) -- (d.north) node[midway, above] {\lstinline|4|};
				\draw[->] (b.east) -- (e.north) node[midway, above] {\lstinline|5|};
				\draw[->] (c.west) -- (f.north) node[midway, above] {\lstinline|4|};
				\draw[->] (c.east) -- (g.north) node[midway, above] {\lstinline|5|};
			\end{tikzpicture}
			\caption{Esempio di albero delle tracce di esecuzione per l'algoritmo SAT-Solver}
			\vspace{-1cm}
		\end{figure}
		
	\begin{obs} Possiamo vedere che:
		\begin{itemize}
			\item L'algoritmo precedentemente descritto si trasforma in diversi programmi. Ogni traccia di esecuzione, che viene rappresentata da un cammino, costituisce un assegnamento diverso.		
			\item La complessità dell'algoritmo è polinomiale: $ O(\vert x \vert^k) $. Ciò significa che la lunghezza massima di ogni cammino è polinomiale, ogni traccia di esecuzione termina in tempo polinomiale.
			\item Ogni programma non deterministico può essere trasformato in uno equivalente deterministico.
			\item Se abbiamo un algoritmo non deterministico, possiamo usarlo come \textit{verificatore}, però deve essere deterministico. Il certificato $ w $ di tale verificatore è la scelta che deve fare ogni volta che c'è un'istruzione \lstinline|goto both|.\\
			Quante sono le scelte che può fare? Sono polinomiali, quindi $ w $ è polinomiale nella taglia dell'input.
		\end{itemize}
	\end{obs}
	
	\begin{definit}[Classe NTIME]
		Definiamo la classe $ \ntime(f(n)) $ come:
		\begin{align*}
			\ntime(f(n)) = \big\lbrace & \prob{A}\ \Big|\ t.c. \text{ esiste un algoritmo non deterministico che risolve istanze di } \prob{A}\\ 
			&\text{ di taglia } n \text{ in tempo } O(f(n)) \big\rbrace
		\end{align*}
	\end{definit}
	
	\begin{obs}
		Osserviamo che:
		\[
			\np = \bigcup_{k > 0} \ntime(n^k)
		\]
		\[
			\nexp = \bigcup_{k > 0} \ntime(2^{n^k})
		\]
	\end{obs}
	
	\begin{thm}
		Se $ \nexp  \neq \Exp \quad \Rightarrow\quad \np \neq \p $
	\end{thm}
	
	\section{Alcuni problemi NP-Completi}
		In questa sezione vediamo alcuni problemi $ \npc $ con le relative dimostrazioni di appartenenza a tale classe.
		\subsection{Problema Max-Cut}
			\begin{itemize}
				\item Input: grafo $ G = (V, E) $ non diretto, $ k $
				\item Output: $ yes\ \Leftrightarrow\  $ esiste una \textit{bicolorazione} dei vertici di $ G $ tale che almeno $ k $ archi \textit{non} siano monocromatici.
			\end{itemize}
			
			\begin{figure}[h!]
				\centering
				\begin{tikzpicture}[scale=0.7]
					\node[draw, circle, fill=gray] (a) at (0,0) {};
					\node[draw, circle] (b) at (2,0) {};
					\node[draw, circle, fill=gray] (c) at (4,0) {};
					\node[draw, circle] (d) at (1,-2) {};
					\node[draw, circle, fill=gray] (e) at (3,-2) {};
					\node[draw, circle] (f) at (5,-2) {};
					\draw (a)  -- node[midway, above] {nm} (b) -- node[midway, above] {nm} (c) -- node[midway, right] {nm} (f) -- node[midway, below] {nm} (e) -- node[midway, right] {nm} (b) -- (d) -- node[midway, below] {nm} (e) ;
				\end{tikzpicture}
				\caption{Esempio di Max Cut con $ k = 5 $ (nm = non monocromatico)}
			\end{figure}
		
		\begin{proof}
			Max-Cut $ \in \npc $
			\begin{enumerate}
				\item Max-Cut $ \in \np $
				\item Max-Cut è $ \np$-hard.
			\end{enumerate}
			\begin{enumerate}
				\item \textit{Certificato}: cut o bicolorazione\\
					  \textit{Verificatore}: verifica arco per arco quanto sono non monocromatici ($ O(|E|\times|V|) $).
				\item Riduzione NAE-3-SAT $ \leq_K $ Max-Cut:\\
				Data $ \phi = C_1 \wedge C_2 \wedge \dots \wedge C_m $ vogliamo trovare $ (G, k) $.\\
				Per ogni variabile $ x $ di $ \phi $ aggiungiamo un arco in $ G $ i cui vertici sono etichettati $ x $ e $ \overline{x} $.\\				
				Per ogni clausola aggiungiamo in $ G $ un triangolo con i vertici etichettati come i letterali. Colleghiamo $ l $ in un triangolo con $ \overline{l} $ negli archi messi sopra.\\
				es.: $ \phi = (x_1 \vee \overline{x}_2 \vee x_3) \wedge (\overline{x}_1 \vee x_2 \vee x_3) $
				
				\begin{figure}[h!]
					\centering
					\begin{tikzpicture}
					\node[draw, circle] (a) at (0,0) {};\node[draw, circle] (b) at (2,0) {};
					\node[draw, circle] (c) at (3,0) {};\node[draw, circle] (d) at (5,0) {};
					\node[draw, circle] (e) at (6,0) {};\node[draw, circle] (f) at (8,0) {};
					\node[draw, circle] (g) at (1,-1) {};\node[draw, circle] (h) at (0,-2) {};
					\node[draw, circle] (i) at (2,-2) {};
					\node[draw, circle] (l) at (4,-1) {};\node[draw, circle] (m) at (3,-2) {};
					\node[draw, circle] (n) at (5,-2) {};
					\draw (a) node[above, yshift=.3cm] {$ x_1 $} -- (b) node[above, yshift=.3cm] {$ \overline{x}_1 $};
					\draw (c) node[above, yshift=.3cm] {$ x_2 $} -- (d) node[above, yshift=.3cm] {$ \overline{x}_2 $};
					\draw (e) node[above, yshift=.3cm] {$ x_3 $} -- (f) node[above, yshift=.3cm] {$ \overline{x}_3 $};
					\draw (g) node[above, yshift=.2cm] {$ x_1 $} -- (h) node[above, yshift=.2cm] {$ \overline{x}_2 $} -- (i) node[above, yshift=.2cm] {$ x_3 $} -- (g);
					\draw (l) node[above, yshift=.2cm] {$ \overline{x}_1 $} -- (m) node[above, yshift=.2cm] {$ x_2 $} -- (n) node[above, yshift=.2cm] {$ x_3 $} -- (l);
					\draw (g) -- (b);\draw (h) -- (c);\draw[bend right=90] (i) to (f);\draw (l) -- (a);
					\draw (m) to [out=15, in=-20] (d);\draw (n) -- (f);
					\end{tikzpicture}
				\end{figure}
				Dove $ m = $ numero di triangoli, $ n = $ numero di letterali. Quanti archi al massimo posso avere bicolorati? $ k = n + 3m + 2m  = n + 5m $.\\
				$ \phi $ è soddisfacibile $ \ \Rightarrow\ G $ ha un cut di taglia $ k = n + 5m $.\\
				$ \phi $ è soddisfacibile $ \ \Leftrightarrow\ \exists a_1, \dots, a_n $ tale che in ogni clausola un letterale è $ T $ e un letterale è $ F $. Colora i vertici etichettati $ l $ nero se $ l = T $, bianco se $ l = F $.\\
				$ \phi(T, T, F) = (\overset{F}{\overline{x}_1}\vee\overset{T}{x_2}\vee\overset{F}{x_3})\wedge
				(\overset{T}{x_1}\vee\overset{F}{\overline{x}_2}\vee\overset{F}{x_3}) $
				\begin{figure}[h!]
					\centering
					\begin{tikzpicture}
						\node[draw, circle, fill=gray] (a) at (0,0) {};\node[draw, circle] (b) at (2,0) {};
						\node[draw, circle, fill=gray] (c) at (3,0) {};\node[draw, circle] (d) at (5,0) {};
						\node[draw, circle] (e) at (6,0) {};\node[draw, circle, fill=gray] (f) at (8,0) {};
						\node[draw, circle, fill=gray] (g) at (1,-1) {};\node[draw, circle] (h) at (0,-2) {};
						\node[draw, circle] (i) at (2,-2) {};
						\node[draw, circle] (l) at (4,-1) {};\node[draw, circle, fill=gray] (m) at (3,-2) {};
						\node[draw, circle] (n) at (5,-2) {};
						\draw (a) node[above, yshift=.3cm] {$ x_1 $} -- node[midway] {|} (b) node[above, yshift=.3cm] {$ \overline{x}_1 $};
						\draw (c) node[above, yshift=.3cm] {$ x_2 $} -- node[midway] {|} (d) node[above, yshift=.3cm] {$ \overline{x}_2 $};
						\draw (e) node[above, yshift=.3cm] {$ x_3 $} -- node[midway] {|} (f) node[above, yshift=.3cm] {$ \overline{x}_3 $};
						\draw (g) node[above, yshift=.2cm] {$ x_1 $} -- node[midway] {|} (h) node[above, yshift=.2cm] {$ \overline{x}_2 $} -- (i) node[above, yshift=.2cm] {$ x_3 $} -- node[midway] {|} (g);
						\draw (l) node[above, yshift=.2cm] {$ \overline{x}_1 $} -- node[midway] {|} (m) node[above, yshift=.2cm] {$ x_2 $} -- node[midway] {|} (n) node[above, yshift=.2cm] {$ x_3 $} -- (l);
						\draw (g) -- node[midway] {|} (b);\draw (h) -- node[midway] {|} (c);\draw[bend right=80] (i) to node[midway] {|} (f);\draw (l) -- node[midway] {|} (a);
						\draw (m) to [out=15, in=-20] node[midway] {|} (d);\draw (n) -- node[midway] {|} (f);
					\end{tikzpicture}
					\vspace{-.5cm}
				\end{figure}
				
				Esiste un cut di $ G $ di taglia $ n + 5m \ \Rightarrow\ $ esiste un assegnamento $ a_1, \dots, a_n \ t.c.\ \phi(a_1, \dots, a_n) $ è NAE soddisfatta.\\
				Esiste un cut di $ G $ di taglia $ n + 5m \ \Rightarrow\ $
				\begin{itemize}
					\item Tutti gli archi variabile sono bicolorati.
					\item Tutti gli archi da variabile a triangolo sono bicolorati.
					\item In ogni triangolo 2 archi sono bicolorati.
				\end{itemize}
				Se scelgo
				\[
					a_i =
					\begin{cases}
						T & \mbox{ se } x_i \text{ è nero (tra gli archi variabile)} \\
						F & \mbox{ se } x_i \text{ è bianco (tra gli archi variabile)} \\
					\end{cases}
				\]
				
			\end{enumerate}
		\end{proof}
		
		
		\subsection{Problema Max-K-SAT}
			\begin{itemize}
				\item Input: formula $ \phi $ K-CNF, $ t \in \N $
				\item Output: $ yes\ \Leftrightarrow\  $ esiste un assegnamento che soddisfa almeno $ t $ clausole
			\end{itemize}
			
			esempio:
			\[
				k = 3,\ t = 2\qquad \phi = (\overline{x}_1\vee\overline{x}_2\vee x_3)\wedge (\overline{x}_1\vee x_2\vee \overline{x}_3)\wedge(\overline{x}_1\vee \overline{x}_2\vee \overline{x}_3)
 			\]
 			
 			Per $ k \geq 3 $ il problema è $ \npc $, per questa condizione, con $ t = m $ ($ m = $ numero di clausole ), il problema è identico al problema k-SAT.\\
			Max-2-SAT con $ t = m $ è risolvibile in tempo polinomiale.\\
			Max-2-SAT in generale è $ \npc $:
			
			\begin{proof}
				Dimostriamo la \textit{hardness} del problema Max-2-SAT, con la riduzione:
				\begin{align*}
					 \text{Max-Cut }& \leq_K  \text{ Max-2-SAT} \\
					 (G, k) & \ \mapsto\ \phi \text{ 2-CNF }, k'
				\end{align*}
				\begin{itemize}
					\item Idea di fondo: Vero = colore bianco, Falso = colore nero.
					\item Per ogni $ v \in V $ definiamo la variabile $ x_v $. Quindi 
					\[
						\phi(x_{v_1}, \dots, x_{v_n}) \ \text{ dove } \ \{v_1, \dots, v_n \} = V
					\]
					\item Per ogni arco $ (u, v)\in E $ aggiungiamo in $ \phi $ la formula che mi rende diversi i nodi, cioè le clausole
					\[
						x_u \neq x_v \equiv (x_u\vee x_v)\wedge(\overline{x}_u\vee\overline{x}_v)
					\]
					\item Dato $ G $ otteniamo
					\[
						\phi(x_{v_1}, \dots, x_{v_n}) = \bigwedge\limits_{l = (u, v)\in E} (x_u\vee x_v)\wedge(\overline{x}_u\vee\overline{x}_v)
					\]
				\end{itemize}
				
				\begin{figure}[h!]
					\centering
					\begin{tikzpicture}
						\node[draw, circle] (a) at (0,0) {};\node[draw, circle] (b) at (2,0) {};
						\node[draw, circle] (c) at (1,-1) {};\node[draw, circle] (d) at (3,0) {};
						\draw (a) -- (b) -- (c) -- (a); \draw (b) -- (d);
						\node at ($ (a.north) +(0,.2) $) {$ u $};\node at ($ (b.north) +(0,.2) $) {$ z $};
						\node at ($ (c.north) +(0,.2) $) {$ v $};\node at ($ (d.north) +(0,.2) $) {$ w $};
					\end{tikzpicture}
				\end{figure}
				
				\begin{align*}
					\phi(x_u, x_v, x_z, x_w) = & (x_v\vee x_u)\wedge(\overline{x}_v\vee \overline{x}_u)\wedge(x_v\vee x_z)\wedge(\overline{x}_v\vee \overline{x}_z) \\
					& (x_z\vee x_u)\wedge(\overline{x}_z\vee \overline{x}_u)\wedge(x_z\vee x_w)\wedge(\overline{x}_z\vee \overline{x}_w)
				\end{align*}
				
				
				\begin{obs}
					Per un qualsiasi assegnamento, in $ \phi $ almeno la metà delle clausole è soddisfatta, ed in particolare almeno una per ``coppia'' $ (x_a\vee x_b) $.\\
					$ k' $ non posso prenderlo più piccolo della metà del numero di clausole.
				\end{obs}
				
				\begin{obs}
					Per ogni coppia entrambe le clausole sono soddisfatte se e solo se le due variabili hanno valore diverso.\\
					$ k' $ deve essere almeno $ \vert E\vert + k $.\\
					Quindi per l'esempio sopra $ k = 2, \ k' = \vert E\vert + k = 4 + 2 = 6 $
				\end{obs}
				
				Facciamo vedere che:
				\begin{enumerate}[label*=\arabic*.]
					\item La riduzione è polinomiale:\\
					$ |\phi| = 2 \times 2\cdot|E| $ letterali quindi $ k' = O(k + |E|) $, perciò è polinomiale.
					\item $ \stackrel{\text{Max-cut}}{yes}\ \Leftrightarrow\ \stackrel{\text{Max-k-SAT}}{yes} $:
					\begin{enumerate}[label*=\arabic*.]
						\item $ yes\ \Rightarrow\ yes $: Se $ G $ ha un cut di taglia $ k $ allora esiste una colorazione che bicolora $ k $ archi $ \forall u \in V\quad x_u = T\ \Leftrightarrow\ u $ è bianco.
						\begin{align}
							& \Rightarrow \ \forall (u, v) \in E \text{ se } col(u)\neq col(v) \equiv (u, v)\in cut C \label{eq1}\\
							& \Rightarrow \ (x_v\vee x_u) \text{ è soddisfatta e } (\overline{x}_v\vee \overline{x}_u) \text{ è soddisfatta.} \label{eq2}\\
							& \Rightarrow \ \forall (u, v) \in E \text{ se } (u, v)\notin cut C \label{eq3}\\
							& \Rightarrow \ (x_v\vee x_u) \text{ è soddisfatta oppure } (\overline{x}_v\vee \overline{x}_u) \text{ è soddisfatta.} \label{eq4}\\
							& \Rightarrow 2|C| + |E| - |C| = |E| + |C| \text{ sono soddisfatte.}
						\end{align}
						$ 2|C| $ dalla implicazione (\ref{eq1}) e (\ref{eq2}), $ |E| - |C| $ da (\ref{eq3}) e (\ref{eq4}).
						\item $ yes\ \Leftarrow\ yes $: Assumiamo che in $ \phi \ \ |E| + k \ $ clausole siano soddisfatte dall'assegnamento $ a_1, \dots, a_n\ (n = |V|) $.\\
						$ \Rightarrow \ $ almeno $ k $ coppie sono soddisfatte,\\
						$ \Rightarrow \ $ per almeno $ k $ coppie le variabili hanno assegnato un valore opposto.\\
						Creiamo quindi la bicolorazione del grafo:
						\[
							\forall v\quad col(v) =
							\begin{cases}
								\text{bianco } & \mbox{ se } x_v = T\\
								\text{nero }   & \mbox{ se } x_v = F
							\end{cases}
						\]
						Per almeno $ k $ archi i vertici hanno colore diverso $ \ \Rightarrow\ $ esiste un cut di taglia $ k $.
					\end{enumerate}
				\end{enumerate}
			\end{proof}
			
		\subsection{Problema Set-Splitting}
			\begin{itemize}
				\item Input: $ (\mathcal{S}, C),\quad C = \{C_1, C_2, \dots, C_k \} $, con $ C_i \subseteq \mathcal{S}\quad i = 1\dots k $
				\item Output: $ yes\ \Leftrightarrow\  $ possiamo colorare gli elementi di $ \mathcal{S} $ rosso o blu in modo tale che ogni $ C_i $ \textit{non} è monocromatico.
			\end{itemize}
			
			\paragraph{Set-Splitting $ \in \np $} Dimostriamo che esiste un verificatore e un certificato che in tempo polinomiale decidono, data un'istanza, se questa appartiene al problema o meno in tempo polinomiale:\\
			esempio di istanza $ yes $:
			\[
				\mathcal{S} = \{\underset{r}{1}, \underset{r}{2}, \underset{b}{3}, \underset{b}{4}, \underset{b}{5}\} \quad
				C = \big\lbrace \{\underset{r}{1}, \underset{b}{3}, \underset{b}{5}\}, \{\underset{r}{2}, \underset{b}{4}\}, \{\underset{r}{1}, \underset{b}{5}\} \big\rbrace
			\]
			
			Il verificatore scorre tutto l'insieme C, e lo fa al massimo $ |\mathcal{S}| = n $ volte, quindi la complessità è $ \ O(k\times n) $. Perciò è polinomiale.
			
			\paragraph{Nae-3-SAT $ \leq_K $ Set-Splitting} Dimostriamo che esiste una riduzione
			\begin{align*}
				\text{Nae-3-SAT } & \leq_K \text{ Set-Splitting}\\
				\phi \text{ 3-CNF } & \mapsto (\mathcal{S}, C)
			\end{align*}
			
			\begin{enumerate}
				\item $ yes \Rightarrow yes $:\\
				Mappo ogni clausola di $ \phi \quad \forall i\quad C^{(i)} = (l^{(i)}_1\vee l^{(i)}_2\vee l^{(i)}_3) \ $ in 
				\[
				C_i =\{l^{(i)}_1, l^{(i)}_2, l^{(i)}_3) \}\quad \forall j = 1\dots n\quad C_j =\{x_j, \overline{x}_j \} 
				\]
				Quindi se abbiamo la formula $ \phi = (x_1\vee x_2 \vee x_3)\wedge(\overline{x}_1\vee x_2\vee \overline{x}_3) $ diventa:
				\begin{align*}
				& \mathcal{S} = \{x_1, x_2, x_3, \overline{x}_1, x_2, \overline{x}_3\} \\
				& C = \big\lbrace \{x_1, x_2, x_3 \}, \{\overline{x}_1, x_2, \overline{x}_3\}, \{x_1, \overline{x}_1\}, \{x_2, \overline{x}_2\}, \{x_3, \overline{x}_3\}\big\rbrace
				\end{align*}
				Perciò ad un assegnamento di $ \phi $ che soddisfa la formula in termini NAE corrisponde una bicolorazione non monocromatica di $ C_i $.
				\item $ yes \Leftarrow yes $:\\
				Ogni colorazione di $ \mathcal{S} $ che bicolora i vari $ C $ implica un assegnamento che soddisfa $ \phi $ in termini NAE. Devo imporre che colori di letterali uguali opposti siano opposti.
			\end{enumerate}
			
			
		
		\subsection{Problema Set-Cover}
			\begin{itemize}
				\item Input: $ (\mathcal{S}, C, k),\quad C $ famiglia di sottoinsiemi di $ \mathcal{S} $, $ \ k\in \N $
				\item Output: $ yes\ \Leftrightarrow\ \exists C_{i 1},\dots, C_{i k} \in C\quad t.c.\quad \bigcup\limits^k_{j = 1} C_{i j} = \mathcal{S} $.
			\end{itemize}
			
			esempio di istanza $ yes $:
			\[
				\mathcal{S} = \{1, 2, 3, 4, 5\},\quad C = \big\lbrace \{\underset{C_1}{1, 2} \}, \{\underset{C_2}{2, 3, 5} \}, \{\underset{C_3}{1, 2, 4}\}, \{\underset{C_4}{1, 3, 5}\}\big\rbrace,\quad k = 2 
			\]
			Esistono 2 insiemi di $ C $ la cui unione è uguale a $ \mathcal{S} $? Sì, sono $ \ C_2 \cup C_3 = \{1, 2, 3, 4, 5\} = \mathcal{S} $.
			
			\paragraph{Vertex-Cover $ \leq_K $ Set-Cover} Dimostriamo che esiste tale riduzione:
			
			\begin{figure}[h!]
				\centering
				\begin{tikzpicture}[scale=.7,every node/.style={scale=0.7}]
					\node[draw, circle] (a) at (0,0) {A}; \node[draw, circle] (b) at (2,0) {B}; 
					\node[draw, circle] (g) at (0,-2) {G}; \node[draw, circle] (c) at (2,-2) {C}; 
					\node[draw, circle] (d) at (1,-1) {D}; \node[draw, circle] (f) at (-1,-2) {F}; 
					\node[draw, circle] (e) at (1,-3) {E};
					\draw (a) -- node[midway, above] {4} (d) -- node[midway, above] {7} (b) -- node[midway, right] {8} (c) -- node[midway, above] {6} (d) -- node[midway, above] {3} (g) -- node[midway, above] {2} (f) -- node[midway, above] {1} (a);
					\draw (d) -- node[midway, right] {5} (e);
				\end{tikzpicture}
				\caption{Per questo grafo esistono $ \tilde{k} $ vertici che toccano tutti gli archi}
			\end{figure}
			Perciò il grafo in esempio si traduce in istanza di Set-Cover nel seguente modo:
			\[
				(\mathcal{S}, C, k) = \big( \{1, 2, 3, \dots, 8\}, \{\overset{A}{1,4}\}, \{\overset{B}{7,8}\}, \{\overset{C}{6, 8}\}, \{\overset{D}{3, 4, 5, 6, 7}\}, \{\overset{E}{5}\}, \{\overset{F}{1, 2}\}, \{\overset{G}{2, 3}\}, \tilde{k} \big)
			\]
			
			\begin{obs}
				Possiamo osservare che
				\[
					\text{istanze di Vertex-Cover } \subseteq \text{ istanze di Set-Cover}
				\]
				Quindi la riduzione ha costo unitario.
			\end{obs}
		
		\subsection{Classe di problemi DP e Problema Clique-No-Clique}
			\begin{definit}[classe di problemi $ \DP $]
				\[
					\DP = \big\lbrace \prob{A}\ \Big|\ \exists \prob{B},\prob{C}\in \np\quad \instance{A} = \instance{B} = \instance{C} \ t.c.\ \prob{A}(x) = yes\ \Leftrightarrow\ \prob{B}(x) = yes\ \wedge\ \prob{C}(x) = no \big\rbrace
				\]
			\end{definit}
			
			\noindent
			\textbf{Problema Clique-No-Clique}
			\begin{itemize}
				\item Input: Due grafi $ G_1, G_2,\quad k_1, k_2 \in \N $
				\item Output: $ yes\ \Leftrightarrow\ G_1 $ ha una clique di taglia $ \geq k_1 $ e $ G_2 $ \textit{non} ha alcuna clique di taglia $ \geq k_2 $.
			\end{itemize}
			
			\paragraph{Clique-No-Clique $ \in \DP $} Prendiamo i due problemi $ \prob{B} $ e $ \prob{C} $. Dove:
			\begin{itemize}
				\item $ \prob{B} = $ problema che prende in input $ G_1, G_2, k_1, k_2 $ e che ritorna in output $ yes\ \Leftrightarrow\ G_1 $ ha una clique di taglia $ \geq k_1 $.
				\item $ \prob{C} = $ input uguale a $ \prob{B} $: $ G_1, G_2, k_1, k_2 $ tranne che ritorna in output $ yes\ \Leftrightarrow\ G_2 $ ha una clique di taglia $ \geq k_2 $.
			\end{itemize}
			Quindi $ \prob{B}, \prob{C} \in \np $ e Clique-no-Clique$(x) = yes\ \Leftrightarrow\ \prob{B}(x) = yes \ \wedge \ \prob{C}(x) = no $.
			
			\paragraph{$ \forall \prob{A}\in \DP, \ \prob{A} \leq_k $ Clique-no-Clique} È vero che esiste tale trasformazione?
			\begin{proof}
				\begin{align*}
					\prob{A} \in \DP \ &\Leftrightarrow \ \exists \prob{B}, \prob{C}\in \np\quad t.c.\quad \prob{A}(x) = yes\ \Leftrightarrow\ \prob{B}(x) = yes\ \wedge\ \prob{C}(x) = no \\
					&\Leftrightarrow \ \exists \prob{B} \in \np, \overline{\prob{C}}\in \conp \quad t.c.\quad \prob{A}(x) = yes\ \Leftrightarrow\ \prob{B}(x) = yes\ \wedge\ \overline{\prob{C}}(x) = yes 
				\end{align*}
				Perciò nella riduzione
				\begin{align*}
					&\text{Clique-no-Clique}(G_1, G_2, k_1, k_2) = yes\ \Leftrightarrow\ \\
					&\text{Clique}(G_1, k_1) = yes\ \wedge\ \text{Clique}(G_2, k_2) = no\ \Leftrightarrow\ \\
					&\text{Clique}(G_1, k_1) = yes\ \wedge\ \overline{\text{Clique}(G_2, k_2)} = yes
				\end{align*}
				Abbiamo dunque che:
				\begin{align*}
					\text{Clique} &\in \npc,      & \overline{\text{Clique}} &\in \conp\mathbf{C} \\
								  & \Downarrow    &                          &\Downarrow \\
					\prob{B} &\leq_K \text{Clique}& 	 \overline{\prob{C}} &\leq_K \overline{\text{Clique}} \\
					\Rightarrow & \exists f_1\ \forall x \in \instance{\prob{B}}
												  & \Rightarrow & \exists f_2\ \forall x \in \instance{\overline{\prob{C}}} \\
					t.c.\quad & \prob{B} = yes \ \Leftrightarrow\ \text{Clique}\big(f_1(x)\big) = yes &
					t.c.\quad & \prob{B} = yes \ \Leftrightarrow\ \overline{\text{Clique}}\big(f_2(x)\big) = yes
				\end{align*}
				Quindi $ \ \forall x \in \instance{\prob{A}} = \instance{\prob{B}} = \instance{\prob{C}} $ abbiamo la funzione:
				\[
					f(x) = \big(f_1(x), f_2(x)\big)
				\]
				\begin{align*}
					\prob{A}(x) = yes\ &\Leftrightarrow\ \prob{B}(x) = yes\ \wedge \ \overline{\prob{C}}(x) = yes\ \Leftrightarrow\ \text{Clique}\big(f_1(x)\big) = yes \ \wedge \ \overline{\text{Clique}}\big(f_2(x)\big) = yes \\
					&\Leftrightarrow \ \text{Clique-no-Clique}\big(f(x)\big) = yes
				\end{align*}
			\end{proof}
			
		
		\subsection{Problema D-Ham-Path}
			\begin{itemize}
				\item Input: grafo diretto $ G = (V, E) $
				\item Output: $ yes\ \Leftrightarrow\ $ esiste in $ G $ un cammino Hamiltoniano (che percorre tutti i nodi).
			\end{itemize}
			
			\begin{figure}[h!]
				\centering
				\begin{subfigure}{.5\textwidth}
					\centering
					\begin{tikzpicture}[>=latex,scale=1.3]
						\node[draw, circle] (a) at (0,0) {}; \node[draw, circle] (b) at (1,0) {}; 
						\node[draw, circle] (c) at (2,0) {}; \node[draw, circle] (d) at (0,-1) {}; 
						\node[draw, circle] (e) at (1,-1) {}; \node[draw, circle] (f) at (2,-1) {};
						\draw[->] (a) -- node[midway, above] {1} (b); \draw[->] (b) -- node[midway, above] {2} (c); \draw[->] (c) -- node[midway, right] {3} (f); \draw[->] (f) -- node[midway, below] {4} (e); \draw[->] (e) -- node[midway, below] {5} (d); \draw[->] (d) -- (b); \draw[->] (b) -- (f); \draw[->] (b) -- (e); \draw[->] (a) -- (d);
					\end{tikzpicture}
					\caption{Istanza $ yes $}
				\end{subfigure}%
				\begin{subfigure}{.5\textwidth}
					\centering
					\begin{tikzpicture}[>=latex,scale=1.7]
					\node[draw, circle] (a) at (0,0) {}; \node[draw, circle] (b) at (1,0) {}; 
					\node[draw, circle] (c) at (0,-1) {};\node[draw, circle] (d) at (1,-1) {};
					\draw[->] (a) -- (b); \draw[->] (b) -- (c); \draw[->] (a) -- (c); \draw[->] (d) -- (b); \draw[->] (d) -- (c); 
					\end{tikzpicture}
					\caption{Istanza $ no $}
				\end{subfigure}%
				\caption{Istanze del problema D-Ham-Path}
			\end{figure}
			
			\paragraph{3-SAT $ \leq_K $ D-Ham-Path} Dimostriamo che esiste tale riduzione:
			\begin{proof}
				Dobbiamo costruire il grafo a partire dalla formula $ \phi $ 3-CNF:
				\begin{itemize}
					\item Per ogni variabile $ x $ di $ \phi $ definiamo un cammino che va in tutte e due le direzioni, con un numero di nodi pari al numero di letterali $ \ x, \overline{x}\ $ in $ \phi + 2 $.
					\item Aggiungiamo due vertici $ s, t $ e vertici $ y_1, \dots, y_n $ tra i cammini. Colleghiamo $ y_i $ agli estremi del cammino di $ x_{i+1} \quad i = 1\dots n $. Stabilendo che attraversando il cammino $ x_i $ da destra a sinistra (sinistra verso destra) significa $ x_i = T \ (x_i = F) $, abbiamo una corrispondenza tra assegnamenti e cammini hamiltoniani. 
					\item Per ogni clausola $ \ C^{(i)} = l^{(i)}_1 \vee l^{(i)}_2 \vee l^{(i)}_3 \ $ aggiungiamo un vertice.\\
					esempio: $ \ \phi(x_1, x_2, x_3) = (\overline{x}_1\vee x_2\vee x_3)\wedge(x_1\vee \overline{x}_2\vee \overline{x}_3) $
					
					\vspace{1cm}
					\begin{figure}[h!]
						\centering
						\begin{tikzpicture}[>=latex]
						\node[draw, circle] (s) at (3.8,1.5) {s};
						\node (a0) at (0,0) {$ x_1 $};
						\node[draw, circle, xshift=.5cm] (b0) at (a0.east) {};
						\node[draw, circle] (b1) at ($ (b0) + (2,0) $) {};
						\node[draw, circle] (b2) at ($ (b1) + (2,0) $) {};
						\node[draw, circle] (b3) at ($ (b2) + (2,0) $) {};
						\node[] (y1) at (3.8,-1) {$ y_1 $};
						\node (a1) at (0,-2) {$ x_2 $};
						\node[draw, circle, xshift=.5cm] (c0) at (a1.east) {};
						\node[draw, circle] (c1) at ($ (c0) + (2,0) $) {};
						\node[draw, circle] (c2) at ($ (c1) + (2,0) $) {};
						\node[draw, circle] (c3) at ($ (c2) + (2,0) $) {};
						\node[] (y2) at (3.8,-3) {$ y_2 $};
						\node (a2) at (0,-4) {$ x_3 $};
						\node[draw, circle, xshift=.5cm] (d0) at (a2.east) {};
						\node[draw, circle] (d1) at ($ (d0) + (2,0) $) {};
						\node[draw, circle] (d2) at ($ (d1) + (2,0) $) {};
						\node[draw, circle] (d3) at ($ (d2) + (2,0) $) {};
						\node[draw, circle] (t) at (3.8,-5.5) {t};
						\node[draw, circle] (C1) at (10,-1) {$ C_1 $};
						\node[draw, circle] (C2) at (10,-3) {$ C_2 $};
						\foreach \i in {b, c, d}{
								\draw[<->] (\i0) -- (\i1);\draw[->, bend left] (\i1) to node[above] {$ T $} (\i2) ;\draw[->, bend left] (\i2) to node[below] {$ F $} (\i1);\draw[<->] (\i2) -- (\i3);
						}
						\draw[->] (s) -- (b0) node[midway, above] {$ T $};
						\draw[->] (s) -- (b3) node[midway, above] {$ F $};
						\draw[->] (y1) -- (c0) node[midway, above] {$ T $};
						\draw[->] (y1) -- (c3) node[midway, above] {$ F $};
						\draw[->] (y2) -- (d0) node[midway, above] {$ T $};
						\draw[->] (y2) -- (d3) node[midway, above] {$ F $};
						\draw[->] (b0) -- (y1);\draw[->] (b3) -- (y1);	
						\draw[->] (c0) -- (y2);\draw[->] (c3) -- (y2);	
						\draw[->] (d0) -- (t);\draw[->] (d3) -- (t);
						\draw[->, bend left, ultra thick] (b2) to (b1);
						\draw[->, bend left, ultra thick] (c1) to (c2);
						\draw[->, bend left, ultra thick] (d1) to (d2);
						\draw[->, dashed] (b2) to [out=45, in=90] (C1);
						\draw[->, dashed] (C1) to [out=140, in=-60] (b1);
						\draw[->, dashed] (C1) to [out=180, in=45] (c2);
						\draw[->, dashed] (c1) to [out=-70, in=220] (C1);
						\draw[->, dashed] (d1) to [out=-50, in=260] (C1);
						\draw[->, dashed] (C1) to [out=200, in=45] (d2);
						\end{tikzpicture}
						\caption{Rappresentazione per la clausola $ C_1 $ del grafo con cammino Hamiltoniano}
					\end{figure}
				\end{itemize}
				
				Quindi abbiamo che ci sono:
				\begin{itemize}
					\item $ n + 1 $ vertici ($ s, t, y_1, \dots, y_n $)
					\item $ 2n $ vertici (gli estremi per i cammini per gli $ x $)
					\item $ 2 * 3m $ vertici nei cammini
					\item $ n $ vertici (1 per clausola)
				\end{itemize}
				Se esiste un assegnamento $ a_1, \dots, a_n\quad t.c.\quad \phi(a_1, \dots, a_n) = T\ $ il cammino che corrisponde a prendere ogni cammino variabile ($ x $) nella direzione corrispondente a $ a_i $ permette di toccare ogni nodo clausola ($ yes\ \Rightarrow\ yes $).\\
				
				\noindent
				Se esiste un cammino Hamiltoniano in $ G $, esso inizia da $ s $ e termina in $ t $, e ogni cammino variabile $ x_i $ è fatto da destra verso sinistra o viceversa. Per toccare i vertici clausola il cammino Hamiltoniano deve aver attraversato almeno uno dei cammini dei letterali della clausola nella direzione corrispondente a rendere il letterale vero. L'assegnamento corrispondente alle direzioni scelte nei cammini variabile soddisfa ogni clausola ($ yes\ \Leftarrow\ yes $).
 				
			\end{proof}
		
		\subsection*{Problema D-Ham-Cycle}
		\begin{itemize}
			\item Input: grafo diretto $ G = (V, E) $
			\item Output: $ yes\ \Leftrightarrow\ $ esiste in $ G $ un ciclo Hamiltoniano (che percorre tutti i nodi).
		\end{itemize}
	
	\noindent
	Si tratta di un problema $\npc$ come il precedente (dimostrazione simile).
			
		\newpage
	\section{Complessità di Spazio e la classe SPACE}
		In questa sezione osserviamo quali problemi sono risolvibili sotto limitazioni di memoria (spazio).
		\paragraph{Modello:} l'istanza viene data in sola lettura e fuori dalla memoria centrale di lavoro. Diciamo che abbiamo limite $ f(n) $ se per istanze lunghe $ n $ possiamo usare al massimo $ f(n) $ bit di memoria di lavoro ($ O(f(n)) $).
		
		\begin{definit}[Classe \textbf{SPACE}]
			La classe \textbf{SPACE} è definita come segue:
			\begin{align*}
				\Space(f(n)) = \big\lbrace & \prob{A}\ \Big|\ \text{ esiste un programma/algoritmo che risolve istanze di } \prob{A} \\ 
				&\text{usando al più } O(f(n)) \text{ bit di memoria di lavoro e accede }\\
				&\text{all'istanza in sola lettura. } n \text{ è la taglia dell'istanza}. \big\rbrace
			\end{align*}
		\end{definit}
		
		\paragraph{Problema Palindroma $ \in $ L} Osserviamo quanto spazio di memoria occupa l'algoritmo che risolve il problema Palindroma.
		\begin{lstlisting}[mathescape = true, frame = tb]
Palindroma(s)
	for i = 1 to n:
		if s[i] $ \neq $ s[n - i + 1]
			return $ no $
	return $ yes $
		\end{lstlisting}
		Lo spazio utilizzato è $ O(\log n) $. Quindi Palindroma $ \in \Space(\log n) $.
		
		\paragraph{Problema SAT $ \in \pspace $} Osserviamo quanto spazio di memoria occupa l'algoritmo che risolve il problema SAT.
		\begin{lstlisting}[mathescape = true, frame = tb]
SAT($ \phi(x_1, \dots, x_n) $)
	for i = 0 to $ 2^n - 1 $
		for j = 1 to n
			$ x_j \ \leftarrow \ j\text{-esimo bit di} $ i
			if ($ \phi(x_1, \dots, x_n) = T $)
				return $ yes $
	return $ no $
		\end{lstlisting}
		Questo algoritmo, come già visto, impiega tempo esponenziale, mentre occupa spazio lineare.
		\begin{itemize}
			\item Per $ i $: $ n $ bit
			\item Per $ j $: $ \log n $ bit
			\item Per \lstinline|x[]|: $ n $ bit
 		\end{itemize}
		Complessità di spazio: $ O(n) $, dove $ n = $ numero di variabili di $ \phi $. $ n \leq |\phi| $.
		
		\subsection{Classe PSPACE, L e NTIME}
			\begin{definit}[Classe PSPACE]
				\[
					\pspace = \bigcup\limits_{k > 0} \Space(n^k)
				\]
			\end{definit}
			Abbiamo visto che: \textbf{SAT} $ \in \pspace $
			
			\begin{definit}[Classe L]
				\[
					\mathbf{L} = \Space(\log n)
				\]
			\end{definit}
			Abbiamo visto che: \textbf{Palindroma} $ \in \mathbf{L} $\\
			Inoltre sappiamo che $ \np \subseteq \pspace $
			
			\begin{prop}
				$ \forall \prob{A} \in \np $ esiste una riduzione $ \prob{A}\leq_K $ SAT che trasforma l'istanza $ x \in \instance{A} $, in tempo polinomiale ($ n^k $), in una formula $ \phi_x $ tale che $ \ \prob{A} = yes\ \Leftrightarrow\ \text{SAT}(\phi_x) = yes $.\\
				Tale riduzione utilizza spazio $ O(n^k) $, in più sappiamo che $ \text{SAT}(\phi_x) $ utilizza spazio $ O(n^{k'}) $. Quindi lo spazio totale utilizzato è $ O(n^{k + k'}) $. Perciò è polinomiale in $ n = |x| $.
			\end{prop}
			
			\begin{figure}[h!]
				\centering
				\begin{tikzpicture}[scale=0.6, every node/.style={scale=0.7}]
					\draw (0,0) ellipse (3cm and 2cm) node[yshift=1.3cm] {$ \pspace $};
					\draw (-1,0) ellipse (1.5cm and 1cm) node[xshift=-.6cm] {$ \np $};
					\draw (1,0) ellipse (1.5cm and 1cm) node[align=center,xshift=.6cm] {$ \conp $};
					\node[draw, circle] at (0,0) {$ \p $};
				\end{tikzpicture}
				\caption{$ \p \subseteq \np \subseteq \pspace $}
			\end{figure}
			
			\begin{definit}[Classe NTIME] Ridefiniamo la classe $ \ntime $ nel seguente modo:
				\begin{align*}
					\ntime = \big\lbrace & \prob{A} \ \Big| \ \text{esiste un verificatore } V_{\prob{A}}(\cdot, \cdot) \\
					& \prob{A} = yes \ \Leftrightarrow\ V_{\prob{A}}(x, w) = yes \\
					& V_{\prob{A}} \text{ impiega tempo } O(f(\vert x \vert)) \\
					& \vert w \vert = O(f(\vert x \vert)) \ \big\rbrace 
				\end{align*}
			\end{definit}
			
			\paragraph{$ \ntime\big(f(n)\big) \subseteq \Space\big(f(n)\big) $} Dimostriamo questa affermazione:
			\begin{proof}
				
				Sia $ \prob{A} \in \ntime\big(f(n)\big) \ $ allora esiste un $ k $ tale che 
				\begin{align*}
					&\forall x \in \instance{A} \quad \prob{A} = yes\ \Leftrightarrow \ \exists w \in \{0, 1\}^{k\cdot f(|x|)} \quad t.c. \\ 
					&V_{\prob{A}}(x, w) = yes\ \text{ e } V_{\prob{A}}(x, w) \text{ impiega tempo al più } k\cdot f(n)
				\end{align*}
				Facciamo vedere che $ \prob{A} \in \Space\big(f(n)\big) $: dobbiamo produrre l'algoritmo $ \Pi $ che risolve le istanze di $ \prob{A} $ e usa al massimo $ f(n) $ bit.\\
				$ \Pi $ costruisce tutti i certificati $ w \in \{0, 1\}^{k\cdot f(|x|)} $ e per ognuno di questi chiama il programma $ V_{\prob{A}}(x, w) $. 
				\begin{itemize}
					\item Se per uno dei $ V_{\prob{A}} $ dice $ yes $ allora esiste il certificato, perciò tale istanza è $ yes $.
					\item Se per tutti i $ V_{\prob{A}} $ dice $ no $ allora è un'istanza $ no $.
				\end{itemize}
				Quanto spazio utilizza $ \Pi $?
				\begin{itemize}
					\item Per produrre tutti i certificati $ w $ usa spazio $ k\cdot f(|x|)\ \Rightarrow\ O\big(f(n)\big) $ bit.
					\item Poi utilizza lo spazio che utilizza il verificatore $ V_{\prob{A}}(x, w) $, il quale termina in tempo $ O\big(f(n)\big)\ \Rightarrow\  $ utilizza $ O\big(f(n)\big)\ $ spazio di memoria (ogni operazione usa una quantità fissata di spazio).
					\item[$ \Rightarrow $] $ O\big(f(n)\big) + O\big(f(n)\big) \ \Rightarrow\ O\big(f(n)\big) $
				\end{itemize}
				Perciò $ \prob{A} \in \Space\big(f(n)\big) $ ed è quindi risolvibile in tempo deterministico.
			\end{proof}
			
			Ora quindi sappiamo che
			\[
				\mathbf{TIME}\big(f(n)\big) \subseteq \ntime\big(f(n)\big) \subseteq \Space\big(f(n)\big)
			\]
			
			\paragraph{$ \Space\big(f(n)\big) \subseteq \mathbf{TIME}\big( 2^{O(f(n))} \big) $} Dimostriamo questa affermazione:
			
			
			\begin{proof}
				Esiste $ \Pi \quad t.c.\quad \Pi(x) = \prob{A}(x) \ $ con $ \ \prob{A}\in\Space\big(f(n)\big)\ $ e utilizza spazio $ O\big(f(|x|)\big) $.\\
				Cosa significa che $ \Pi $ utilizza spazio $ O\big(f(|x|)\big) $ ? Significa che tutta la memoria che contiene/usa $ \Pi $ è limitata superiormente da $ f(|x|) $.
				
				\vspace{2.5cm}
				\begin{figure}[h!]
					\vspace{-2.5cm}
					\centering
					\begin{tikzpicture}[scale=0.7, decoration={brace,amplitude=6pt}]
						\draw (0,0) -- (8,0);
						\foreach \i in {0, 0.5, ..., 8.0} {
							\draw (\i, 0) -- (\i,-.5);
						}
						\draw (0,-.5) -- (8,-.5);
						\draw[decorate,thick] (0,0.2) -- (8,0.2)
						node [midway,above, yshift=.2cm] {$ O\big(f(|x|)\big) $};
					\end{tikzpicture}
					\caption{In questa memoria i bit cambiano a seconda delle istruzioni dell'algoritmo}
				\end{figure}

				In quanti modi questi bit possono cambiare? $ O\big(f(|x|)\big) = k\cdot f(n) $.			 Ci sono al più $\ 2^{k\cdot f(n)}\ $ stati in cui la memoria si può trovare durante l'esecuzione. È deterministico, la memoria mi dice quale operazione bisogna svolgere successivamente, quindi non avremo mai il caso in cui la memoria sarà uguale più di una volta.
				
				$ \Rightarrow\ $ Il numero di stati/passi/istruzioni del programma/algoritmo è al più $2^{k\cdot f(n)}  $.
				
				$ \Rightarrow\ \prob{A}\in \mathbf{TIME}\big( 2^{O(f(n))} \big) $\\
				Perciò $ \Space\big(f(n)\big) \subseteq \mathbf{TIME}\big( 2^{O(f(n))} \big) $
			\end{proof}
			
			Quindi osserviamo l'evoluzione del programma osservando \textit{l'evoluzione della memoria}. La conseguenza immediata di questo è che:
			\[
				\pspace = \bigcup\limits_{k > 0} \Space(n^k) \subseteq \bigcup\limits_{k > 0} \mathbf{TIME}(2^{n^k}) = \Exp
			\]
			\[
				\Rightarrow \pspace\subseteq\Exp
			\]
			\[
				\Rightarrow \mathbf{L} = \Space(\log n) \subseteq  \mathbf{TIME}\big(\tikzmark{t1} 2^{O(f(n))}\tikzmark{t2} \big)
			\]
			
			\bigskip
			
			Perciò abbiamo che:
			\[
				\mathbf{L} \subseteq\p\subseteq\np\subseteq\pspace\subseteq\Exp
			\]
			
			\begin{tikzpicture}[overlay, remember picture, decoration={brace,amplitude=3pt}]
				\draw[decorate,thick] (t2.south) -- (t1.south)
				node [midway, below, yshift=-.1cm, xshift=1cm] {$ 2^{k\log n} = n^k = \p $};
			\end{tikzpicture}
			
			
		\subsection{Non determinismo e classe NSPACE}
			\begin{definit}[Classe NSPACE]
				\begin{align*}
					\nspace = \big\lbrace & \prob{A}\ \Big| \ \text{ esiste un algoritmo/programma } \Pi \text{ \textit{non deterministico}} \\
					& \text{che risolve } x \in \instance{A} \text{ usando memoria di lavoro } O(f(\vert x\vert)) \quad \Pi(x) = \prob{A}(x) \ \big\rbrace
				\end{align*}
			\end{definit}
		
		\noindent
			Nel caso del tempo con limitazione polinomiale in algoritmi non deterministici abbiamo la classe dei problemi $ \np $. Cosa succede nel caso dello spazio? Quali sono i problemi in $ \npspace $ ?
			
			\paragraph{$ \nspace \subseteq \mathbf{TIME}\big( 2^{O(f(n))} \big) $} Se ammettiamo non determinismo, dimostriamo che sappiamo risolvere lo stesso problema in tempo $ 2^{O(f(n))} $.
			
			\begin{proof}
				Prendiamo un problema $ \prob{A} \in \nspace\big(f(n)\big) $. Sappiamo che la memoria dell'algoritmo $ \Pi $ può avere $ 2^{k\cdot f(n)} $ configurazioni.
				\begin{itemize}
					\item Nel determinismo: ogni configurazione mi porta per forza alla successiva.
					\item Nel \textit{non} determinismo: ogni configurazione mi può portare al massimo in 2 configurazioni diverse. Rappresentiamo lo spazio di configurazioni con un grafo $ G_x^{\Pi} $ in cui 
					\begin{itemize}
						\item Ogni vertice è lo stato della memoria.
						\item Ogni vertice ha \textit{out-degree} 0, 1, 2.
						\item Ha $ 2^{k\cdot f(n)} $ vertici.
						\item Parte da uno stato iniziale e termina in uno stato finale in cui dice $ yes $ o $ no $.
					\end{itemize}
					 Ciò significa che $ \prob{A} = yes\ \Leftrightarrow\ $ esiste in $ G_x^{\Pi} $ un cammino dallo stato $ start $ allo stato $ finale $.
				\end{itemize}
				
				\noindent
				Se conosco $ \Pi $ posso costruire il grafo, poiché conosco l'evoluzione della memoria del programma e quindi simulo il programma e vedo i possibili stati della memoria. Il grafo è costruibile in tempo $ 2^{k\cdot f(n)} $.
				
				\begin{figure}[h!]
					\centering
					\begin{tikzpicture}[>=latex, scale=0.5]
						\foreach \u in {0, -4, -7} {
							\draw (0,\u) -- (4,\u);
							\foreach \i in {0, 0.5, ..., 4.0} {
								\draw (\i, \u) -- (\i,\u-1);
							}
							\draw (0,\u-1) -- (4,\u-1);
						}
						\foreach \u in {-2,-6,-9} {
							\draw (6,\u) -- (10,\u);
							\foreach \i in {6, 6.5, ..., 10.0} {
								\draw (\i, \u) -- (\i,\u-1);
							}
							\draw (6,\u-1) -- (10,\u-1);
						}
						\draw[->] (4,-.5) -- (8,-2);\draw[->] (2,0) -- (2,-4);\draw[->] (4,-4.5) -- (7,-3);\draw[<-] (8,-6) -- (8,-3);\draw[->] (2,-5) -- (2,-7);\draw[->] (6,-6.5) -- (4,-7.5);\draw[->] (8,-7) -- (8,-9);\draw[->,bend right] (8,-2) to (4,0);
						\node at (11.4,-9.5) {$ finale $};
						\node at (2,.5) {$ start $};
					\end{tikzpicture}
					\caption{Esempio di grafo $ G_x^{\Pi} $}
				\end{figure}
				Sia $ \prob{A} \in \nspace\big(f(n)\big)\ \Rightarrow\ \exists\Pi \ \Rightarrow\ \forall x \ \exists G_x^{\Pi} = (V, E)\ $ con $ |V| = 2^{O(f(|x|))}\ $ ed $ E $ è costruibile in tempo $ 2^{O\big(f(|x|)\big)} $
				\[
					\Rightarrow G_x^{\Pi} \text{ è costruibile in } 2^{O\big(f(|x|)\big)}
				\]
				Una volta costruito eseguiamo il solutore del problema \textbf{Reachability} su $ \big(G_x^{\Pi}, start, finale\big) $ e ritorna il valore ritornato. Il solutore è una BFS, la quale viene eseguita in tempo $ 2^{O\big(f(|x|)\big)} $.
				
				Perciò $ \nspace \subseteq \mathbf{TIME}\big( 2^{O(f(n))} \big) $.
				\begin{itemize}
					\item Se limitiamo il tempo $ \ \Rightarrow\ $ limitiamo la lunghezza del cammino di reachability di $ G_x^{\Pi} $.
					\item Se limitiamo lo spazio $ \ \Rightarrow\ $ limitiamo la dimensione del grafo $ G_x^{\Pi} $.
				\end{itemize}
			\end{proof}
		
		\subsection{Problema Reachability in termini di spazio}
			\begin{itemize}
				\item Input: grafo $ G $, nodi $ s $ e $ t $.
				\item Output: $ yes\ \Leftrightarrow\ $ esiste un cammino da $ s $ a $ t $.
			\end{itemize}
			Sappiamo che il problema appartiene alla classe $ \p $ poiché utilizzando BFS sappiamo risolverlo in tempo polinomiale, quindi vale anche che Reachability $ \in \pspace \ $ ($ \ \p\subseteq\pspace  $).
			
			\paragraph{Reachability $ \in \Space\big((\log n)^2\big) $} Utilizzando BFS non utilizziamo spazio logaritmico ma ne utilizziamo sicuramente di più. 
			
		\begin{proof}
			Dimostriamo l'appartenenza a tale classe utilizzando un algoritmo ricorsivo che utilizza l'induzione:
			
			\begin{itemize}
				\item[$ \rightarrow $] Se esiste un cammino $ s\rightsquigarrow t $ allora esiste un cammino che utilizza al più $ |V| $ vertici che ha lunghezza $ \leq n $ ($ n = |V| $).
				\item[$ \rightarrow $] Se esiste un cammino $ s\rightsquigarrow t $ di lunghezza al più $ n $ allora esiste un vertice $ u $ tale che:
				\begin{itemize}
					\item Esiste un cammino $ s\rightsquigarrow u $ di lunghezza $ \leq \lceil n/2 \rceil $.
					\item Esiste un cammino $ u\rightsquigarrow t $ di lunghezza $ \leq \lceil n/2 \rceil $.
				\end{itemize}
				\item[$ \rightarrow $] Se esiste un cammino $ s\rightsquigarrow t $ di lunghezza $ \leq 1 $ allora $ \ s = t\ $ oppure $ \ (s, t)\in E $.
			\end{itemize}
			Scriviamo quindi l'algoritmo ricorsivo:
			
			\begin{lstlisting}[mathescape=true, frame=tb, caption={Algoritmo ricorsivo per risolvere Reachability}, basicstyle=\footnotesize\ttfamily]
MiddleSearch($\medmath{ G, s, t,}$ length)
	if length $ \medmath{\leq 1} $:
		if $ s = t $ or $ (s, t)\in E $:
			return $ yes $
		else:
			return $ no $
	else:
		risposta $ \leftarrow no $
		foreach $ u \in V $:
			if (MiddleSearch($\medmath{ G, s, u, \dfrac{length}{2}} $) $ \medmath{= yes} $ and MiddleSearch($ \medmath{G, u, t, \dfrac{length}{2}} $) $ \medmath{= yes} $):
				risposta $ \leftarrow yes $
		return risposta
			\end{lstlisting}
			Quanta memoria utilizza?\\
			Quanta memoria occupano le variabili?
			\begin{itemize}
				\item Per $ s, t $ e $ u $ abbiamo $ O(\log n) $ bit.
				\item Per \lstinline|risposta| abbiamo 1 bit.
			\end{itemize}
			Cosa succede nelle chiamate ricorsive?
			
			\begin{figure}[h!]
				\begin{tikzpicture}[>=latex, decoration={brace,amplitude=6pt}]
					\node (rt) at (0,0) {MS$(G, s, t, length)$};
					\node (l) at (-3,-1.5) {MS$\big(G, s, u, \dfrac{length}{2}\big)$};
					\node (r) at (3,-1.5) {MS$\big(G, u, t, \dfrac{length}{2}\big)$};
					\node (ll) at (-6,-3) {MS$\big(G, s, u', \dfrac{length}{4}\big)$};
					\node (lr) at (0,-3) {MS$\big(G, u', u, \dfrac{length}{4}\big)$};
					\node (dots) at (ll.south) {$ \dots $};
					\node (dots1) at (lr.south) {$ \dots $};\node (dots2) at (r.south) {$ \dots $};
					\node[yshift=-1cm] (lb) at ($ (dots.south) +(-1.5,0) $) {MS$(G, s, \hat{u}, 1)$};
					\node[yshift=-1cm] (rb) at ($ (dots.south) +(1.5,0) $) {0};
					\draw[->] (rt) -- (r);\draw[->] (rt) -- (l);\draw[->] (l) -- (ll);\draw[->] (l) -- (lr);
					\draw[->] (ll) -- (lb);\draw[->] (ll) -- (rb);
					\draw[decorate,thick] (4.7,0) -- (4.7,-5) node [midway,right, xshift=.2cm] {$ O(\log n) $};
				\end{tikzpicture}
			\end{figure}
			\noindent
			In tutto viene utilizzata $ O(\log n\cdot \log n) = O(\log^2 n)$ memoria:
			\begin{itemize}
				\item $ \log n $ bit per ogni cammino radice foglia, poiché è la profondità dell'albero.
				\item $ \log n $ bit per memorizzare ogni nodo lungo il cammino.
			\end{itemize}
			Perciò il problema Reachability $ \in \Space\big((\log n)^2\big) $.
			
		\end{proof}
		
		
		\subsection{Classe NPSPACE}
			\begin{definit}(Classe NPSPACE)
				Definiamo la classe $ \npspace $ in modo analogo alla classe $ \pspace $ come:
				\[
					\npspace = \bigcup\limits_{k > 0} \nspace(n^k)
				\]
			\end{definit}
		
		Nella successiva sezione vogliamo dimostrare che $ \pspace \equiv \npspace $. Lo facciamo vedere attraverso il teorema di Savitch.
		
			 
		\subsection{Teorema di Savitch}

			\begin{thm}[Teorema di Savitch]
				Per ogni funzione $ f(n) \geq \log n \ $ si ha che
				\[
					\nspace\big(f(n)\big) \subseteq \Space\Big(\big(f(n)\big)^2\Big)
				\]
			\end{thm}
			
			\begin{proof}
				Sappiamo che $ \pspace \subseteq \npspace $. Facciamo vedere che 
				\[
					\npspace = \bigcup\limits_{k > 0} \nspace(n^k) \subseteq \bigcup\limits_{k > 0} \Space(n^{2k}) \subseteq \bigcup\limits_{k > 0} \Space(n^k) = \pspace
				\]
				Sia $ \prob{A}\in \npspace\big(f(n)\big) $:
				\begin{itemize}
					\item[$ \Rightarrow $] Esiste un algoritmo $ \Pi $ non deterministico tale che per ogni istanza $ x \in \instance{\prob{A}} $ abbiamo che $ \Pi(x) = \prob{A}(x) $ e $ \Pi $ usa spazio $ O\big(f(n)\big) $.
					\item[$ \Rightarrow $] Detto $ G_x^{\Pi} $ il grafo degli stati di $ \Pi $ su $ x $, sappiamo che tale grafo avrà $ |V| = 2^{k\cdot f(n)} $ e dati 2 stati $ u, v \in V $ abbiamo che $ (u,v)\in E $ se e solo se $ \Pi $ nello stato $ u $ ha $ v $ tra le possibili transizioni.
				\end{itemize}
				$ \Pi(x) = yes $
				\begin{itemize}
					\item[$ \Leftrightarrow $] In $ G_x^{\Pi} $ esiste un cammino dallo stato $ start $ allo stato $ finale $.
					\item[$ \Leftrightarrow $] Reachability$(G_x^{\Pi}, start, finale, 2^{k\cdot f(n)} ) = yes $.
					\item[$ \Leftrightarrow $] Middlesearch$(G_x^{\Pi}, start, finale, 2^{k\cdot f(n)} ) = yes $. Con al più 
					\[
						O\big(\log^2(2^{k\cdot f(n)})\big) = O\Big(k^2\big(f(n)\big)^2\Big) = O\big(f^2(n)\big)
					\]
					
				\end{itemize}
			
			\noindent
			Abbiamo dunque dimostrato che $\pspace = \npspace$ poiché il non-determinismo non aggiunge potenzialità nello spazio. Abbiamo inoltre che \textbf{NL} $\subseteq$ \textbf{SPACE}$(log^2(n))$
			
			\end{proof}
		
		\noindent
		Abbiamo dato una definizione di non-determinismo in termini di spazio. Ne diamo una definizione in termini di verifica.
		
		\begin{align*}
			\nspace (f(n)) = \big\lbrace & \prob{A}\ |\ \exists V(\cdot, \cdot)\ \text{ deterministico tale che } \forall x \in\instance{A} \quad \prob{A}(x) = yes\ \Leftrightarrow\ V(x, w)= yes \\
			&\text{e } V \text{ usa al più } O(f(n)) \text{ di memoria di lavoro (escludendo } x \text{ e } w\text{), }\\ 
			&V \text{ accede a } x \text{ in maniera Read-Only,} \\
			&V \text{ accede a } w \text{ in maniera Read-Only e Left-to-Right} \big\rbrace
		\end{align*}

	\begin{lstlisting}[mathescape=true, frame=tb, caption={SAT-Solver-ND $\in \npspace(n)$}, basicstyle=\footnotesize\ttfamily]
SAT-Solver-ND($\phi(x_1 \dots x_n)$)
	for i=1 to n:
    	$a_i \leftarrow T$
		GotToBoth 4,5
		$a_i \leftarrow F$
	endfor
	if $\phi(a_1 \dots a_n) = T$
		return yes
	return no
			\end{lstlisting}

		\begin{lstlisting}[mathescape=true, frame=tb, caption={SAT-Verifier}, basicstyle=\footnotesize\ttfamily]
SAT-Verifier($\phi(C_1 \dots C_n), \underline{a}$)
	risposta $\leftarrow$ yes
	for i=1 to n:
		if $l_1^i = F$ in $a ~\land~ l_2^i = F$ in $a ~\land~ l_3^i = F$ in $a$
			return no
	return yes
		\end{lstlisting}
		
		\begin{align*}
			&\pspace = \npspace = \\\big\lbrace & \prob{A}\ |\ \exists V(\cdot, \cdot)\ \text{ deterministico tale che } \forall x \in\instance{A} \quad \prob{A}(x) = yes\ \Leftrightarrow\ V(x, w)= yes \\
			&\text{e } V \text{ usa al più } O(|x|^k) \text{ di memoria di lavoro (escludendo } x \text{ e } w\text{), }\\ 
			&V \text{ accede a } x \text{ in maniera Read-Only,} \\
			&V \text{ accede a } w \text{ in maniera Read-Only e Left-to-Right} \big\rbrace
		\end{align*}
		
		\subsection{Classe di problemi PSPACE-completi}
		\begin{multicols}{2}
			\begin{definit}
				$ \prob{A} $ è $ \pspace$-completo se:
				\begin{itemize}
					\item $ \prob{A} \in \pspace $
					\item $ \forall \prob{B} \in \pspace \quad \prob{B} \leq_K \prob{A} \ $ (hardness)
				\end{itemize}
				$ \Rightarrow\ $ se $ \prob{A} $ è $ \pspace$-completo e $ \prob{A}\in \p $ allora $ \p \equiv\pspace $ (implica anche che $ \p \equiv\np $) 
			\end{definit}
			\columnbreak
			\begin{figure}[H]
				\centering
				\begin{tikzpicture}[scale=0.7,every node/.style={scale=0.7}]
				\draw (0,0) ellipse (3cm and 2cm) node[yshift=1cm] {$ \pspace $};
				\draw (-1.3,0) circle (1cm) node[align=center] {$ \pspace $ \\\textbf{Completo}};
				\draw (1.3,0) circle (1cm) node[align=center] {$ \np $};
				\draw[fill=black] (0,-1) circle (.02cm) node[above] {};
				\end{tikzpicture}
			\end{figure}
		\end{multicols}
	
	
	 \subsection{Problemi Q-SAT e 2-Player-SAT}
	 \textit{\textbf{Q-SAT} (Quantified SAT)} $\in \pspace$\textbf{-Completo}
	 \begin{itemize}
	 	\item Input: $ \phi (x_1 \dots x_n) = \exists x_1 \forall x_2 \dots \exists x_{n-1} \forall x_n \phi (x_1 \dots x_n)$
	 	\item Output: $ yes \ \Leftrightarrow\ \phi $ è vera
	 \end{itemize}
 
 	\noindent
	\textit{\textbf{2-Player-SAT}}
 	\begin{itemize}
 		\item Input: $ \phi (x_1 \dots x_n)$ CNF
 		\item Output: $ yes \ \Leftrightarrow\ P_1 \ $ vince nel seguente gioco:\\
 		$ P_1 $ e $ P_2 $ si alternano scegliendo i valori delle varie $x_i$. $P_1$ vince se $\phi$ è soddisfatta dai valori scelti, altrimenti vince $P_2$ ($P_1$ deve fare scelte che valgono $\forall$ mossa di $P_2$).
	\end{itemize}
	 
	 \noindent
	 Questi due problemi sono equivalenti tra loro.\\
	 Facciamo vedere che \textit{Q-SAT} $ \in \pspace$\textbf{-completo}:
	 
	 \begin{proof}[\textit{Q-SAT} $ \in \pspace$]
	 	Costruisco l'albero di decisione:
	 	\begin{figure}[h!]
	 		\centering
	 		\begin{tikzpicture}
		 		\node[draw] (a) at (6, 3.75) {OR}; 
		 		\node[draw] (b) at (3.25, 2.75) {AND}; \node[draw] (c) at (8.75, 2.75) {AND}; 
		 		\node[draw] (d) at (1.75, 1.75) {OR}; \node[draw] (e) at (4.75, 1.75) {OR}; 
		 		\node[draw] (f) at (7.25, 1.75) {OR}; \node[draw] (g) at (10.25, 1.75) {OR}; 
		 		\node (h) at (1.25, .75) {$ \phi $}; \node (l) at (2.25, .75) {$ \phi $}; 
		 		\node (m) at (4.25, .75) {$ \phi $}; \node (i) at (10.75, .75) {$ \phi $};
		 		\node (n) at (5.25, .75) {$ \phi $}; \node (o) at (6.75, .75) {$ \phi $}; 
		 		\node (p) at (7.75, .75) {$ \phi $}; \node (q) at (9.75, .75) {$ \phi $};
		 		\draw (a) -- node[left, above] {T} (b) -- (d) -- (h); \draw (d) -- (l);
		 		\draw (b) -- (e) -- (m); \draw (e) -- (n);
		 		\draw (a) -- node[right, above] {F} (c) -- (g) -- (q); \draw (c) -- (f) -- (o); \draw (f) -- (p);\draw (g) -- (i);
		 		\node at (12,3.75) {$ x_1 $}; \node at (12,2.75) {$ x_2 $};\node at (12,1.75) {$ x_3 $};
	 		\end{tikzpicture}
	 	\end{figure}
	 	
	 	Quindi dalla prima ramificazione partendo da $ x_1 $ abbiamo:
	 	\begin{align*}
		 	&\forall x_2\exists x_3\ \phi (T, x_2, x_3) \\
		 	&\forall x_2\exists x_3\ \phi (F, x_2, x_3)
	 	\end{align*}
		 Perciò data una formula quantificata totalmente possiamo vedere se è T o F. Costruiamo quindi il programma che valuta la formula:
		 \begin{lstlisting}[mathescape=true, frame=tb, basicstyle=\small\ttfamily, caption={Algoritmo che valuta la formula quantificata $ \phi $}]
eval($ \phi = Q_1 x_1\ Q_2 x_2\ \dots\ Q_n x_n\ \phi $)
	if $ \ Q_1 = $ null: ($ \phi $ non quantificata)
		return 0
	if $ \ Q_1 = \exists $:
		return eval($ Q_2 x_2\ Q_3 x_3\ \dots\ Q_n x_n\ \phi(x_1\ \leftarrow\ T ) $) OR
			   eval($ Q_2 x_2\ Q_3 x_3\ \dots\ Q_n x_n\ \phi(x_1\ \leftarrow\ F ) $)
	else:
		return eval($ Q_2 x_2\ Q_3 x_3\ \dots\ Q_n x_n\ \phi(x_1\ \leftarrow\ T ) $) AND
			   eval($ Q_2 x_2\ Q_3 x_3\ \dots\ Q_n x_n\ \phi(x_1\ \leftarrow\ F ) $)
		 \end{lstlisting}
		 
		 Sappiamo che impiega $ O(2^n) $ tempo.\\
		 Quanto spazio occupa questo algoritmo?\\
		 Ho $ n $ chiamate ricorsive, una per ogni variabile. Ogni chiamata ha un bit per sapere la validità del sotto-albero. Quindi è $ O(n) $. Perciò \textit{Q-SAT}$ \in\pspace $.
	 \end{proof}
	 
	 Facciamo ora vedere che \textit{Q-SAT} è $ \pspace$\textbf{-hard}, cioè che:
	 \[
		 \forall \prob{A}\in \pspace\quad \prob{A}\leq_K \text{\textit{Q-SAT}}
	 \]
	 
	 \begin{proof}
	 	Dimostriamo che ogni problema in $ \pspace $ si riduce ad un problema di gioco tra due giocatori:
	 	
	 \end{proof}
		
		\subsection{Problema Geography}
			\begin{itemize}
				\item Input: grafo diretto $ G = (V, E) $ diretto, $ \ s \in V $
				\item Output: $ yes \ \Leftrightarrow\ P_1 \ $ vince nel seguente gioco:\\
				$ P_1 $ e $ P_2 $ si alternano scegliendo un vertice collegato da un arco nell'ultimo vertice scelto e non scelto ancora. Perde il primo che non ha più mosse.
			\end{itemize}
		
		\noindent
		Il problema \textbf{Geography} è $\pspace$\textbf{-Completo} (si dimostra con \textit{Q-SAT} $\leq$ \textit{Geography}).
		
		\subsection{Problema Alternating Hamiltonian Path}
			\begin{itemize}
				\item Input: grafo diretto orientato $ G = (V, E) $, $ \ s\in V $
				\item Output: $ yes\ \Leftrightarrow\ P_1 \ $ vince nel seguente gioco:\\
				$ P_1 $ e $ P_2 $ si alternano come in Geography. $ P_1 $ vuole completare un HamPath e $ P_2 $ vuole bloccare $ P_1 $.
			\end{itemize}
		
		\noindent
		Il problema \textbf{Geography} è $\pspace$\textbf{-Completo} (si dimostra con \textit{Q-SAT} $\leq$ \textit{A-HamPath}).
		
		
	\section{Approssimazione}
		Per ogni \textit{problema di ottimizzazione} è possibile definire il corrispondente problema di \textit{decisione}.\\
		Diciamo che $\mathbb{A}^{opt}$ è $\np$\textit{-hard} se il corrispondente problema di decisione è $\npc$.
		
		\subsection{Algoritmo di Approssimazione per un problema A\textsuperscript{opt}}
		\begin{definit}
			Sia $\mathbb{A}$ un problema di \textbf{minimizzazione}, $\mathcal{A}$ è un algoritmo di \textit{k-approssimazione} per $\mathbb{A}$ se: 
			\[
				\forall x \in \instance{A}\quad \dfrac{VAL(\alg{A}(x))}{VAL(OPT(x))}\leq k
			\]
			
		\end{definit}
	
	\begin{definit}
		Sia $\mathbb{A}$ un problema di \textbf{massimizzazione}, $\mathcal{A}$ è un algoritmo di \textit{k-approssimazione} per $\mathbb{A}$ se: 
		\[
			\forall x \in \instance{A}\quad \dfrac{VAL(OPT(x))}{VAL(\alg{A}(x))}\leq k
		\]

	\end{definit}

\noindent
dove
\begin{itemize}
	\item \textit{OPT(x)}: è una soluzione di valore massimo/minimo per l'istanza $x$.
	\item $\alg{A}(x)$: è la soluzione ritornata dall'algoritmo $\alg{A}$ sull'istanza $x$.
\end{itemize}
\noindent
Un algoritmo di \textit{1-approssimazione} è un algoritmo ottimo.
		
		\subsection{Approssimazione per il problema Makespan}
			\begin{itemize}
				\item Input: $ n $ job/task $ \ \{1, 2,\dots, n \} \ $ di taglia $ \ j_1, j_2,\dots, j_n $
				\item Output: Partizione di $ \{1 \dots n \},\ M_1 \dots M_n \ $ tale che
				\[
					\max\limits{1\leq k\leq m} \sum\limits_{i\in M_k} j_i \text{ è \textit{minimo}}
				\]
			\end{itemize}
		
		\noindent
		Il problema di minimizzazione \textit{Makespan} è $\np$\textbf{-hard} (il problema di decisione è $\npc$).\\
		
		Dobbiamo avere un lower bound $ B $ tale che $ \ OPT(x) \geq B $.		
		Un lower bound per $ OPT\ $ è $\ \sum\limits_{i} \dfrac{j_i}{m} $. Perciò abbiamo che:
		\[
			OPT(x) \geq \dfrac{T}{m}
		\]
		dove $\ T =\ $ tempo totale dei job $ \ = \sum\limits_{i} j_i $.\\
		Scegliamo un parametro $ \ s\in \left[ 0, 1 \right]\ $, sia $\ L = \{i\ |\ j_i \geq T_s \} $.\\
		
		\noindent
		Algoritmo:
		\begin{itemize}
			\item Risolvi ottimamente il problema per i soli job in $ L $.$ ^* $
			\item Per ogni job $ \notin L\ $ assegna il job alla macchina con il carico minimo fino ad ora (in maniera greedy). $ ^{\star} $
		\end{itemize}
		Vogliamo far vedere che \textit{l'algoritmo è polinomiale} e \textit{c'è garanzia di Approssimazione}.
		
		\begin{obs} 
			sia $\ s\ $ costante $\ |L| \leq \dfrac{1}{s} $. Sia $ r > \dfrac{1}{s} $, il carico di job in $ L $ è:
			\[
				sT \geq sT\cdot r > sT \cdot \dfrac{1}{s} = T
			\]
		\end{obs}
		Quante partizioni di $\ \dfrac{1}{s}\ $ in $ m $ parti? $ m^{1/s} $\\
		Quindi: 
		\begin{itemize}
			\item $ ^* $ costa $ O(m^{1/s}) $ tempo
			\item $ ^{\star} $ costa $ O(n\cdot m\log m) $ tempo
		\end{itemize}
		Perciò l'algoritmo è polinomiale!

		\newpage
		
		\begin{figure}[h!]
			\centering
			\begin{tikzpicture}
				\draw (0,0) -- (0,-1) -- (1,-1) -- (1,0);\draw[pattern=north east lines] (0,-.5) rectangle (1,-1);
				\draw (2,0) -- (2,-1) -- (3,-1) -- (3,0);\draw[pattern=north east lines] (2,-.75) rectangle (3,-1);
				\draw (4,0) -- (4,-1) -- (5,-1) -- (5,0);\draw[pattern=north east lines] (4,-.25) rectangle (5,-1);
				\draw (6,0) -- (6,-1) -- (7,-1) -- (7,0);\draw (6,-.1) rectangle (7,-.8) node[midway] {$ x $};
				\draw (8,0) -- (8,-1) -- (9,-1) -- (9,0);\draw[pattern=north east lines] (8,-.2) rectangle (9,-1);
				\draw (10,0) -- (10,-1) -- (11,-1) -- (11,0);\draw[pattern=north east lines] (10,-.65) rectangle (11,-1);
				\node at (6.5, -1.5) {$ M_x $};\node at (8.5, -1.5) {$ M_t $};\node at (10.5, -1.5) {$ m $};
			\end{tikzpicture}
			\caption{Prendiamo la macchina che ottiene il Makespan (carico maggiore)}
		\end{figure}
		Quando l'ultimo job $ x $ messo su $ M_x $ è stato posto lì, il carico di $ M_x = (M_x - x) $ era non maggiore del carico delle altre macchine.\\
		$ M_t \geq M_x - x \ $ per ogni $ \ M_t \neq M_x $\\
		Il carico totale delle macchine è 
		\[
			T = \sum\limits_{M_t \neq M_x} M_t + M_x \geq (m - 1)\left[ M_t - x\right] + M_x 
		\]
		\[
			m M_x \leq T + (m - 1) x
		\]
		\[
			M_x \leq \dfrac{T}{m} + \dfrac{(m - 1)x}{m} \leq \dfrac{T}{m} + x
		\]
		
		\begin{itemize}
			\item Se $ \ x \in L\ $ allora $ M_x $ ha una suddivisione ottima
			\item Se $ \ x \notin L\ $ allora $ \ x < T\cdot s $.
		\end{itemize}
		
		\[
			M_x \leq \dfrac{T}{m} + \dfrac{(m - 1)x}{m} < \dfrac{T}{m} + \dfrac{(m - 1)x}{m} T\cdot s =
			\dfrac{T}{m} \big( 1 + (m - 1) s \big)
		\]
		Quindi ho ottenuto l'approssimazione: $ \ \big( 1 + (m - 1) s \big)\ $, dove $ s $ viene scelta:
		\[
			\dfrac{M_x}{OPT} \leq \big( 1 + (m - 1) s \big)
		\]
		Se prendiamo l'approssimazione di $ 1.001 $ scegliamo $ s $ come:
		\[
			s < \dfrac{0.001}{m - 1}
		\]
		Concludiamo che l'algoritmo è un PTAS,\\ cioè $ \ \forall \epsilon \in \left[0, 1\right] $ posso garantire l'approssimazione $ (1 + \epsilon) $
		
		\subsection{PTAS e FPTAS}
		
		\begin{definit}[PTAS]
			\textit{\textbf{PTAS} (Polinomial Time Approximation Scheme)} è un algoritmo che data $\ x\in \mathcal{I}(\mathbb{A}) \ $ e $\ \epsilon$, fornisce una soluzione $\ s\ $ per $\ x\ $ t.c.
			\[
			\dfrac{VAL(\mathcal{A}(x))}{VAL(OPT(x))}~\leq~(1+~\epsilon)
			\]
			
			Il running-time del \textit{PTAS} $\mathcal{A}$ è $\mathcal{O}(|x|^k)$ (polinomiale in $|x|$ ma può essere esponenziale in $(\frac{1}{\epsilon})$).
		\end{definit}
		\begin{definit}[FPTAS]
			\textit{\textbf{FPTAS} (Fully Polinomial Time Approximation Scheme)} è un algoritmo che data $\ x\in \mathcal{I}(\mathbb{A})\ $ e $\ \epsilon$, fornisce una soluzione $\ s\ $ per $\ x\ $ t.c.
			\[
			\dfrac{VAL(\mathcal{A}(x))}{VAL(OPT(x))}~\leq~(1+~\epsilon)
			\]
			Il running-time del \textit{PTAS} $\mathcal{A}$ è $\mathcal{O}(|x|^k (\frac{1}{\epsilon})^k)$ (polinomiale in $|x|$ e in $(\frac{1}{\epsilon})$).
		\end{definit}
		
		\subsection{Il problema SubSetSum (decisione)}
		\begin{itemize}
			\item Input: $A = \{ a_1 \dots a_n \}, S$
			\item Output: $yes \Leftrightarrow \exists A' \subseteq A t.c. \Sigma_{x\in A'} x = S$
		\end{itemize}
		
		\noindent
		Il problema di decisione \textit{SubSetSum} è $\npc$
		
		\subsection{Il problema Partition (decisione)}
		\begin{itemize}
			\item Input: $A = \{ a_1 \dots a_n \}$
			\item Output: $yes \Leftrightarrow \exists A' \subseteq A t.c. \Sigma_{x\in A'} x = \Sigma_{x\notin A'} x$
		\end{itemize}
	
	\noindent
	Il problema di decisione \textit{Partition} è $\npc$ e sappiamo che \textit{Partition} $\leq$ \textit{Makespan} (con $m=2$).
		
		\subsection{Problema di Traveling Salesman}
			\begin{itemize}
				\item Input: Grafo completo diretto pesato $ G = (V, E) $, $ \ w : E \mapsto \N $
				\item Output: ciclo hamiltoniano di peso minimo.
			\end{itemize}
		
		\noindent
		Il problema \textit{TSP} è $\np$\textbf{-hard} (il problema di decisione è $\npc$, infatti \textit{HamCycle} $\leq$ \textit{TSP\textsubscript{Decision}}).\\
		\textit{TSP} non è approssimabile (se P $\neq$ NP): non esiste un algoritmo polinomiale per TSP che garantisce $f(n)$ approssimazione, altrimenti risolverei \textit{HamCycle} in tempo polinomiale.
		
		\subsection{Problema Knapsack}
			\begin{itemize}
				\item Input: $ v_1, \dots, v_n $ (valori) $ \quad w_1, \dots, w_n $ (pesi)
				\item Output: $ A \subseteq \{1\dots n \} \ t.c.\ \sum\limits_{i \in A} w_i \leq W,\quad \sum\limits_{i \in A} v_i \ $ è massima.
			\end{itemize}
		
		\noindent
		Il problema \textit{Knapsack} è $\np$\textbf{-hard} (il problema di decisione è $\npc$, infatti \textit{Partition} $\leq$ \textit{Knapsack}).\\
		Si risolve con programmazione dinamica: soluzione non polinomiale per istanze grandi. 
		
		\subsection{Classe APX}
			\begin{definit}[Classe APX]
				\begin{align*}
					\apx(r(n)) = \big\lbrace & \prob{A} \text{ di ottimizzazione } \Big| \ \text{ esiste un algoritmo polinomiale per } \prob{A} \\
					& \text{ che è } r(n)\text{-approssimabile } \big\rbrace
				\end{align*}
			\end{definit}
		
		\noindent
		TSP $\notin APX$, ~~IndependentSet $\notin APX$.\\
		VertexCover $\in APX$, ~~Makespan $\in APX$, ~~Knapsack $\in APX$.
		
		\subsection{Tecnica del GAP}
			\begin{thm}
				Dato un problema di ottimizzazione $ \prob{A} $ definiamo il problema $ (a, b) - \prob{A} $ il problema \textbf{di decisione} che consiste nel dire se la soluzione ottima ad un'istanza di $ \prob{A} $ è $ \leq a \ $ o $ \ \geq b $.
			\end{thm}
		
		\noindent
		Se esiste un problema $\prob{B} \in \npc$ t.c. $\mathbb{B} \leq (a,b)-\prob{A}$, allora \textit{non esiste} un algoritmo di approssimazione polinomiale per $\prob{A}$ che garantisce approssimazione $k < \frac{b}{a}$ se P$\neq$ NP.
		
		\subsection{Problema Max-k-xor-SAT}
			\begin{itemize}
				\item Input: formula k-xor-CNF, esempio: $ \phi = (x_1 \oplus x_2\oplus x_2) \wedge (\overline{x}_1 \oplus x_2 \oplus \overline{x}_3) $.
				\item Output: il massimo numero di clausole soddisfacibili.
			\end{itemize}
		
		\noindent
		Il problema è $\np$\textbf{-hard} $\forall k \geq 2$, altrimenti è inapprossimabile (problema di decisione $\npc$).\\
		Il problema $(a,b)$\textit{-gap-k-max-xor-sat} è $\npc$ per ogni $(a, b)$ t.c. $a<1$ e $b > \frac{1}{2}$.
		
		
		\subsection{Max-3-SAT}
		\begin{itemize}
			\item Input: formula $\psi$ 3 CNF
			\item Output: assegnamento che soddisfa il massimo numero di clausole.
		\end{itemize}
	
	\noindent
	Il problema generale \textit{Max-k-SAT} è $\np$\textbf{-hard} $\forall k \geq 2$, altrimenti è inapprossimabile.\\
	\begin{thm}
		\textit{Max-3-SAT} non ammette approssimazione migliore di $\frac{8}{7}$.
	\end{thm}
	\begin{proof}
		Trasferimento del gap da \textit{Max-3-XOR-SAT} a \textit{Max-k-SAT}, ovvero una riduzione:
		\[
			\text{(a,b)-Gap-Max-3-XOR-SAT}\ \mapsto\ \text{(a', b')-Gap-Max-3-SAT}
		\]
		cioè
		\[
			\phi(x_1, \dots, x_n) = (x_1\oplus x_2\oplus x_3)\wedge(\overline{x}_1\oplus x_2\oplus \overline{x}_3)\ \mapsto\
			\psi(x_1\vee x_2'\vee x_3')\wedge(\overline{x}_1'\vee x_2'\vee \overline{x}_3')
		\]
		
		\begin{figure}[h!]
			\centering
			\begin{tikzpicture}
				\draw[|<->|] (0,0) -- (2,0) node[yshift=-.45cm] {$ bm $}; 
				\draw[|<->|] (3,0) node[yshift=-.5cm] {$ am $} -- (5,0) node[yshift=-.5cm] {$ m $}; 
				\draw[|<->|] (6,0) -- (8,0) node[yshift=-.45cm] {$ b'm $}; 
				\draw[|<->|] (9,0) node[yshift=-.45cm] {$ a'm $} -- (11,0) node[yshift=-.45cm] {$ m' $}; 
			\end{tikzpicture}
		\end{figure}
		
		\noindent
		Supponiamo che $ \ (l_1\oplus l_2\oplus l_3)\ $ sia una clausola di $ \phi $. Quand'è che la clausola è vera? Quando \textit{non} è vero che:
		\[
			(\overline{l}_1\wedge \overline{l}_2\wedge\overline{l}_3)\vee(\overline{l}_1\wedge l_2\wedge l_3)\vee(l_1\wedge \overline{l}_2\wedge l_3)\vee(l_1\wedge l_2\wedge\overline{l}_3)
		\]
		Quindi usando de Morgan abbiamo che dev'essere vera:
		\[
			(l_1\vee l_2\vee l_3)\wedge(l_1\vee \overline{l}_2\vee \overline{l}_3)\wedge(\overline{l}_1\vee l_2\vee \overline{l}_3)\wedge(\overline{l}_1\vee \overline{l}_2\vee l_3)
		\]
		
		Da $ m $ clausole in $ phi $ passo a $ 4m $ clausole in $ \psi $.
		
		\begin{obs}
			Almeno tre delle clausole mostrate sopra sono soddisfatte per ogni assegnamento che posso scegliere.\\
			Se $ \underline{a} $ per $ \phi $ soddisfa $ \alpha $ clausole allora per $ \psi $ soddisfa $\ 3m + \alpha\ $ clausole.\\
			Se dico che in $ \phi $ riesco a soddisfare $ 1/2 m $ clausole, allora in $ \psi $ riesco a soddisfare $ 3m + 1/2m $ clausole.
		\end{obs}
		\begin{figure}[h!]
			\centering
			\begin{tabular}{c|ccccc|c}
			             & & $ \phi $ &                         & $ \psi $      & & \\
			$ b = 1/2m $ & & $ 1/2m $ & $ \longleftrightarrow $ & $ 3m + 1/2m $ & & $ b'= 3m + 1/2m $\\
			$ a = m $    & & $ m $ & $ \longleftrightarrow $ & $ 4m $ & & $ a'= 4m $
			\end{tabular}
		\end{figure}
		
		Quindi $ \Big(\dfrac{4m}{4m}, \dfrac{3m + 1/2m}{4m} \Big)$-Gap-Max-3-SAT è $ \np$-completo. Perciò
		\[
			\dfrac{4\cancel{m}}{\cancel{4m}}\cdot\dfrac{\cancel{4m}}{3\cancel{m} + 1/2\cancel{m}} = \dfrac{8}{7}
		\]
		è la migliore approssimazione che posso ottenere per Max-3-SAT
	\end{proof}
	
	\noindent
	Per Max-3-SAT non esiste un algoritmo di k-approssimazione tale che $ k < \dfrac{8}{7} $\\
	$ \Leftrightarrow $\\
	Per ogni algoritmo $ \alg{A} $ per Max-3-SAT esiste un insieme di formule $ \phi $ tali che esiste un assegnamento che soddisfa $ t $ clausole ma $ \alg{A} $ ritorna un assegnamento che soddisfa $ \leq\dfrac{7}{8}t $ clausole.
		
		
	\subsection{Inapprossimabilità}
	VertexCover $\notin FPTAS$.\\
	IndependetSet $\notin FPTAS$.
		
	\section{Riassunto delle classi di complessità}
	
	\begin{figure}[h!]
		\centering
			\begin{tikzpicture}
				\draw (0,0) ellipse (7cm and 5cm) node[yshift=4.5cm] {$ \Exp $};
				\draw (0,0) ellipse (6.5cm and 4cm) node[yshift=3.5cm] {$ \pspace = \npspace $};
				\draw (3,1) ellipse (2cm and 2cm) node {$ \pspace-$completo};
				\draw (-2.5,-.5) ellipse (3.5cm and 2.5cm) node[yshift=2.25cm] {$ \ph $};
				\draw[color=gray] (-2.5,-.5) ellipse (3.4cm and 2.4cm);
				\draw[color=gray] (-2.5,-.5) ellipse (3.3cm and 2.3cm);
				\draw[color=gray] (-2.5,-.5) ellipse (3.2cm and 2.2cm);
				\draw[color=gray] (-2.5,-.5) ellipse (3.1cm and 2.1cm);
				\draw (-2.5,-.5) ellipse (3cm and 2cm) node[yshift=1.25cm] {$ \np $};
				\draw (-4,-.5) ellipse (1.4cm and 1.4cm) node[yshift=1.1cm] {$ \p $};
				\draw (-4,-.6) ellipse (.7cm and 1cm) node[yshift=.6cm] {$ \mathbf{NL} $};
				\draw (-4,-.7) ellipse (.4cm and .4cm) node {$ \mathbf{L} $};
				\draw (-1,-.5) ellipse (1cm and 1cm) node {$ \npc^{*} $};
			\end{tikzpicture}
			\caption{Insieme delle classi di complessità}
	\end{figure}
	
	\[
		\mathbf{L}\subseteq\mathbf{NL}\subseteq\p\subseteq\np\subseteq\pspace\subseteq\Exp
	\]
	
	\subsection{Lista dei problemi visti e complessità}
		\begin{figure}[h!]
			\begin{tabular}{lccccccc}
				\toprule
				\textbf{Problema} & {\small $ \p $} & {\small $ \np $} & {\small $ \npc $} & {\small $ \conp\mathbf{C} $} & {\small $ \pspace $} & {\small $ \pspace$-compl} & {\small \textbf{Riduzione da}}\\
				\midrule
				Eulerian Cycle & \checkmark & & & & \checkmark & & \\
				K-Colouring (K=2) & \checkmark & & & & \checkmark & & \\
				K-Colouring (K>2) & & \checkmark & \checkmark & & \checkmark & & ($ \leq_K $) (K+1)-Col  \\
				K-SAT (K=2) & \checkmark & & & & \checkmark & & \\
				K-SAT (K>2) & & \checkmark & \checkmark & & \checkmark & & K-Colouring\\
				Circuit-SAT & & \checkmark & \checkmark & & \checkmark &  & ($ \leq_K $) SAT\\
				Tautology & & & & \checkmark & \checkmark & & \\
				Min-Circuit Bool\footnotemark[1] & & & & & \checkmark & & \\
				Graph Isomorphism & & \checkmark & & & \checkmark & & \\
				Clique & & \checkmark & \checkmark & & \checkmark & & 3-SAT \\
				Clique-no-Clique & & \checkmark & \checkmark & & \checkmark & & $ \prob{A}\in\mathbf{DP} $\\
				Independent Set & & \checkmark & \checkmark & & \checkmark & & Clique \\
				Only Small IndSet & & & & \checkmark & \checkmark & & \\
				Vertex Cover & & \checkmark & \checkmark & & \checkmark & & Independent Set\\
				Hitting Set & & \checkmark & \checkmark & & \checkmark & & Vertex Cover \\
				Max Cut & & \checkmark & \checkmark & & \checkmark & & NAE-3-SAT\\
				Set Splitting & & \checkmark & \checkmark & & \checkmark & & NAE-3-SAT\\
				Set Cover & & \checkmark & \checkmark & & \checkmark & & Vertex Cover\\
				Hamiltonian Path & & \checkmark & \checkmark & & \checkmark & &  \\
			\end{tabular}
		\end{figure}
		\begin{figure}[t]		
			\begin{tabular}{lccccccc}
				\toprule
				\textbf{Problema} & {\small $ \p $} & {\small $ \np $} & {\small $ \npc $} & {\small $ \conp\mathbf{C} $} & {\small $ \pspace $} & {\small $ \pspace$-compl} & {\small \textbf{Riduzione da}}\\
				\midrule
				Q-SAT (= 2p-SAT) & & & & & & \checkmark &  \\
				Geography & & & & & & \checkmark & Q-SAT\\
				Alternating Hampath & & & & & & \checkmark & Q-SAT \\
				Reachability\footnotemark[2] & \checkmark & & & & \checkmark & & \\
				Makespan-m & & \checkmark & \checkmark & & \checkmark & &  Partition\\
				SubsetSum & & \checkmark & \checkmark & & \checkmark & & \\
				Partition & & \checkmark & \checkmark & & \checkmark & & \\
				Traveling Salesman & & \checkmark & \checkmark & & \checkmark & & HamCycle\\
				Knapsack & & \checkmark & \checkmark & & \checkmark & & Partition\\
				Max-k-xor-SAT & & \checkmark & \checkmark & & \checkmark & & \\
				Max-k-SAT & & \checkmark & \checkmark & & \checkmark & & Max Cut\\
				Set Cover & & \checkmark & \checkmark & & \checkmark & & Vertex Cover\\
				\bottomrule
			\end{tabular}
			\caption{Problemi e classi di complessità relative}
		\end{figure}
	
		\footnotetext[1]{Min-Circuit Bool appartiene alla gerarchia polinomiale $ \Sigma_2 P $}
		\footnotetext[2]{per Reachability abbiamo una complessità di $ O(\Space(\log^2 n)) $}
\end{document}
